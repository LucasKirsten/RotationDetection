{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \u001b[0m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \u001b[0m\u001b[33m\u001b[33m\n",
      "Hit:4 https://deb.nodesource.com/node_12.x xenial InRelease                    \u001b[0m\u001b[33m\u001b[33m\n",
      "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1413 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]   \u001b[0mm\u001b[33m\u001b[33m\u001b[33m\n",
      "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2584 kB][33m\n",
      "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2152 kB]3m\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2184 kB]\u001b[33m\u001b[33m\u001b[33m\n",
      "Fetched 8585 kB in 9s (997 kB/s)                                               \u001b[0m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "122 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libc-ares2 libhttp-parser2.7.1 libicu60 libssl1.0.0 libuv1 nodejs-doc\n",
      "Use 'apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  libbsd0 libice6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 x11-common\n",
      "The following NEW packages will be installed:\n",
      "  libbsd0 libice6 libsm6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6\n",
      "  libxext6 x11-common\n",
      "0 upgraded, 10 newly installed, 0 to remove and 122 not upgraded.\n",
      "Need to get 899 kB of archives.\n",
      "After this operation, 4012 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxau6 amd64 1:1.0.8-1ubuntu1 [7556 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbsd0 amd64 0.8.7-1ubuntu0.1 [41.6 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp6 amd64 1:1.1.2-3 [10.7 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1 amd64 1.13-2~ubuntu18.04 [45.5 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-data all 2:1.6.4-3ubuntu0.4 [114 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-6 amd64 2:1.6.4-3ubuntu0.4 [572 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxext6 amd64 2:1.3.3-1 [29.4 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 x11-common all 1:7.7+19ubuntu7.1 [22.5 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libice6 amd64 2:1.0.9-2 [40.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm6 amd64 2:1.2.2-1 [15.8 kB]\n",
      "Fetched 899 kB in 2s (451 kB/s)   \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libxau6:amd64.\n",
      "(Reading database ... 21462 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libxau6_1%3a1.0.8-1ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libxau6:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../1-libbsd0_0.8.7-1ubuntu0.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../2-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../3-libxcb1_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../4-libx11-data_2%3a1.6.4-3ubuntu0.4_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libx11-data (2:1.6.4-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../5-libx11-6_2%3a1.6.4-3ubuntu0.4_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libx11-6:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../6-libxext6_2%3a1.3.3-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../7-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8\u001b[1mdpkg-query:\u001b[0m no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../8-libice6_2%3a1.0.9-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking libice6:amd64 (2:1.0.9-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../9-libsm6_2%3a1.2.2-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libx11-data (2:1.6.4-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libxau6:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up libice6:amd64 (2:1.0.9-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libx11-6:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following packages were automatically installed and are no longer required:\n",
      "  libc-ares2 libhttp-parser2.7.1 libicu60 libssl1.0.0 libuv1 nodejs-doc\n",
      "Use 'apt autoremove' to remove them.\n",
      "The following additional packages will be installed:\n",
      "  libpthread-stubs0-dev libx11-dev libx11-doc libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxrender1 x11proto-core-dev x11proto-dev xorg-sgml-doctools\n",
      "  xtrans-dev\n",
      "Suggested packages:\n",
      "  libxcb-doc\n",
      "The following NEW packages will be installed:\n",
      "  libpthread-stubs0-dev libx11-dev libx11-doc libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxrender-dev libxrender1 x11proto-core-dev x11proto-dev\n",
      "  xorg-sgml-doctools xtrans-dev\n",
      "0 upgraded, 12 newly installed, 0 to remove and 122 not upgraded.\n",
      "Need to get 3206 kB of archives.\n",
      "After this operation, 15.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpthread-stubs0-dev amd64 0.3-4 [4068 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 xorg-sgml-doctools all 1:1.11-1 [12.9 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-dev all 2018.4-4 [251 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-core-dev all 2018.4-4 [2620 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxau-dev amd64 1:1.0.8-1ubuntu1 [9476 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp-dev amd64 1:1.1.2-3 [25.1 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 xtrans-dev all 1.3.5-1 [70.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1-dev amd64 1.13-2~ubuntu18.04 [80.0 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-dev amd64 2:1.6.4-3ubuntu0.4 [641 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-doc all 2:1.6.4-3ubuntu0.4 [2065 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender-dev amd64 1:0.9.10-1 [24.9 kB]\n",
      "Fetched 3206 kB in 2s (1320 kB/s)         \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libpthread-stubs0-dev:amd64.\n",
      "(Reading database ... 21793 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libpthread-stubs0-dev_0.3-4_amd64.deb ...\n",
      "Unpacking libpthread-stubs0-dev:amd64 (0.3-4) ...\n",
      "Selecting previously unselected package xorg-sgml-doctools.\n",
      "Preparing to unpack .../01-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\n",
      "Unpacking xorg-sgml-doctools (1:1.11-1) ...\n",
      "Selecting previously unselected package x11proto-dev.\n",
      "Preparing to unpack .../02-x11proto-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-dev (2018.4-4) ...\n",
      "Selecting previously unselected package x11proto-core-dev.\n",
      "Preparing to unpack .../03-x11proto-core-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-core-dev (2018.4-4) ...\n",
      "Selecting previously unselected package libxau-dev:amd64.\n",
      "Preparing to unpack .../04-libxau-dev_1%3a1.0.8-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxau-dev:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "Selecting previously unselected package libxdmcp-dev:amd64.\n",
      "Preparing to unpack .../05-libxdmcp-dev_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp-dev:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package xtrans-dev.\n",
      "Preparing to unpack .../06-xtrans-dev_1.3.5-1_all.deb ...\n",
      "Unpacking xtrans-dev (1.3.5-1) ...\n",
      "Selecting previously unselected package libxcb1-dev:amd64.\n",
      "Preparing to unpack .../07-libxcb1-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb1-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libx11-dev:amd64.\n",
      "Preparing to unpack .../08-libx11-dev_2%3a1.6.4-3ubuntu0.4_amd64.deb ...\n",
      "Unpacking libx11-dev:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Selecting previously unselected package libx11-doc.\n",
      "Preparing to unpack .../09-libx11-doc_2%3a1.6.4-3ubuntu0.4_all.deb ...\n",
      "Unpacking libx11-doc (2:1.6.4-3ubuntu0.4) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../10-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libxrender-dev:amd64.\n",
      "Preparing to unpack .../11-libxrender-dev_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender-dev:amd64 (1:0.9.10-1) ...\n",
      "Setting up libpthread-stubs0-dev:amd64 (0.3-4) ...\n",
      "Setting up xorg-sgml-doctools (1:1.11-1) ...\n",
      "Setting up x11proto-dev (2018.4-4) ...\n",
      "Setting up xtrans-dev (1.3.5-1) ...\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.2-3) ...\n",
      "Setting up libx11-doc (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up x11proto-core-dev (2018.4-4) ...\n",
      "Setting up libxau-dev:amd64 (1:1.0.8-1ubuntu1) ...\n",
      "Setting up libxcb1-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libx11-dev:amd64 (2:1.6.4-3ubuntu0.4) ...\n",
      "Setting up libxrender-dev:amd64 (1:0.9.10-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/libs/utils/cython_utils\n",
      "rm: cannot remove '*.so': No such file or directory\n",
      "rm: cannot remove '*.c': No such file or directory\n",
      "rm: cannot remove '*.cpp': No such file or directory\n",
      "running build_ext\n",
      "cythoning bbox.pyx to bbox.c\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /workdir/msc/RotationDetection/libs/utils/cython_utils/bbox.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "cythoning nms.pyx to nms.c\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /workdir/msc/RotationDetection/libs/utils/cython_utils/nms.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'cython_bbox' extension\n",
      "{'gcc': ['-Wno-cpp', '-Wno-unused-function']}\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c bbox.c -o build/temp.linux-x86_64-3.6/bbox.o -Wno-cpp -Wno-unused-function\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/bbox.o -o /workdir/msc/RotationDetection/libs/utils/cython_utils/cython_bbox.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'cython_nms' extension\n",
      "{'gcc': ['-Wno-cpp', '-Wno-unused-function']}\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c nms.c -o build/temp.linux-x86_64-3.6/nms.o -Wno-cpp -Wno-unused-function\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/nms.o -o /workdir/msc/RotationDetection/libs/utils/cython_utils/cython_nms.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/libs/utils/cython_utils\n",
    "!rm *.so\n",
    "!rm *.c\n",
    "!rm *.cpp\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/libs/utils\n",
      "rm: cannot remove '*.so': No such file or directory\n",
      "rm: cannot remove '*.c': No such file or directory\n",
      "rm: cannot remove '*.cpp': No such file or directory\n",
      "running build_ext\n",
      "cythoning rbbox_overlaps.pyx to rbbox_overlaps.cpp\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /workdir/msc/RotationDetection/libs/utils/rbbox_overlaps.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "cythoning rotate_polygon_nms.pyx to rotate_polygon_nms.cpp\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /workdir/msc/RotationDetection/libs/utils/rotate_polygon_nms.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "cythoning iou_cpu.pyx to iou_cpu.cpp\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /workdir/msc/RotationDetection/libs/utils/iou_cpu.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'rbbox_overlaps' extension\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c rbbox_overlaps_kernel.cu -o build/temp.linux-x86_64-3.6/rbbox_overlaps_kernel.o -arch=sm_35 --ptxas-options=-v -c --compiler-options '-fPIC'\n",
      "ptxas info    : 0 bytes gmem, 144 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function '_Z15overlaps_kerneliiPKfS0_Pf' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z15overlaps_kerneliiPKfS0_Pf\n",
      "    176 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 78 registers, 2560 bytes smem, 352 bytes cmem[0], 228 bytes cmem[2]\n",
      "ptxas info    : Function properties for __internal_trig_reduction_slowpathd\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c rbbox_overlaps.cpp -o build/temp.linux-x86_64-3.6/rbbox_overlaps.o -Wno-unused-function\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Krbbox_overlaps.cpp:626\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/rbbox_overlaps_kernel.o build/temp.linux-x86_64-3.6/rbbox_overlaps.o -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/usr/local/cuda/lib64 -lcudart -o /workdir/msc/RotationDetection/libs/utils/rbbox_overlaps.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'rotate_polygon_nms' extension\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c rotate_polygon_nms_kernel.cu -o build/temp.linux-x86_64-3.6/rotate_polygon_nms_kernel.o -arch=sm_35 --ptxas-options=-v -c --compiler-options '-fPIC'\n",
      "ptxas info    : 0 bytes gmem, 144 bytes cmem[3]\n",
      "ptxas info    : Compiling entry function '_Z17rotate_nms_kernelifPKfPy' for 'sm_35'\n",
      "ptxas info    : Function properties for _Z17rotate_nms_kernelifPKfPy\n",
      "    176 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 62 registers, 1536 bytes smem, 344 bytes cmem[0], 200 bytes cmem[2]\n",
      "ptxas info    : Function properties for __internal_trig_reduction_slowpathd\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c rotate_polygon_nms.cpp -o build/temp.linux-x86_64-3.6/rotate_polygon_nms.o -Wno-unused-function\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Krotate_polygon_nms.cpp:626\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/rotate_polygon_nms_kernel.o build/temp.linux-x86_64-3.6/rotate_polygon_nms.o -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/usr/local/cuda/lib64 -lcudart -o /workdir/msc/RotationDetection/libs/utils/rotate_polygon_nms.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'iou_cpu' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/local/cuda/include -I/usr/include/python3.6m -c iou_cpu.cpp -o build/temp.linux-x86_64-3.6/iou_cpu.o -Wno-unused-function\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kiou_cpu.cpp:626\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/iou_cpu.o -L/usr/local/cuda/lib64 -Wl,--enable-new-dtags,-R/usr/local/cuda/lib64 -lcudart -o /workdir/msc/RotationDetection/libs/utils/iou_cpu.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/libs/utils/\n",
    "!rm *.so\n",
    "!rm *.c\n",
    "!rm *.cpp\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HRSC2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/dataloader/dataset/HRSC2016\n",
      "/workdir/msc/RotationDetection/dataloader\n"
     ]
    }
   ],
   "source": [
    "# change path in files to attend each dataset\n",
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/HRSC2016\n",
    "!python make_test_xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /workdir/msc/RotationDetection/dataloader/dataset/  \n",
    "#!python convert_data_to_tfrecord.py --VOC_dir='/datasets/dataset/HRSC2016/HRSC2016/HRSC2016'  \\\n",
    "#                                   --xml_dir='/datasets/dataset/HRSC2016/HRSC2016/HRSC2016/Train/xmls' \\\n",
    "#                                   --image_dir='/datasets/dataset/HRSC2016/HRSC2016/HRSC2016/Train/AllImages' \\\n",
    "#                                   --save_name='train'  \\\n",
    "#                                   --img_format='.bmp'  \\\n",
    "#                                   --save_dir='/datasets/dataset/HRSC2016/HRSC2016' \\\n",
    "#                                   --dataset='HRSC2016'     \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/DOTA\n",
    "!python data_crop.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/  \n",
    "!python convert_data_to_tfrecord.py --VOC_dir='/datasets/dataset/DOTA/crop/trainval' \\\n",
    "                                   --xml_dir='labeltxt' \\\n",
    "                                   --image_dir='images' \\\n",
    "                                   --save_name='train'  \\\n",
    "                                   --img_format='.png'  \\\n",
    "                                   --dataset='DOTA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO_VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/dataloader/dataset/COCO_VOC\n",
      "True\n",
      "100%|█████████████████████████████████████| 85241/85241 [40:41<00:00, 34.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# change path in files to attend each dataset\n",
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/COCO_VOC\n",
    "!python txt2xml.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/dataloader/dataset\n",
      "2021-05-22 01:42:03.498087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/workdir/msc/RotationDetection\n",
      "WARNING:tensorflow:From convert_data_to_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "100%|█████████████████████████████████████| 85240/85240 [46:51<00:00, 30.32it/s]\n",
      "\n",
      "Conversion is complete!\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/dataloader/dataset/  \n",
    "!python convert_data_to_tfrecord.py --VOC_dir='/datasets/dataset/COCO_VOC/train' \\\n",
    "                                   --xml_dir='xmls' \\\n",
    "                                   --image_dir='images' \\\n",
    "                                   --save_name='train'  \\\n",
    "                                   --img_format='.jpg'  \\\n",
    "                                   --dataset='COCO_VOC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/tools/gwd\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "/workdir/msc/RotationDetection\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/mobilenet/mobilenet.py:357: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:139: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:219: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/losses/losses_gwd.py:29: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:33: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:111: The name tf.train.piecewise_constant is deprecated. Please use tf.compat.v1.train.piecewise_constant instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:35: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:37: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "tfrecord path is --> /datasets/msc/HRSC2016_train*\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:114: The name tf.train.match_filenames_once is deprecated. Please use tf.io.match_filenames_once instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:116: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:26: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:29: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:32: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:173: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:223: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:209: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/image_augmentation.py:42: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../dataloader/dataset/read_tfrecord.py:127: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From train.py:80: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:83: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:83: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:144: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:156: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "\n",
      "**********\n",
      "Using ProbIoU l1\n",
      "**********\n",
      "WARNING:tensorflow:From train.py:145: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:178: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:182: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      " CHECKPOINT PATH: /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_HRSC2016_10L3_2L1/HRSC2016_64998model.ckpt\n",
      "\n",
      "******************************\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:173: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "model restore from : /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_HRSC2016_10L3_2L1/HRSC2016_64998model.ckpt\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:188: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:189: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:192: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:195: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-06-01 17:23:02.418409: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-06-01 17:23:02.442486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2021-06-01 17:23:02.443661: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48bb630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-01 17:23:02.443684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-01 17:23:02.446746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-01 17:23:02.568541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8bbef10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-01 17:23:02.568601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2021-06-01 17:23:02.570643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65\n",
      "pciBusID: 0000:2d:00.0\n",
      "2021-06-01 17:23:02.570744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-01 17:23:02.573551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-01 17:23:02.575854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-01 17:23:02.576455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-01 17:23:02.579710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-01 17:23:02.582331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-01 17:23:02.588693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-01 17:23:02.590973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-01 17:23:02.591030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-01 17:23:02.594096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-01 17:23:02.594118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-01 17:23:02.594128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-01 17:23:02.596323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5)\n",
      "2021-06-01 17:23:02.830301: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "Identity: GPU CPU XLA_CPU XLA_GPU \n",
      "VariableV2: CPU \n",
      "Assign: CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  get_batch/matching_filenames (VariableV2) /device:GPU:0\n",
      "  get_batch/matching_filenames/Assign (Assign) /device:GPU:0\n",
      "  get_batch/matching_filenames/read (Identity) /device:GPU:0\n",
      "\n",
      "2021-06-01 17:23:02.830645: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "ReaderReadV2: CPU \n",
      "TFRecordReaderV2: CPU \n",
      "QueueSizeV2: GPU CPU XLA_CPU XLA_GPU \n",
      "QueueCloseV2: GPU CPU XLA_CPU XLA_GPU \n",
      "FIFOQueueV2: CPU XLA_CPU XLA_GPU \n",
      "QueueEnqueueManyV2: CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  get_batch/input_producer (FIFOQueueV2) /device:GPU:0\n",
      "  get_batch/input_producer/input_producer_EnqueueMany (QueueEnqueueManyV2) /device:GPU:0\n",
      "  get_batch/input_producer/input_producer_Close (QueueCloseV2) /device:GPU:0\n",
      "  get_batch/input_producer/input_producer_Close_1 (QueueCloseV2) /device:GPU:0\n",
      "  get_batch/input_producer/input_producer_Size (QueueSizeV2) /device:GPU:0\n",
      "  get_batch/TFRecordReaderV2 (TFRecordReaderV2) /device:GPU:0\n",
      "  get_batch/ReaderReadV2 (ReaderReadV2) /device:GPU:0\n",
      "\n",
      "2021-06-01 17:23:02.831030: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
      "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
      "See below for details of this colocation group:\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "QueueDequeueManyV2: CPU \n",
      "QueueCloseV2: GPU CPU XLA_CPU XLA_GPU \n",
      "PaddingFIFOQueueV2: CPU \n",
      "QueueSizeV2: GPU CPU XLA_CPU XLA_GPU \n",
      "QueueEnqueueV2: GPU CPU XLA_CPU XLA_GPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  get_batch/batch/padding_fifo_queue (PaddingFIFOQueueV2) /device:GPU:0\n",
      "  get_batch/batch/padding_fifo_queue_enqueue (QueueEnqueueV2) /device:GPU:0\n",
      "  get_batch/batch/padding_fifo_queue_Close (QueueCloseV2) /device:GPU:0\n",
      "  get_batch/batch/padding_fifo_queue_Close_1 (QueueCloseV2) /device:GPU:0\n",
      "  get_batch/batch/padding_fifo_queue_Size (QueueSizeV2) /device:GPU:0\n",
      "  get_batch/batch (QueueDequeueManyV2) /device:GPU:0\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:200: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:204: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "restore model\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:30: The name tf.profiler.profile is deprecated. Please use tf.compat.v1.profiler.profile instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/train_base.py:30: The name tf.profiler.ProfileOptionBuilder is deprecated. Please use tf.compat.v1.profiler.ProfileOptionBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "1108 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/472.72m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_50 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_50/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_47 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_47/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_43 (2.36m/7.08m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/mul (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/sub_1 (2.36m/2.36m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_43/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/7.08m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (7.08m/7.08m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_45 (2.10m/6.29m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/mul (2.10m/2.10m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/sub_1 (2.10m/2.10m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_45/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/6.29m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (6.29m/6.29m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv1/weights/Initializer/truncated_normal (2.36m/4.72m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/shortcut/weights/Initializer/truncated_normal (2.10m/4.19m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (2.10m/2.10m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_49 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_49/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_48 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_48/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_46 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_46/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_51 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_51/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_44 (1.05m/3.15m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/mul (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/sub_1 (1.05m/1.05m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_44/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/3.15m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (3.15m/3.15m flops)\n",
      "  tower_0/gradients/AddN_8 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_35 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_30 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_28 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_26 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_18 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_13 (2.95m/2.95m flops)\n",
      "  tower_0/gradients/AddN_10 (2.95m/2.95m flops)\n",
      "  tower_0/clip_by_norm_47/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_58 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_47/mul (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_53 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_50/truediv (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_50/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_50/mul (2.36m/2.36m flops)\n",
      "  tower_0/gradients/AddN_49 (2.36m/2.36m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_43/mul (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_43/mul_1 (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_43/truediv (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_47/truediv (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_47/Sum (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_50/Sum (2.36m/2.36m flops)\n",
      "  tower_0/clip_by_norm_43/Sum (2.36m/2.36m flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (2.10m/2.10m flops)\n",
      "  resnet50_v1d/C5/bottleneck_1/conv0/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_2/conv0/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv2/weights/Initializer/truncated_normal (1.05m/2.10m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_57 (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_45/truediv (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_45/mul (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_45/mul_1 (2.10m/2.10m flops)\n",
      "  tower_0/clip_by_norm_45/Sum (2.10m/2.10m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_28 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_28/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_24 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_24/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_74 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_74/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_74/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_74/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_82 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_82/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_82/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_82/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_72 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_72/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_72/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_72/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_78 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_78/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_78/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_78/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_31 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_31/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_70 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_70/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_80 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_80/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_80/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_80/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_84 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_84/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_84/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_84/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_68 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_68/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_66 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_66/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_34 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_34/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_64 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_64/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_62 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_62/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_60 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_60/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_37 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_37/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_58 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_58/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_40 (589.82k/1.77m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/mul (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/sub_1 (589.82k/589.82k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_40/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_cls_1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_cls_1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_cls_2/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_cls_2/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_cls_3/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_cls_3/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_reg_0/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_reg_0/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_reg_1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_reg_1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_reg_2/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_reg_2/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_reg_3/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_reg_3/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/rpn_net/conv2d_3x3_cls_0/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/rpn_net/conv2d_3x3_cls_0/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/p7_conv/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/p7_conv/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/p6_conv/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/p6_conv/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer (1/1.77m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer/L2Loss (1.77m/1.77m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_42 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_42/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_52 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_52/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_26 (524.29k/1.57m flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/mul (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/sub_1 (524.29k/524.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_26/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer (1/1.57m flops)\n",
      "    tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer/L2Loss (1.57m/1.57m flops)\n",
      "  tower_0/gradients/AddN_24 (1.21m/1.21m flops)\n",
      "  build_pyramid/fuse_P5/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P5/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P5/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/p7_conv/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/p7_conv/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/p7_conv/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/p6_conv/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/p6_conv/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/p6_conv/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/fuse_P4/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P4/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P4/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  build_pyramid/fuse_P3/weights/Initializer/random_uniform (589.82k/1.18m flops)\n",
      "    build_pyramid/fuse_P3/weights/Initializer/random_uniform/mul (589.82k/589.82k flops)\n",
      "    build_pyramid/fuse_P3/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_cls_0/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_cls_0/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_cls_1/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_cls_1/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_cls_2/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_cls_2/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_cls_3/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_cls_3/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_reg_0/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_reg_0/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_reg_1/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_reg_1/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_reg_2/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_reg_2/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv1/weights/Initializer/truncated_normal (589.82k/1.18m flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv1/weights/Initializer/truncated_normal/mul (589.82k/589.82k flops)\n",
      "  rpn_net/conv2d_3x3_reg_3/weights/Initializer/random_normal (589.82k/1.18m flops)\n",
      "    rpn_net/conv2d_3x3_reg_3/weights/Initializer/random_normal/mul (589.82k/589.82k flops)\n",
      "  build_pyramid/build_P5/weights/Initializer/random_uniform (524.29k/1.05m flops)\n",
      "    build_pyramid/build_P5/weights/Initializer/random_uniform/mul (524.29k/524.29k flops)\n",
      "    build_pyramid/build_P5/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C5/bottleneck_0/conv0/weights/Initializer/truncated_normal (524.29k/1.05m flops)\n",
      "    resnet50_v1d/C5/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (524.29k/524.29k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/shortcut/weights/Initializer/truncated_normal (524.29k/1.05m flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_56 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_51/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_51/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_51/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_49/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_49/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_44/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_48/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_48/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_44/truediv (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_44/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_46/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_46/mul_1 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_48 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_46/truediv (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_48/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_51 (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_49/mul (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_52 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/AddN_55 (1.05m/1.05m flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_48/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_44/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_51/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_46/Sum (1.05m/1.05m flops)\n",
      "  tower_0/clip_by_norm_49/Sum (1.05m/1.05m flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_41 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_41/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_38 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_38/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_39 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_39/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_54 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_54/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_25 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_25/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_36 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_36/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_35 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_35/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_33 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_33/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_32 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_32/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_30 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_30/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_29 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_29/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_27 (262.14k/786.43k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/mul (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/sub_1 (262.14k/262.14k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_27/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer (1/786.43k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer/L2Loss (786.43k/786.43k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_86 (241.92k/725.76k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_86/mul (241.92k/241.92k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_86/sub_1 (241.92k/241.92k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_86/sub (1/1 flops)\n",
      "  tower_0/rpn_net/rpn_regression/kernel/Regularizer/l2_regularizer (1/725.76k flops)\n",
      "    tower_0/rpn_net/rpn_regression/kernel/Regularizer/l2_regularizer/L2Loss (725.76k/725.76k flops)\n",
      "  tower_0/clip_by_norm_78/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_74/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_74/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p7_conv/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_72/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_78/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_74/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_72/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_66/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_68/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_78/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_72/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_68/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_70/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_68/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_70/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_70/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_37/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_31/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_31/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_31/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_34/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_34/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_34/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_28/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_37/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_37/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_40/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_40/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_40/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p6_conv/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_60/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_66/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_64/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_64/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_64/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_62/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_62/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_62/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_60/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_60/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_66/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_28/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_28/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_82/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_80/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_42 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_74 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_78 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_38 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_80/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_37 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_83 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_82/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_36 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_82/truediv (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_84/truediv (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_84/mul (589.82k/589.82k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_84/mul_1 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_44 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_62 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_70 (589.82k/589.82k flops)\n",
      "  tower_0/gradients/AddN_66 (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_80/mul (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_60/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_34/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_37/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_84/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_72/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_70/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_64/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_82/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_80/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_74/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_78/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_58/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_62/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_40/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_28/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_68/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_31/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_66/Sum (589.82k/589.82k flops)\n",
      "  tower_0/clip_by_norm_24/Sum (589.82k/589.82k flops)\n",
      "  build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform (262.14k/524.29k flops)\n",
      "    build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform/mul (262.14k/262.14k flops)\n",
      "    build_pyramid/build_P4/reduce_dim_P4/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_52/mul (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_52/truediv (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_26/truediv (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_26/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_26/mul (524.29k/524.29k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_5/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_5/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_4/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_4/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_3/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_3/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_1/conv2/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_2/conv0/weights/Initializer/truncated_normal (262.14k/524.29k flops)\n",
      "    resnet50_v1d/C4/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_42/truediv (524.29k/524.29k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_82 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/mul (524.29k/524.29k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_47 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_52/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/mul_1 (524.29k/524.29k flops)\n",
      "  tower_0/gradients/AddN_60 (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_52/Sum (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_26/Sum (524.29k/524.29k flops)\n",
      "  tower_0/clip_by_norm_42/Sum (524.29k/524.29k flops)\n",
      "  rpn_net/rpn_regression/weights/Initializer/random_normal (241.92k/483.84k flops)\n",
      "    rpn_net/rpn_regression/weights/Initializer/random_normal/mul (241.92k/241.92k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_21 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_21/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_11 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_11/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_15 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_15/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_18 (147.46k/442.37k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/mul (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/sub_1 (147.46k/147.46k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_18/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/442.37k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (442.37k/442.37k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_13 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_13/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_23 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_23/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_56 (131.07k/393.22k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/mul (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/sub_1 (131.07k/131.07k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_56/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer (1/393.22k flops)\n",
      "    tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer/L2Loss (393.21k/393.21k flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv1/weights/Initializer/truncated_normal (147.46k/294.91k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv1/weights/Initializer/truncated_normal/mul (147.46k/147.46k flops)\n",
      "  build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform (131.07k/262.14k flops)\n",
      "    build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform/mul (131.07k/131.07k flops)\n",
      "    build_pyramid/build_P3/reduce_dim_P3/weights/Initializer/random_uniform/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_32/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_41/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_41/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_33/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_33/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_33/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_32/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_35/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_32/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_72 (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/shortcut/weights/Initializer/truncated_normal (131.07k/262.14k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_30/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_30/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_30/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_80 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_39/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_39/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_39/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_38/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_38/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_38/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_81 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_41/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_77 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_36/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_36/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_36/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_76 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_73 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_35/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_35/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_68 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_65 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_64 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_27/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_27/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_27/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/mul (262.14k/262.14k flops)\n",
      "  resnet50_v1d/C4/bottleneck_0/conv0/weights/Initializer/truncated_normal (131.07k/262.14k flops)\n",
      "    resnet50_v1d/C4/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_46 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_61 (262.14k/262.14k flops)\n",
      "  tower_0/gradients/AddN_69 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_54/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_54/mul_1 (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_54/truediv (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/truediv (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_33/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_30/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_54/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_39/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_38/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_25/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_36/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_27/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_32/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_35/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_29/Sum (262.14k/262.14k flops)\n",
      "  tower_0/clip_by_norm_41/Sum (262.14k/262.14k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_regression/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (241.92k/241.92k flops)\n",
      "  tower_0/clip_by_norm_86/mul (241.92k/241.92k flops)\n",
      "  tower_0/clip_by_norm_86/mul_1 (241.92k/241.92k flops)\n",
      "  tower_0/clip_by_norm_86/truediv (241.92k/241.92k flops)\n",
      "  tower_0/gradients/AddN_3 (241.92k/241.92k flops)\n",
      "  tower_0/clip_by_norm_86/Sum (241.92k/241.92k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_19 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_19/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_20 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_20/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_12 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_12/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_22 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_22/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_14 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_14/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_16 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_16/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_17 (65.54k/196.61k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/mul (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/sub_1 (65.54k/65.54k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_17/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/196.61k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (196.61k/196.61k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_18/truediv (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_18/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_18/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/truediv (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_100 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_15/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_15/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_21/truediv (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_21/mul (147.46k/147.46k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_15/truediv (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_95 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_91 (147.46k/147.46k flops)\n",
      "  tower_0/gradients/AddN_87 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_21/mul_1 (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_11/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_21/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_15/Sum (147.46k/147.46k flops)\n",
      "  tower_0/clip_by_norm_18/Sum (147.46k/147.46k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_76 (48.38k/145.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_76/mul (48.38k/48.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_76/sub_1 (48.38k/48.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_76/sub (1/1 flops)\n",
      "  tower_0/rpn_net/rpn_classification/kernel/Regularizer/l2_regularizer (1/145.15k flops)\n",
      "    tower_0/rpn_net/rpn_classification/kernel/Regularizer/l2_regularizer/L2Loss (145.15k/145.15k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_13/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_3/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_3/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_43 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_23/mul (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_23/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_23/truediv (131.07k/131.07k flops)\n",
      "  tower_0/gradients/AddN_85 (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_13/mul (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_2/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_56/truediv (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_56/mul_1 (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_13/truediv (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_56/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  tower_0/gradients/AddN_99 (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (131.07k/131.07k flops)\n",
      "  resnet50_v1d/C3/bottleneck_1/conv0/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv2/weights/Initializer/truncated_normal (65.54k/131.07k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_56/Sum (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_23/Sum (131.07k/131.07k flops)\n",
      "  tower_0/clip_by_norm_13/Sum (131.07k/131.07k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_1 (36.86k/110.59k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/mul (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/sub_1 (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_1/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_8 (36.86k/110.59k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/mul (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/sub_1 (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_8/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_5 (36.86k/110.59k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/mul (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/sub_1 (36.86k/36.86k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_5/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer (1/110.59k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (110.59k/110.59k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_10 (32.77k/98.31k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/mul (32.77k/32.77k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/sub_1 (32.77k/32.77k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_10/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/98.30k flops)\n",
      "    tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (98.30k/98.30k flops)\n",
      "  rpn_net/rpn_classification/weights/Initializer/random_normal (48.38k/96.77k flops)\n",
      "    rpn_net/rpn_classification/weights/Initializer/random_normal/mul (48.38k/48.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv1/weights/Initializer/truncated_normal (36.86k/73.73k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv1/weights/Initializer/truncated_normal/mul (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_16/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_22/truediv (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_12/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_14/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_14/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_14/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_16/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_20/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_22/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_16/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_22/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_17/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_17/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_17/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_20/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_19/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_19/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_19/truediv (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_20/mul_1 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_86 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_89 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_90 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_93 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_94 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_97 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/AddN_98 (65.54k/65.54k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  resnet50_v1d/C3/bottleneck_0/conv0/weights/Initializer/truncated_normal (32.77k/65.54k flops)\n",
      "    resnet50_v1d/C3/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (32.77k/32.77k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (65.54k/65.54k flops)\n",
      "  tower_0/clip_by_norm_20/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_19/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_17/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_16/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_22/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_14/Sum (65.53k/65.53k flops)\n",
      "  tower_0/clip_by_norm_12/Sum (65.53k/65.53k flops)\n",
      "  tower_0/resnet50_v1d/C1/conv2/kernel/Regularizer/l2_regularizer (1/55.30k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (55.30k/55.30k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_9 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_9/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_7 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_7/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_2 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_2/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_6 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_6/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_3 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_3/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_4 (16.38k/49.15k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/mul (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/sub_1 (16.38k/16.38k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_4/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer (1/49.15k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss (49.15k/49.15k flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_classification/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (48.38k/48.38k flops)\n",
      "  tower_0/clip_by_norm_76/truediv (48.38k/48.38k flops)\n",
      "  tower_0/clip_by_norm_76/mul_1 (48.38k/48.38k flops)\n",
      "  tower_0/clip_by_norm_76/mul (48.38k/48.38k flops)\n",
      "  tower_0/clip_by_norm_76/Sum (48.38k/48.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (36.86k/36.86k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (36.86k/36.86k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (36.86k/36.86k flops)\n",
      "  resnet50_v1d/C1/conv2/weights/Initializer/truncated_normal (18.43k/36.86k flops)\n",
      "    resnet50_v1d/C1/conv2/weights/Initializer/truncated_normal/mul (18.43k/18.43k flops)\n",
      "  tower_0/gradients/AddN_113 (36.86k/36.86k flops)\n",
      "  tower_0/gradients/AddN_108 (36.86k/36.86k flops)\n",
      "  tower_0/gradients/AddN_104 (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_8/mul (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_8/mul_1 (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_8/truediv (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_1/truediv (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_1/mul_1 (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_1/mul (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_5/truediv (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_5/mul_1 (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_5/mul (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_8/Sum (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_5/Sum (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_1/Sum (36.86k/36.86k flops)\n",
      "  tower_0/clip_by_norm_10/truediv (32.77k/32.77k flops)\n",
      "  tower_0/gradients/AddN_102 (32.77k/32.77k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/shortcut/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/shortcut/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv0/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv0/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_1/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_1/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv0/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv0/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  resnet50_v1d/C2/bottleneck_2/conv2/weights/Initializer/truncated_normal (16.38k/32.77k flops)\n",
      "    resnet50_v1d/C2/bottleneck_2/conv2/weights/Initializer/truncated_normal/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (32.77k/32.77k flops)\n",
      "  tower_0/clip_by_norm_10/mul (32.77k/32.77k flops)\n",
      "  tower_0/clip_by_norm_10/mul_1 (32.77k/32.77k flops)\n",
      "  tower_0/clip_by_norm_10/Sum (32.77k/32.77k flops)\n",
      "  tower_0/resnet50_v1d/C1/conv1/kernel/Regularizer/l2_regularizer (1/27.65k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv1/kernel/Regularizer/l2_regularizer/L2Loss (27.65k/27.65k flops)\n",
      "  resnet50_v1d/C1/conv1/weights/Initializer/truncated_normal (9.22k/18.43k flops)\n",
      "    resnet50_v1d/C1/conv1/weights/Initializer/truncated_normal/mul (9.22k/9.22k flops)\n",
      "  tower_0/clip_by_norm_9/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_2/truediv (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_2/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_2/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_106 (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_103 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_6/truediv (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_4/truediv (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_4/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_9/truediv (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_9/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_4/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_7/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_7/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_7/truediv (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_3/truediv (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_3/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_3/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_107 (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_6/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_6/mul_1 (16.38k/16.38k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_112 (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_110 (16.38k/16.38k flops)\n",
      "  tower_0/gradients/AddN_111 (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_4/Sum (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_6/Sum (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_7/Sum (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_9/Sum (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_2/Sum (16.38k/16.38k flops)\n",
      "  tower_0/clip_by_norm_3/Sum (16.38k/16.38k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg (4.10k/12.29k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/mul (4.10k/4.10k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/sub_1 (4.10k/4.10k flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg/sub (1/1 flops)\n",
      "  tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer (1/12.29k flops)\n",
      "    tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss (12.29k/12.29k flops)\n",
      "  resnet50_v1d/C2/bottleneck_0/conv0/weights/Initializer/truncated_normal (4.10k/8.19k flops)\n",
      "    resnet50_v1d/C2/bottleneck_0/conv0/weights/Initializer/truncated_normal/mul (4.10k/4.10k flops)\n",
      "  tower_0/clip_by_norm/mul_1 (4.10k/4.10k flops)\n",
      "  tower_0/clip_by_norm/mul (4.10k/4.10k flops)\n",
      "  tower_0/gradients/AddN_114 (4.10k/4.10k flops)\n",
      "  tower_0/clip_by_norm/truediv (4.10k/4.10k flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer/L2Loss_grad/mul (4.10k/4.10k flops)\n",
      "  tower_0/clip_by_norm/Sum (4.09k/4.09k flops)\n",
      "  tower_0/resnet50_v1d/C1/conv0/kernel/Regularizer/l2_regularizer (1/2.59k flops)\n",
      "    tower_0/resnet50_v1d/C1/conv0/kernel/Regularizer/l2_regularizer/L2Loss (2.59k/2.59k flops)\n",
      "  resnet50_v1d/C1/conv0/weights/Initializer/truncated_normal (864/1.73k flops)\n",
      "    resnet50_v1d/C1/conv0/weights/Initializer/truncated_normal/mul (864/864 flops)\n",
      "  tower_0/gradients/AddN_31 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_11 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_29 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_27 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_25 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_7 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_14 (1.02k/1.02k flops)\n",
      "  tower_0/gradients/AddN_9 (1.02k/1.02k flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_59 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_59/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_69 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_69/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_65 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_65/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_57 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_57/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_71 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_71/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_73 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_73/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_73/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_73/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_67 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_67/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_83 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_83/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_83/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_83/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_79 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_79/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_79/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_79/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_53 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_53/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_61 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_61/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_63 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_63/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_81 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_81/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_81/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_81/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_85 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_85/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_85/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_85/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_55 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_55/sub (1/1 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_75 (256/769 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_75/mul (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_75/sub_1 (256/256 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_75/sub (1/1 flops)\n",
      "  tower_0/gradients/AddN_23 (420/420 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_87 (105/316 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_87/mul (105/105 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_87/sub_1 (105/105 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_87/sub (1/1 flops)\n",
      "  Gradient_Mult/Mul_4 (256/256 flops)\n",
      "  Gradient_Mult/Mul_2 (256/256 flops)\n",
      "  Gradient_Mult/Mul_3 (256/256 flops)\n",
      "  tower_0/clip_by_norm_79/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_79/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_79/mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_5 (256/256 flops)\n",
      "  Gradient_Mult/Mul_6 (256/256 flops)\n",
      "  tower_0/clip_by_norm_85/mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_13 (256/256 flops)\n",
      "  Gradient_Mult/Mul_11 (256/256 flops)\n",
      "  Gradient_Mult/Mul_10 (256/256 flops)\n",
      "  Gradient_Mult/Mul_1 (256/256 flops)\n",
      "  Gradient_Mult/Mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_14 (256/256 flops)\n",
      "  Gradient_Mult/Mul_15 (256/256 flops)\n",
      "  tower_0/clip_by_norm_85/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_85/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_81/mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_16 (256/256 flops)\n",
      "  Gradient_Mult/Mul_9 (256/256 flops)\n",
      "  tower_0/clip_by_norm_83/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_83/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_83/mul (256/256 flops)\n",
      "  Gradient_Mult/Mul_8 (256/256 flops)\n",
      "  Gradient_Mult/Mul_7 (256/256 flops)\n",
      "  tower_0/clip_by_norm_81/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_81/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_73/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_75/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_75/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_71/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_65/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_65/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_71/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_67/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_71/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_69/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_73/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_73/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_69/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_55/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_67/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_67/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_63/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_57/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_61/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_61/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_61/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_59/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_75/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_63/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_63/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_59/mul_1 (256/256 flops)\n",
      "  tower_0/clip_by_norm_59/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_69/truediv (256/256 flops)\n",
      "  tower_0/clip_by_norm_65/mul (256/256 flops)\n",
      "  tower_0/clip_by_norm_53/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_85/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_57/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_71/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_55/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_69/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_73/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_83/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_67/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_75/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_81/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_65/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_59/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_63/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_61/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_79/Sum (255/255 flops)\n",
      "  tower_0/clip_by_norm_87/mul (105/105 flops)\n",
      "  tower_0/clip_by_norm_87/truediv (105/105 flops)\n",
      "  tower_0/clip_by_norm_87/mul_1 (105/105 flops)\n",
      "  Gradient_Mult/Mul_17 (105/105 flops)\n",
      "  tower_0/clip_by_norm_87/Sum (104/104 flops)\n",
      "  tower_0/gradients/AddN_2 (84/84 flops)\n",
      "  tower_0/AddN (72/72 flops)\n",
      "  ExponentialMovingAverage/AssignMovingAvg_77 (21/64 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_77/mul (21/21 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_77/sub_1 (21/21 flops)\n",
      "    ExponentialMovingAverage/AssignMovingAvg_77/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_77/mul (21/21 flops)\n",
      "  tower_0/clip_by_norm_77/mul_1 (21/21 flops)\n",
      "  Gradient_Mult/Mul_12 (21/21 flops)\n",
      "  tower_0/clip_by_norm_77/truediv (21/21 flops)\n",
      "  tower_0/clip_by_norm_77/Sum (20/20 flops)\n",
      "  tower_0/crop_to_bounding_box/assert_positive/assert_less/Less (4/4 flops)\n",
      "  cond/PiecewiseConstant/case/num_true_conds (3/3 flops)\n",
      "  get_batch/cond_2/flip_left_right/assert_positive/assert_less/Less (3/3 flops)\n",
      "  get_batch/cond_3/flip_up_down/assert_positive/assert_less/Less (3/3 flops)\n",
      "  get_batch/random_uniform (1/3 flops)\n",
      "    get_batch/random_uniform/mul (1/1 flops)\n",
      "    get_batch/random_uniform/sub (1/1 flops)\n",
      "  get_batch/random_uniform_1 (1/3 flops)\n",
      "    get_batch/random_uniform_1/mul (1/1 flops)\n",
      "    get_batch/random_uniform_1/sub (1/1 flops)\n",
      "  get_batch/random_uniform_2 (1/3 flops)\n",
      "    get_batch/random_uniform_2/mul (1/1 flops)\n",
      "    get_batch/random_uniform_2/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/truediv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/truediv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_2_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_regression/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_regression/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_classification/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_2_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/rpn_classification/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_1/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/shortcut/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/ones/Less (1/1 flops)\n",
      "  tower_0/ones_1/Less (1/1 flops)\n",
      "  tower_0/postprocess_detctions/Greater_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_2_grad/mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_4/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_2_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/truediv_2_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_2/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_1/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_cls_0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_5/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C4/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C5/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/truediv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv2/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv1/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/rpn_net/conv2d_3x3_reg_0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C3/bottleneck_3/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/clip_by_norm_33/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_3/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_3/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_30/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_30/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_31/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_31/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_32/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_32/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_29/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_33/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_34/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_34/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_35/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_35/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_36/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_36/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_37/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_29/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_28/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_28/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_27/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_27/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_26/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_26/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_25/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_25/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_24/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_24/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_23/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_23/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_22/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_22/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_44/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_50/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_50/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_5/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_5/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_49/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_49/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_48/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_48/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_47/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_47/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_46/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_46/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_45/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_45/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_44/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_21/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_43/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_43/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_42/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_42/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_41/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_41/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_40/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_40/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_4/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_4/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_39/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_39/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_38/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_38/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_37/Maximum (1/1 flops)\n",
      "  get_batch/input_producer/Greater (1/1 flops)\n",
      "  get_batch/Less_3 (1/1 flops)\n",
      "  get_batch/batch/mul (1/1 flops)\n",
      "  get_batch/cond_1/Less (1/1 flops)\n",
      "  get_batch/cond_1/Less_1 (1/1 flops)\n",
      "  get_batch/cond_1/mul (1/1 flops)\n",
      "  get_batch/cond_1/mul_1 (1/1 flops)\n",
      "  get_batch/cond_2/flip_left_right/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  get_batch/cond_3/flip_up_down/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  get_batch/Less_2 (1/1 flops)\n",
      "  get_batch/input_producer/mul (1/1 flops)\n",
      "  sub (1/1 flops)\n",
      "  sub_1 (1/1 flops)\n",
      "  tower_0/build_loss/Maximum (1/1 flops)\n",
      "  tower_0/build_loss/Maximum_1 (1/1 flops)\n",
      "  tower_0/build_loss/mul_43 (1/1 flops)\n",
      "  tower_0/build_loss/mul_44 (1/1 flops)\n",
      "  tower_0/build_loss/ones/Less (1/1 flops)\n",
      "  get_batch/Less_1 (1/1 flops)\n",
      "  get_batch/Less (1/1 flops)\n",
      "  cond/truediv (1/1 flops)\n",
      "  cond/mul (1/1 flops)\n",
      "  cond/PiecewiseConstant/case/LessEqual (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual_2 (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual_1 (1/1 flops)\n",
      "  cond/PiecewiseConstant/LessEqual (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater_2 (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater_1 (1/1 flops)\n",
      "  cond/PiecewiseConstant/Greater (1/1 flops)\n",
      "  Momentum (1/1 flops)\n",
      "  LessEqual (1/1 flops)\n",
      "  ExponentialMovingAverage/truediv (1/1 flops)\n",
      "  ExponentialMovingAverage/Minimum (1/1 flops)\n",
      "  tower_0/clip_by_norm_14/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_21/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_20/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_20/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_2/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_2/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_19/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_19/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_18/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_18/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_17/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_17/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_16/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_16/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_15/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_15/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_51/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_14/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_13/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_13/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_12/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_12/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_11/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_11/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_10/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_10/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_1/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_1/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm/Greater (1/1 flops)\n",
      "  tower_0/build_loss/truediv_10 (1/1 flops)\n",
      "  tower_0/build_loss/truediv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/Pow_6_grad/sub (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/Greater (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/GreaterEqual (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/GreaterEqual_1 (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/Greater_1 (1/1 flops)\n",
      "  tower_0/crop_to_bounding_box/assert_greater_equal/GreaterEqual (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/Pow_3_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/Pow_4_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/Pow_5_grad/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_9/Maximum (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/Pow_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/mul_43_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/mul_43_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/mul_44_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/mul_44_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_13_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_14_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_15_grad/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_9/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_87/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_87/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_86/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_86/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_85/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_85/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_84/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_84/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_83/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_83/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_82/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_82/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_81/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_81/Greater (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p7_conv/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p7_conv/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p6_conv/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/p6_conv/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P5/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P4/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/fuse_P3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P5/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P4/reduce_dim_P4/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/clip_by_norm_80/Maximum (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_pyramid/build_P3/reduce_dim_P3/kernel/Regularizer/l2_regularizer_grad/Mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_grad/mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_10_grad/mul (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_10_grad/RealDiv_2 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_10_grad/RealDiv_1 (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_10_grad/RealDiv (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/truediv_10_grad/Neg (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_2_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_1_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_18_grad/sub (1/1 flops)\n",
      "  tower_0/gradients/tower_0/build_loss/pow_16_grad/sub (1/1 flops)\n",
      "  tower_0/clip_by_norm_62/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_59/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_6/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_6/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_60/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_60/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_61/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_61/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_62/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_59/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_63/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_63/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_64/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_64/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_65/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_65/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_66/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_66/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_58/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_58/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_57/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_57/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_56/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_56/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_55/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_55/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_54/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_54/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_53/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_53/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_52/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_52/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_51/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_73/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_80/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_8/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_8/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_79/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_79/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_78/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_78/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_77/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_77/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_76/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_76/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_75/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_75/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_74/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_74/Greater (1/1 flops)\n",
      "  tower_0/gradients/tower_0/resnet50_v1d/C2/bottleneck_0/conv0/kernel/Regularizer/l2_regularizer_grad/Mul_1 (1/1 flops)\n",
      "  tower_0/clip_by_norm_73/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_72/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_72/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_71/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_71/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_70/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_70/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_7/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_7/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_69/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_69/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_68/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_68/Greater (1/1 flops)\n",
      "  tower_0/clip_by_norm_67/Maximum (1/1 flops)\n",
      "  tower_0/clip_by_norm_67/Greater (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "1108 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/32.33m params)\n",
      "  build_pyramid (--/3.87m params)\n",
      "    build_pyramid/build_P3 (--/131.33k params)\n",
      "      build_pyramid/build_P3/reduce_dim_P3 (--/131.33k params)\n",
      "        build_pyramid/build_P3/reduce_dim_P3/biases (256, 256/256 params)\n",
      "        build_pyramid/build_P3/reduce_dim_P3/weights (1x1x512x256, 131.07k/131.07k params)\n",
      "    build_pyramid/build_P4 (--/262.40k params)\n",
      "      build_pyramid/build_P4/reduce_dim_P4 (--/262.40k params)\n",
      "        build_pyramid/build_P4/reduce_dim_P4/biases (256, 256/256 params)\n",
      "        build_pyramid/build_P4/reduce_dim_P4/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "    build_pyramid/build_P5 (--/524.54k params)\n",
      "      build_pyramid/build_P5/biases (256, 256/256 params)\n",
      "      build_pyramid/build_P5/weights (1x1x2048x256, 524.29k/524.29k params)\n",
      "    build_pyramid/fuse_P3 (--/590.08k params)\n",
      "      build_pyramid/fuse_P3/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/fuse_P4 (--/590.08k params)\n",
      "      build_pyramid/fuse_P4/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P4/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/fuse_P5 (--/590.08k params)\n",
      "      build_pyramid/fuse_P5/biases (256, 256/256 params)\n",
      "      build_pyramid/fuse_P5/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/p6_conv (--/590.08k params)\n",
      "      build_pyramid/p6_conv/biases (256, 256/256 params)\n",
      "      build_pyramid/p6_conv/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    build_pyramid/p7_conv (--/590.08k params)\n",
      "      build_pyramid/p7_conv/biases (256, 256/256 params)\n",
      "      build_pyramid/p7_conv/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "  resnet50_v1d (--/23.45m params)\n",
      "    resnet50_v1d/C2 (--/212.99k params)\n",
      "      resnet50_v1d/C2/bottleneck_0 (--/73.73k params)\n",
      "        resnet50_v1d/C2/bottleneck_0/conv0 (--/4.10k params)\n",
      "          resnet50_v1d/C2/bottleneck_0/conv0/weights (1x1x64x64, 4.10k/4.10k params)\n",
      "        resnet50_v1d/C2/bottleneck_0/conv1 (--/36.86k params)\n",
      "          resnet50_v1d/C2/bottleneck_0/conv1/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        resnet50_v1d/C2/bottleneck_0/conv2 (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_0/conv2/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "        resnet50_v1d/C2/bottleneck_0/shortcut (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_0/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "      resnet50_v1d/C2/bottleneck_1 (--/69.63k params)\n",
      "        resnet50_v1d/C2/bottleneck_1/conv0 (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_1/conv0/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "        resnet50_v1d/C2/bottleneck_1/conv1 (--/36.86k params)\n",
      "          resnet50_v1d/C2/bottleneck_1/conv1/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        resnet50_v1d/C2/bottleneck_1/conv2 (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_1/conv2/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "      resnet50_v1d/C2/bottleneck_2 (--/69.63k params)\n",
      "        resnet50_v1d/C2/bottleneck_2/conv0 (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_2/conv0/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "        resnet50_v1d/C2/bottleneck_2/conv1 (--/36.86k params)\n",
      "          resnet50_v1d/C2/bottleneck_2/conv1/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        resnet50_v1d/C2/bottleneck_2/conv2 (--/16.38k params)\n",
      "          resnet50_v1d/C2/bottleneck_2/conv2/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "    resnet50_v1d/C3 (--/1.21m params)\n",
      "      resnet50_v1d/C3/bottleneck_0 (--/376.83k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv0 (--/32.77k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv0/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_0/shortcut (--/131.07k params)\n",
      "          resnet50_v1d/C3/bottleneck_0/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      resnet50_v1d/C3/bottleneck_1 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_1/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_1/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "      resnet50_v1d/C3/bottleneck_2 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_2/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_2/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "      resnet50_v1d/C3/bottleneck_3 (--/278.53k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv0 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv0/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv1 (--/147.46k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv1/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        resnet50_v1d/C3/bottleneck_3/conv2 (--/65.54k params)\n",
      "          resnet50_v1d/C3/bottleneck_3/conv2/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "    resnet50_v1d/C4 (--/7.08m params)\n",
      "      resnet50_v1d/C4/bottleneck_0 (--/1.51m params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv0 (--/131.07k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv0/weights (1x1x512x256, 131.07k/131.07k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_0/shortcut (--/524.29k params)\n",
      "          resnet50_v1d/C4/bottleneck_0/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "      resnet50_v1d/C4/bottleneck_1 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_1/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_1/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_2 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_2/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_2/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_3 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_3/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_3/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_4 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_4/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_4/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      resnet50_v1d/C4/bottleneck_5 (--/1.11m params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv0 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv0/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv1 (--/589.82k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "        resnet50_v1d/C4/bottleneck_5/conv2 (--/262.14k params)\n",
      "          resnet50_v1d/C4/bottleneck_5/conv2/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "    resnet50_v1d/C5 (--/14.94m params)\n",
      "      resnet50_v1d/C5/bottleneck_0 (--/6.03m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv0 (--/524.29k params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv0/weights (1x1x1024x512, 524.29k/524.29k params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_0/shortcut (--/2.10m params)\n",
      "          resnet50_v1d/C5/bottleneck_0/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
      "      resnet50_v1d/C5/bottleneck_1 (--/4.46m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv0 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv0/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_1/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_1/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "      resnet50_v1d/C5/bottleneck_2 (--/4.46m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv0 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv0/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv1 (--/2.36m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv1/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "        resnet50_v1d/C5/bottleneck_2/conv2 (--/1.05m params)\n",
      "          resnet50_v1d/C5/bottleneck_2/conv2/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "  rpn_net (--/5.01m params)\n",
      "    rpn_net/conv2d_3x3_cls_0 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_cls_0/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_cls_0/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_cls_1 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_cls_1/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_cls_1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_cls_2 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_cls_2/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_cls_2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_cls_3 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_cls_3/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_cls_3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_reg_0 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_reg_0/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_reg_0/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_reg_1 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_reg_1/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_reg_1/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_reg_2 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_reg_2/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_reg_2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/conv2d_3x3_reg_3 (--/590.08k params)\n",
      "      rpn_net/conv2d_3x3_reg_3/biases (256, 256/256 params)\n",
      "      rpn_net/conv2d_3x3_reg_3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "    rpn_net/rpn_classification (--/48.41k params)\n",
      "      rpn_net/rpn_classification/biases (21, 21/21 params)\n",
      "      rpn_net/rpn_classification/weights (3x3x256x21, 48.38k/48.38k params)\n",
      "    rpn_net/rpn_regression (--/242.03k params)\n",
      "      rpn_net/rpn_regression/biases (105, 105/105 params)\n",
      "      rpn_net/rpn_regression/weights (3x3x256x105, 241.92k/241.92k params)\n",
      "\n",
      "======================End of Report==========================\n",
      "FLOPs: 472715447;    Trainable params: 32325246\n",
      "2021-06-01 17:23:15.258659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-01 17:23:16.305513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "************************************************************************\n",
      "2021-06-01 17:23:26: global_step:65019  current_step:20\n",
      "speed: 4.443s, remaining training time: 03:08:11:21\n",
      "total_losses:0.905\n",
      "cls_loss:0.241\n",
      "reg_loss:0.664\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:33: global_step:65039  current_step:40\n",
      "speed: 0.169s, remaining training time: 00:03:03:09\n",
      "total_losses:0.496\n",
      "cls_loss:0.076\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:36: global_step:65059  current_step:60\n",
      "speed: 0.158s, remaining training time: 00:02:51:17\n",
      "total_losses:0.752\n",
      "cls_loss:0.125\n",
      "reg_loss:0.627\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:40: global_step:65079  current_step:80\n",
      "speed: 0.156s, remaining training time: 00:02:48:27\n",
      "total_losses:0.532\n",
      "cls_loss:0.055\n",
      "reg_loss:0.477\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:43: global_step:65099  current_step:100\n",
      "speed: 0.173s, remaining training time: 00:03:07:12\n",
      "total_losses:0.687\n",
      "cls_loss:0.195\n",
      "reg_loss:0.492\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:46: global_step:65119  current_step:120\n",
      "speed: 0.183s, remaining training time: 00:03:17:43\n",
      "total_losses:0.668\n",
      "cls_loss:0.184\n",
      "reg_loss:0.485\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:50: global_step:65139  current_step:140\n",
      "speed: 0.169s, remaining training time: 00:03:02:55\n",
      "total_losses:0.752\n",
      "cls_loss:0.219\n",
      "reg_loss:0.533\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:53: global_step:65159  current_step:160\n",
      "speed: 0.161s, remaining training time: 00:02:53:55\n",
      "total_losses:0.396\n",
      "cls_loss:0.039\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:23:56: global_step:65179  current_step:180\n",
      "speed: 0.168s, remaining training time: 00:03:01:52\n",
      "total_losses:0.822\n",
      "cls_loss:0.231\n",
      "reg_loss:0.591\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:03: global_step:65219  current_step:220\n",
      "speed: 0.157s, remaining training time: 00:02:49:49\n",
      "total_losses:0.524\n",
      "cls_loss:0.043\n",
      "reg_loss:0.481\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:06: global_step:65239  current_step:240\n",
      "speed: 0.170s, remaining training time: 00:03:03:15\n",
      "total_losses:0.588\n",
      "cls_loss:0.098\n",
      "reg_loss:0.491\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:10: global_step:65259  current_step:260\n",
      "speed: 0.163s, remaining training time: 00:02:55:37\n",
      "total_losses:0.779\n",
      "cls_loss:0.249\n",
      "reg_loss:0.531\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:13: global_step:65279  current_step:280\n",
      "speed: 0.177s, remaining training time: 00:03:10:24\n",
      "total_losses:0.656\n",
      "cls_loss:0.163\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:16: global_step:65299  current_step:300\n",
      "speed: 0.152s, remaining training time: 00:02:43:40\n",
      "total_losses:0.973\n",
      "cls_loss:0.517\n",
      "reg_loss:0.456\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:20: global_step:65319  current_step:320\n",
      "speed: 0.158s, remaining training time: 00:02:50:30\n",
      "total_losses:0.637\n",
      "cls_loss:0.201\n",
      "reg_loss:0.436\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:23: global_step:65339  current_step:340\n",
      "speed: 0.176s, remaining training time: 00:03:09:10\n",
      "total_losses:0.761\n",
      "cls_loss:0.381\n",
      "reg_loss:0.380\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:26: global_step:65359  current_step:360\n",
      "speed: 0.172s, remaining training time: 00:03:05:42\n",
      "total_losses:0.882\n",
      "cls_loss:0.367\n",
      "reg_loss:0.515\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:30: global_step:65379  current_step:380\n",
      "speed: 0.176s, remaining training time: 00:03:09:35\n",
      "total_losses:0.682\n",
      "cls_loss:0.083\n",
      "reg_loss:0.599\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:36: global_step:65419  current_step:420\n",
      "speed: 0.178s, remaining training time: 00:03:11:50\n",
      "total_losses:0.569\n",
      "cls_loss:0.161\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:40: global_step:65439  current_step:440\n",
      "speed: 0.168s, remaining training time: 00:03:00:24\n",
      "total_losses:0.665\n",
      "cls_loss:0.168\n",
      "reg_loss:0.497\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:43: global_step:65459  current_step:460\n",
      "speed: 0.186s, remaining training time: 00:03:19:34\n",
      "total_losses:0.504\n",
      "cls_loss:0.132\n",
      "reg_loss:0.372\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:47: global_step:65479  current_step:480\n",
      "speed: 0.162s, remaining training time: 00:02:53:45\n",
      "total_losses:0.471\n",
      "cls_loss:0.020\n",
      "reg_loss:0.451\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:50: global_step:65499  current_step:500\n",
      "speed: 0.157s, remaining training time: 00:02:48:52\n",
      "total_losses:0.376\n",
      "cls_loss:0.055\n",
      "reg_loss:0.320\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:53: global_step:65519  current_step:520\n",
      "speed: 0.168s, remaining training time: 00:03:00:42\n",
      "total_losses:0.744\n",
      "cls_loss:0.251\n",
      "reg_loss:0.494\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:24:57: global_step:65539  current_step:540\n",
      "speed: 0.173s, remaining training time: 00:03:06:23\n",
      "total_losses:0.807\n",
      "cls_loss:0.113\n",
      "reg_loss:0.694\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:00: global_step:65559  current_step:560\n",
      "speed: 0.161s, remaining training time: 00:02:52:51\n",
      "total_losses:0.670\n",
      "cls_loss:0.184\n",
      "reg_loss:0.487\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:03: global_step:65579  current_step:580\n",
      "speed: 0.176s, remaining training time: 00:03:09:25\n",
      "total_losses:0.501\n",
      "cls_loss:0.088\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:10: global_step:65619  current_step:620\n",
      "speed: 0.168s, remaining training time: 00:03:00:21\n",
      "total_losses:0.711\n",
      "cls_loss:0.210\n",
      "reg_loss:0.501\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:14: global_step:65639  current_step:640\n",
      "speed: 0.150s, remaining training time: 00:02:41:14\n",
      "total_losses:0.910\n",
      "cls_loss:0.473\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:17: global_step:65659  current_step:660\n",
      "speed: 0.154s, remaining training time: 00:02:45:01\n",
      "total_losses:0.554\n",
      "cls_loss:0.145\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:20: global_step:65679  current_step:680\n",
      "speed: 0.174s, remaining training time: 00:03:06:49\n",
      "total_losses:0.806\n",
      "cls_loss:0.261\n",
      "reg_loss:0.545\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:23: global_step:65699  current_step:700\n",
      "speed: 0.153s, remaining training time: 00:02:43:43\n",
      "total_losses:0.962\n",
      "cls_loss:0.172\n",
      "reg_loss:0.790\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:27: global_step:65719  current_step:720\n",
      "speed: 0.155s, remaining training time: 00:02:45:33\n",
      "total_losses:0.526\n",
      "cls_loss:0.104\n",
      "reg_loss:0.422\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:30: global_step:65739  current_step:740\n",
      "speed: 0.163s, remaining training time: 00:02:54:48\n",
      "total_losses:0.572\n",
      "cls_loss:0.164\n",
      "reg_loss:0.408\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:34: global_step:65759  current_step:760\n",
      "speed: 0.171s, remaining training time: 00:03:02:46\n",
      "total_losses:0.457\n",
      "cls_loss:0.110\n",
      "reg_loss:0.347\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:37: global_step:65779  current_step:780\n",
      "speed: 0.173s, remaining training time: 00:03:04:54\n",
      "total_losses:0.732\n",
      "cls_loss:0.202\n",
      "reg_loss:0.531\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:44: global_step:65819  current_step:820\n",
      "speed: 0.164s, remaining training time: 00:02:55:15\n",
      "total_losses:0.426\n",
      "cls_loss:0.171\n",
      "reg_loss:0.255\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:47: global_step:65839  current_step:840\n",
      "speed: 0.161s, remaining training time: 00:02:51:57\n",
      "total_losses:0.431\n",
      "cls_loss:0.076\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:50: global_step:65859  current_step:860\n",
      "speed: 0.155s, remaining training time: 00:02:45:19\n",
      "total_losses:0.526\n",
      "cls_loss:0.028\n",
      "reg_loss:0.498\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:54: global_step:65879  current_step:880\n",
      "speed: 0.169s, remaining training time: 00:03:00:10\n",
      "total_losses:0.504\n",
      "cls_loss:0.140\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:25:57: global_step:65899  current_step:900\n",
      "speed: 0.163s, remaining training time: 00:02:54:34\n",
      "total_losses:0.392\n",
      "cls_loss:0.049\n",
      "reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:00: global_step:65919  current_step:920\n",
      "speed: 0.165s, remaining training time: 00:02:56:39\n",
      "total_losses:0.534\n",
      "cls_loss:0.165\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:04: global_step:65939  current_step:940\n",
      "speed: 0.158s, remaining training time: 00:02:48:47\n",
      "total_losses:0.423\n",
      "cls_loss:0.062\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:07: global_step:65959  current_step:960\n",
      "speed: 0.168s, remaining training time: 00:02:59:07\n",
      "total_losses:0.727\n",
      "cls_loss:0.134\n",
      "reg_loss:0.593\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:10: global_step:65979  current_step:980\n",
      "speed: 0.168s, remaining training time: 00:02:58:47\n",
      "total_losses:0.744\n",
      "cls_loss:0.331\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:17: global_step:66019  current_step:1020\n",
      "speed: 0.163s, remaining training time: 00:02:53:41\n",
      "total_losses:0.483\n",
      "cls_loss:0.131\n",
      "reg_loss:0.352\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:21: global_step:66039  current_step:1040\n",
      "speed: 0.165s, remaining training time: 00:02:55:58\n",
      "total_losses:0.651\n",
      "cls_loss:0.091\n",
      "reg_loss:0.560\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:24: global_step:66059  current_step:1060\n",
      "speed: 0.179s, remaining training time: 00:03:10:37\n",
      "total_losses:0.493\n",
      "cls_loss:0.088\n",
      "reg_loss:0.405\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:27: global_step:66079  current_step:1080\n",
      "speed: 0.166s, remaining training time: 00:02:57:19\n",
      "total_losses:0.513\n",
      "cls_loss:0.070\n",
      "reg_loss:0.442\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:31: global_step:66099  current_step:1100\n",
      "speed: 0.163s, remaining training time: 00:02:53:24\n",
      "total_losses:0.827\n",
      "cls_loss:0.295\n",
      "reg_loss:0.532\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:34: global_step:66119  current_step:1120\n",
      "speed: 0.164s, remaining training time: 00:02:55:00\n",
      "total_losses:0.417\n",
      "cls_loss:0.049\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:38: global_step:66139  current_step:1140\n",
      "speed: 0.162s, remaining training time: 00:02:52:51\n",
      "total_losses:0.409\n",
      "cls_loss:0.047\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:41: global_step:66159  current_step:1160\n",
      "speed: 0.173s, remaining training time: 00:03:04:26\n",
      "total_losses:0.378\n",
      "cls_loss:0.044\n",
      "reg_loss:0.334\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:44: global_step:66179  current_step:1180\n",
      "speed: 0.171s, remaining training time: 00:03:01:49\n",
      "total_losses:0.597\n",
      "cls_loss:0.106\n",
      "reg_loss:0.490\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:51: global_step:66219  current_step:1220\n",
      "speed: 0.163s, remaining training time: 00:02:53:39\n",
      "total_losses:0.367\n",
      "cls_loss:0.052\n",
      "reg_loss:0.315\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:54: global_step:66239  current_step:1240\n",
      "speed: 0.164s, remaining training time: 00:02:54:11\n",
      "total_losses:0.513\n",
      "cls_loss:0.043\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:26:58: global_step:66259  current_step:1260\n",
      "speed: 0.155s, remaining training time: 00:02:44:49\n",
      "total_losses:0.439\n",
      "cls_loss:0.082\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:01: global_step:66279  current_step:1280\n",
      "speed: 0.159s, remaining training time: 00:02:49:13\n",
      "total_losses:0.583\n",
      "cls_loss:0.071\n",
      "reg_loss:0.512\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:04: global_step:66299  current_step:1300\n",
      "speed: 0.157s, remaining training time: 00:02:46:16\n",
      "total_losses:0.705\n",
      "cls_loss:0.256\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:08: global_step:66319  current_step:1320\n",
      "speed: 0.176s, remaining training time: 00:03:07:01\n",
      "total_losses:0.570\n",
      "cls_loss:0.121\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:11: global_step:66339  current_step:1340\n",
      "speed: 0.142s, remaining training time: 00:02:30:35\n",
      "total_losses:0.864\n",
      "cls_loss:0.314\n",
      "reg_loss:0.549\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:14: global_step:66359  current_step:1360\n",
      "speed: 0.161s, remaining training time: 00:02:50:44\n",
      "total_losses:0.485\n",
      "cls_loss:0.066\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:18: global_step:66379  current_step:1380\n",
      "speed: 0.180s, remaining training time: 00:03:10:30\n",
      "total_losses:0.665\n",
      "cls_loss:0.177\n",
      "reg_loss:0.488\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:25: global_step:66419  current_step:1420\n",
      "speed: 0.145s, remaining training time: 00:02:34:06\n",
      "total_losses:0.479\n",
      "cls_loss:0.052\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:28: global_step:66439  current_step:1440\n",
      "speed: 0.153s, remaining training time: 00:02:41:36\n",
      "total_losses:0.796\n",
      "cls_loss:0.331\n",
      "reg_loss:0.464\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:31: global_step:66459  current_step:1460\n",
      "speed: 0.162s, remaining training time: 00:02:51:23\n",
      "total_losses:0.353\n",
      "cls_loss:0.036\n",
      "reg_loss:0.316\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:34: global_step:66479  current_step:1480\n",
      "speed: 0.169s, remaining training time: 00:02:59:05\n",
      "total_losses:1.091\n",
      "cls_loss:0.462\n",
      "reg_loss:0.629\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:38: global_step:66499  current_step:1500\n",
      "speed: 0.174s, remaining training time: 00:03:04:30\n",
      "total_losses:1.364\n",
      "cls_loss:0.613\n",
      "reg_loss:0.751\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:41: global_step:66519  current_step:1520\n",
      "speed: 0.172s, remaining training time: 00:03:01:48\n",
      "total_losses:0.589\n",
      "cls_loss:0.143\n",
      "reg_loss:0.446\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:44: global_step:66539  current_step:1540\n",
      "speed: 0.162s, remaining training time: 00:02:50:52\n",
      "total_losses:0.527\n",
      "cls_loss:0.070\n",
      "reg_loss:0.458\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:48: global_step:66559  current_step:1560\n",
      "speed: 0.164s, remaining training time: 00:02:53:34\n",
      "total_losses:0.695\n",
      "cls_loss:0.092\n",
      "reg_loss:0.603\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:51: global_step:66579  current_step:1580\n",
      "speed: 0.172s, remaining training time: 00:03:02:09\n",
      "total_losses:0.650\n",
      "cls_loss:0.129\n",
      "reg_loss:0.521\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:27:58: global_step:66619  current_step:1620\n",
      "speed: 0.176s, remaining training time: 00:03:06:19\n",
      "total_losses:1.155\n",
      "cls_loss:0.521\n",
      "reg_loss:0.634\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:01: global_step:66639  current_step:1640\n",
      "speed: 0.153s, remaining training time: 00:02:41:36\n",
      "total_losses:0.445\n",
      "cls_loss:0.026\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:05: global_step:66659  current_step:1660\n",
      "speed: 0.157s, remaining training time: 00:02:46:15\n",
      "total_losses:0.365\n",
      "cls_loss:0.067\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:08: global_step:66679  current_step:1680\n",
      "speed: 0.151s, remaining training time: 00:02:39:36\n",
      "total_losses:0.496\n",
      "cls_loss:0.136\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:11: global_step:66699  current_step:1700\n",
      "speed: 0.163s, remaining training time: 00:02:51:45\n",
      "total_losses:0.503\n",
      "cls_loss:0.148\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:15: global_step:66719  current_step:1720\n",
      "speed: 0.155s, remaining training time: 00:02:43:26\n",
      "total_losses:0.471\n",
      "cls_loss:0.067\n",
      "reg_loss:0.404\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:18: global_step:66739  current_step:1740\n",
      "speed: 0.152s, remaining training time: 00:02:40:23\n",
      "total_losses:0.526\n",
      "cls_loss:0.138\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:21: global_step:66759  current_step:1760\n",
      "speed: 0.172s, remaining training time: 00:03:01:11\n",
      "total_losses:0.652\n",
      "cls_loss:0.081\n",
      "reg_loss:0.571\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:25: global_step:66779  current_step:1780\n",
      "speed: 0.181s, remaining training time: 00:03:11:10\n",
      "total_losses:0.515\n",
      "cls_loss:0.137\n",
      "reg_loss:0.378\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:32: global_step:66819  current_step:1820\n",
      "speed: 0.165s, remaining training time: 00:02:53:36\n",
      "total_losses:0.494\n",
      "cls_loss:0.130\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:35: global_step:66839  current_step:1840\n",
      "speed: 0.163s, remaining training time: 00:02:51:59\n",
      "total_losses:0.618\n",
      "cls_loss:0.191\n",
      "reg_loss:0.427\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:38: global_step:66859  current_step:1860\n",
      "speed: 0.161s, remaining training time: 00:02:49:30\n",
      "total_losses:0.346\n",
      "cls_loss:0.023\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:42: global_step:66879  current_step:1880\n",
      "speed: 0.170s, remaining training time: 00:02:59:19\n",
      "total_losses:0.854\n",
      "cls_loss:0.341\n",
      "reg_loss:0.513\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:45: global_step:66899  current_step:1900\n",
      "speed: 0.150s, remaining training time: 00:02:37:47\n",
      "total_losses:0.482\n",
      "cls_loss:0.133\n",
      "reg_loss:0.349\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:48: global_step:66919  current_step:1920\n",
      "speed: 0.160s, remaining training time: 00:02:48:44\n",
      "total_losses:0.389\n",
      "cls_loss:0.091\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:51: global_step:66939  current_step:1940\n",
      "speed: 0.155s, remaining training time: 00:02:42:46\n",
      "total_losses:0.530\n",
      "cls_loss:0.025\n",
      "reg_loss:0.505\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:55: global_step:66959  current_step:1960\n",
      "speed: 0.157s, remaining training time: 00:02:45:14\n",
      "total_losses:0.690\n",
      "cls_loss:0.180\n",
      "reg_loss:0.510\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:28:58: global_step:66979  current_step:1980\n",
      "speed: 0.155s, remaining training time: 00:02:43:06\n",
      "total_losses:0.025\n",
      "cls_loss:0.025\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:05: global_step:67019  current_step:2020\n",
      "speed: 0.161s, remaining training time: 00:02:48:44\n",
      "total_losses:0.758\n",
      "cls_loss:0.136\n",
      "reg_loss:0.622\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:08: global_step:67039  current_step:2040\n",
      "speed: 0.171s, remaining training time: 00:02:59:24\n",
      "total_losses:0.564\n",
      "cls_loss:0.104\n",
      "reg_loss:0.460\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:11: global_step:67059  current_step:2060\n",
      "speed: 0.160s, remaining training time: 00:02:47:57\n",
      "total_losses:0.301\n",
      "cls_loss:0.016\n",
      "reg_loss:0.285\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:15: global_step:67079  current_step:2080\n",
      "speed: 0.154s, remaining training time: 00:02:41:23\n",
      "total_losses:0.017\n",
      "cls_loss:0.017\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:18: global_step:67099  current_step:2100\n",
      "speed: 0.162s, remaining training time: 00:02:49:35\n",
      "total_losses:0.390\n",
      "cls_loss:0.049\n",
      "reg_loss:0.341\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:21: global_step:67119  current_step:2120\n",
      "speed: 0.163s, remaining training time: 00:02:50:40\n",
      "total_losses:0.758\n",
      "cls_loss:0.249\n",
      "reg_loss:0.509\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:25: global_step:67139  current_step:2140\n",
      "speed: 0.175s, remaining training time: 00:03:03:07\n",
      "total_losses:0.624\n",
      "cls_loss:0.192\n",
      "reg_loss:0.433\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:28: global_step:67159  current_step:2160\n",
      "speed: 0.157s, remaining training time: 00:02:44:15\n",
      "total_losses:0.926\n",
      "cls_loss:0.175\n",
      "reg_loss:0.751\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:31: global_step:67179  current_step:2180\n",
      "speed: 0.162s, remaining training time: 00:02:50:02\n",
      "total_losses:0.864\n",
      "cls_loss:0.214\n",
      "reg_loss:0.649\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:38: global_step:67219  current_step:2220\n",
      "speed: 0.169s, remaining training time: 00:02:56:44\n",
      "total_losses:0.362\n",
      "cls_loss:0.069\n",
      "reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:42: global_step:67239  current_step:2240\n",
      "speed: 0.171s, remaining training time: 00:02:58:46\n",
      "total_losses:0.436\n",
      "cls_loss:0.051\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:45: global_step:67259  current_step:2260\n",
      "speed: 0.176s, remaining training time: 00:03:04:18\n",
      "total_losses:0.704\n",
      "cls_loss:0.178\n",
      "reg_loss:0.526\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:48: global_step:67279  current_step:2280\n",
      "speed: 0.153s, remaining training time: 00:02:40:01\n",
      "total_losses:0.338\n",
      "cls_loss:0.019\n",
      "reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:52: global_step:67299  current_step:2300\n",
      "speed: 0.152s, remaining training time: 00:02:38:21\n",
      "total_losses:0.347\n",
      "cls_loss:0.024\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:55: global_step:67319  current_step:2320\n",
      "speed: 0.163s, remaining training time: 00:02:50:27\n",
      "total_losses:0.279\n",
      "cls_loss:0.020\n",
      "reg_loss:0.259\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:29:58: global_step:67339  current_step:2340\n",
      "speed: 0.156s, remaining training time: 00:02:42:44\n",
      "total_losses:0.466\n",
      "cls_loss:0.122\n",
      "reg_loss:0.345\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:02: global_step:67359  current_step:2360\n",
      "speed: 0.168s, remaining training time: 00:02:55:44\n",
      "total_losses:0.374\n",
      "cls_loss:0.036\n",
      "reg_loss:0.338\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:05: global_step:67379  current_step:2380\n",
      "speed: 0.157s, remaining training time: 00:02:43:20\n",
      "total_losses:0.396\n",
      "cls_loss:0.058\n",
      "reg_loss:0.338\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:12: global_step:67419  current_step:2420\n",
      "speed: 0.169s, remaining training time: 00:02:56:24\n",
      "total_losses:0.679\n",
      "cls_loss:0.231\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:15: global_step:67439  current_step:2440\n",
      "speed: 0.163s, remaining training time: 00:02:50:06\n",
      "total_losses:0.577\n",
      "cls_loss:0.136\n",
      "reg_loss:0.440\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:19: global_step:67459  current_step:2460\n",
      "speed: 0.158s, remaining training time: 00:02:44:57\n",
      "total_losses:0.432\n",
      "cls_loss:0.046\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:22: global_step:67479  current_step:2480\n",
      "speed: 0.145s, remaining training time: 00:02:31:20\n",
      "total_losses:0.656\n",
      "cls_loss:0.101\n",
      "reg_loss:0.555\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:25: global_step:67499  current_step:2500\n",
      "speed: 0.162s, remaining training time: 00:02:49:15\n",
      "total_losses:0.557\n",
      "cls_loss:0.073\n",
      "reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:28: global_step:67519  current_step:2520\n",
      "speed: 0.169s, remaining training time: 00:02:56:01\n",
      "total_losses:0.076\n",
      "cls_loss:0.076\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:32: global_step:67539  current_step:2540\n",
      "speed: 0.168s, remaining training time: 00:02:55:17\n",
      "total_losses:0.614\n",
      "cls_loss:0.136\n",
      "reg_loss:0.478\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:35: global_step:67559  current_step:2560\n",
      "speed: 0.164s, remaining training time: 00:02:50:54\n",
      "total_losses:0.446\n",
      "cls_loss:0.096\n",
      "reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:38: global_step:67579  current_step:2580\n",
      "speed: 0.168s, remaining training time: 00:02:54:47\n",
      "total_losses:0.598\n",
      "cls_loss:0.063\n",
      "reg_loss:0.535\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:45: global_step:67619  current_step:2620\n",
      "speed: 0.176s, remaining training time: 00:03:02:42\n",
      "total_losses:0.569\n",
      "cls_loss:0.141\n",
      "reg_loss:0.427\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:49: global_step:67639  current_step:2640\n",
      "speed: 0.159s, remaining training time: 00:02:44:54\n",
      "total_losses:0.793\n",
      "cls_loss:0.202\n",
      "reg_loss:0.592\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:52: global_step:67659  current_step:2660\n",
      "speed: 0.156s, remaining training time: 00:02:42:20\n",
      "total_losses:0.332\n",
      "cls_loss:0.028\n",
      "reg_loss:0.303\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:55: global_step:67679  current_step:2680\n",
      "speed: 0.161s, remaining training time: 00:02:46:50\n",
      "total_losses:0.348\n",
      "cls_loss:0.038\n",
      "reg_loss:0.310\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:30:59: global_step:67699  current_step:2700\n",
      "speed: 0.151s, remaining training time: 00:02:37:14\n",
      "total_losses:0.539\n",
      "cls_loss:0.083\n",
      "reg_loss:0.456\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:02: global_step:67719  current_step:2720\n",
      "speed: 0.176s, remaining training time: 00:03:02:21\n",
      "total_losses:0.903\n",
      "cls_loss:0.424\n",
      "reg_loss:0.480\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:05: global_step:67739  current_step:2740\n",
      "speed: 0.161s, remaining training time: 00:02:46:48\n",
      "total_losses:0.406\n",
      "cls_loss:0.057\n",
      "reg_loss:0.349\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:09: global_step:67759  current_step:2760\n",
      "speed: 0.163s, remaining training time: 00:02:49:22\n",
      "total_losses:0.671\n",
      "cls_loss:0.197\n",
      "reg_loss:0.474\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:12: global_step:67779  current_step:2780\n",
      "speed: 0.165s, remaining training time: 00:02:51:09\n",
      "total_losses:0.774\n",
      "cls_loss:0.265\n",
      "reg_loss:0.509\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:19: global_step:67819  current_step:2820\n",
      "speed: 0.168s, remaining training time: 00:02:53:48\n",
      "total_losses:0.551\n",
      "cls_loss:0.122\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:22: global_step:67839  current_step:2840\n",
      "speed: 0.174s, remaining training time: 00:03:00:33\n",
      "total_losses:0.724\n",
      "cls_loss:0.146\n",
      "reg_loss:0.578\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:26: global_step:67859  current_step:2860\n",
      "speed: 0.173s, remaining training time: 00:02:59:22\n",
      "total_losses:0.502\n",
      "cls_loss:0.049\n",
      "reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:29: global_step:67879  current_step:2880\n",
      "speed: 0.164s, remaining training time: 00:02:49:36\n",
      "total_losses:0.394\n",
      "cls_loss:0.060\n",
      "reg_loss:0.334\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:33: global_step:67899  current_step:2900\n",
      "speed: 0.158s, remaining training time: 00:02:43:24\n",
      "total_losses:0.449\n",
      "cls_loss:0.084\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:36: global_step:67919  current_step:2920\n",
      "speed: 0.165s, remaining training time: 00:02:50:55\n",
      "total_losses:0.386\n",
      "cls_loss:0.047\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:39: global_step:67939  current_step:2940\n",
      "speed: 0.149s, remaining training time: 00:02:34:11\n",
      "total_losses:0.520\n",
      "cls_loss:0.092\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:43: global_step:67959  current_step:2960\n",
      "speed: 0.163s, remaining training time: 00:02:48:04\n",
      "total_losses:0.435\n",
      "cls_loss:0.070\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:46: global_step:67979  current_step:2980\n",
      "speed: 0.166s, remaining training time: 00:02:51:17\n",
      "total_losses:0.375\n",
      "cls_loss:0.052\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:53: global_step:68019  current_step:3020\n",
      "speed: 0.169s, remaining training time: 00:02:54:51\n",
      "total_losses:0.318\n",
      "cls_loss:0.053\n",
      "reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:56: global_step:68039  current_step:3040\n",
      "speed: 0.166s, remaining training time: 00:02:51:02\n",
      "total_losses:0.637\n",
      "cls_loss:0.215\n",
      "reg_loss:0.423\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:31:59: global_step:68059  current_step:3060\n",
      "speed: 0.164s, remaining training time: 00:02:49:10\n",
      "total_losses:0.676\n",
      "cls_loss:0.169\n",
      "reg_loss:0.507\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:03: global_step:68079  current_step:3080\n",
      "speed: 0.170s, remaining training time: 00:02:55:02\n",
      "total_losses:0.546\n",
      "cls_loss:0.099\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:06: global_step:68099  current_step:3100\n",
      "speed: 0.180s, remaining training time: 00:03:05:17\n",
      "total_losses:0.614\n",
      "cls_loss:0.165\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:10: global_step:68119  current_step:3120\n",
      "speed: 0.173s, remaining training time: 00:02:58:48\n",
      "total_losses:0.827\n",
      "cls_loss:0.313\n",
      "reg_loss:0.513\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:13: global_step:68139  current_step:3140\n",
      "speed: 0.159s, remaining training time: 00:02:44:17\n",
      "total_losses:0.393\n",
      "cls_loss:0.047\n",
      "reg_loss:0.346\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:16: global_step:68159  current_step:3160\n",
      "speed: 0.188s, remaining training time: 00:03:14:13\n",
      "total_losses:1.152\n",
      "cls_loss:0.677\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:20: global_step:68179  current_step:3180\n",
      "speed: 0.155s, remaining training time: 00:02:39:24\n",
      "total_losses:0.443\n",
      "cls_loss:0.034\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:26: global_step:68219  current_step:3220\n",
      "speed: 0.151s, remaining training time: 00:02:35:44\n",
      "total_losses:0.428\n",
      "cls_loss:0.037\n",
      "reg_loss:0.391\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:30: global_step:68239  current_step:3240\n",
      "speed: 0.160s, remaining training time: 00:02:44:59\n",
      "total_losses:0.512\n",
      "cls_loss:0.054\n",
      "reg_loss:0.458\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:33: global_step:68259  current_step:3260\n",
      "speed: 0.164s, remaining training time: 00:02:48:54\n",
      "total_losses:0.750\n",
      "cls_loss:0.389\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:37: global_step:68279  current_step:3280\n",
      "speed: 0.171s, remaining training time: 00:02:56:15\n",
      "total_losses:0.681\n",
      "cls_loss:0.142\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:40: global_step:68299  current_step:3300\n",
      "speed: 0.152s, remaining training time: 00:02:35:51\n",
      "total_losses:0.496\n",
      "cls_loss:0.132\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:43: global_step:68319  current_step:3320\n",
      "speed: 0.183s, remaining training time: 00:03:07:51\n",
      "total_losses:0.844\n",
      "cls_loss:0.169\n",
      "reg_loss:0.675\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:47: global_step:68339  current_step:3340\n",
      "speed: 0.166s, remaining training time: 00:02:50:53\n",
      "total_losses:1.066\n",
      "cls_loss:0.564\n",
      "reg_loss:0.502\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:50: global_step:68359  current_step:3360\n",
      "speed: 0.164s, remaining training time: 00:02:48:18\n",
      "total_losses:0.731\n",
      "cls_loss:0.300\n",
      "reg_loss:0.431\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:32:53: global_step:68379  current_step:3380\n",
      "speed: 0.162s, remaining training time: 00:02:46:06\n",
      "total_losses:1.527\n",
      "cls_loss:0.793\n",
      "reg_loss:0.734\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:00: global_step:68419  current_step:3420\n",
      "speed: 0.151s, remaining training time: 00:02:35:23\n",
      "total_losses:0.843\n",
      "cls_loss:0.189\n",
      "reg_loss:0.654\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:03: global_step:68439  current_step:3440\n",
      "speed: 0.169s, remaining training time: 00:02:53:00\n",
      "total_losses:0.336\n",
      "cls_loss:0.025\n",
      "reg_loss:0.311\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:07: global_step:68459  current_step:3460\n",
      "speed: 0.200s, remaining training time: 00:03:25:13\n",
      "total_losses:0.672\n",
      "cls_loss:0.068\n",
      "reg_loss:0.605\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:10: global_step:68479  current_step:3480\n",
      "speed: 0.153s, remaining training time: 00:02:37:01\n",
      "total_losses:0.365\n",
      "cls_loss:0.059\n",
      "reg_loss:0.307\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:14: global_step:68499  current_step:3500\n",
      "speed: 0.173s, remaining training time: 00:02:56:52\n",
      "total_losses:0.531\n",
      "cls_loss:0.061\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:17: global_step:68519  current_step:3520\n",
      "speed: 0.169s, remaining training time: 00:02:53:38\n",
      "total_losses:0.277\n",
      "cls_loss:0.032\n",
      "reg_loss:0.245\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:20: global_step:68539  current_step:3540\n",
      "speed: 0.175s, remaining training time: 00:02:59:01\n",
      "total_losses:0.420\n",
      "cls_loss:0.065\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:23: global_step:68559  current_step:3560\n",
      "speed: 0.155s, remaining training time: 00:02:39:00\n",
      "total_losses:0.665\n",
      "cls_loss:0.222\n",
      "reg_loss:0.442\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:27: global_step:68579  current_step:3580\n",
      "speed: 0.187s, remaining training time: 00:03:11:19\n",
      "total_losses:0.590\n",
      "cls_loss:0.034\n",
      "reg_loss:0.555\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:34: global_step:68619  current_step:3620\n",
      "speed: 0.174s, remaining training time: 00:02:58:11\n",
      "total_losses:0.701\n",
      "cls_loss:0.218\n",
      "reg_loss:0.483\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:37: global_step:68639  current_step:3640\n",
      "speed: 0.166s, remaining training time: 00:02:49:34\n",
      "total_losses:0.650\n",
      "cls_loss:0.159\n",
      "reg_loss:0.490\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:40: global_step:68659  current_step:3660\n",
      "speed: 0.164s, remaining training time: 00:02:47:16\n",
      "total_losses:0.489\n",
      "cls_loss:0.052\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:44: global_step:68679  current_step:3680\n",
      "speed: 0.164s, remaining training time: 00:02:47:24\n",
      "total_losses:0.432\n",
      "cls_loss:0.027\n",
      "reg_loss:0.406\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:47: global_step:68699  current_step:3700\n",
      "speed: 0.159s, remaining training time: 00:02:42:00\n",
      "total_losses:0.506\n",
      "cls_loss:0.050\n",
      "reg_loss:0.456\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:50: global_step:68719  current_step:3720\n",
      "speed: 0.173s, remaining training time: 00:02:56:49\n",
      "total_losses:0.541\n",
      "cls_loss:0.137\n",
      "reg_loss:0.404\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:54: global_step:68739  current_step:3740\n",
      "speed: 0.157s, remaining training time: 00:02:40:20\n",
      "total_losses:0.329\n",
      "cls_loss:0.052\n",
      "reg_loss:0.277\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:33:57: global_step:68759  current_step:3760\n",
      "speed: 0.162s, remaining training time: 00:02:45:00\n",
      "total_losses:0.350\n",
      "cls_loss:0.020\n",
      "reg_loss:0.330\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:00: global_step:68779  current_step:3780\n",
      "speed: 0.165s, remaining training time: 00:02:48:10\n",
      "total_losses:0.629\n",
      "cls_loss:0.107\n",
      "reg_loss:0.522\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:07: global_step:68819  current_step:3820\n",
      "speed: 0.150s, remaining training time: 00:02:33:01\n",
      "total_losses:0.893\n",
      "cls_loss:0.484\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:10: global_step:68839  current_step:3840\n",
      "speed: 0.179s, remaining training time: 00:03:02:34\n",
      "total_losses:0.597\n",
      "cls_loss:0.169\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:14: global_step:68859  current_step:3860\n",
      "speed: 0.188s, remaining training time: 00:03:11:37\n",
      "total_losses:0.677\n",
      "cls_loss:0.226\n",
      "reg_loss:0.452\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:17: global_step:68879  current_step:3880\n",
      "speed: 0.181s, remaining training time: 00:03:04:29\n",
      "total_losses:0.466\n",
      "cls_loss:0.063\n",
      "reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:20: global_step:68899  current_step:3900\n",
      "speed: 0.167s, remaining training time: 00:02:49:36\n",
      "total_losses:0.653\n",
      "cls_loss:0.235\n",
      "reg_loss:0.418\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:24: global_step:68919  current_step:3920\n",
      "speed: 0.160s, remaining training time: 00:02:43:07\n",
      "total_losses:0.481\n",
      "cls_loss:0.078\n",
      "reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:27: global_step:68939  current_step:3940\n",
      "speed: 0.164s, remaining training time: 00:02:46:29\n",
      "total_losses:0.521\n",
      "cls_loss:0.167\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:30: global_step:68959  current_step:3960\n",
      "speed: 0.156s, remaining training time: 00:02:38:42\n",
      "total_losses:0.333\n",
      "cls_loss:0.015\n",
      "reg_loss:0.318\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:34: global_step:68979  current_step:3980\n",
      "speed: 0.162s, remaining training time: 00:02:44:36\n",
      "total_losses:0.356\n",
      "cls_loss:0.029\n",
      "reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:40: global_step:69019  current_step:4020\n",
      "speed: 0.153s, remaining training time: 00:02:35:08\n",
      "total_losses:0.501\n",
      "cls_loss:0.126\n",
      "reg_loss:0.375\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:44: global_step:69039  current_step:4040\n",
      "speed: 0.160s, remaining training time: 00:02:42:27\n",
      "total_losses:0.532\n",
      "cls_loss:0.112\n",
      "reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:47: global_step:69059  current_step:4060\n",
      "speed: 0.156s, remaining training time: 00:02:38:03\n",
      "total_losses:0.356\n",
      "cls_loss:0.057\n",
      "reg_loss:0.299\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:50: global_step:69079  current_step:4080\n",
      "speed: 0.174s, remaining training time: 00:02:56:26\n",
      "total_losses:0.439\n",
      "cls_loss:0.086\n",
      "reg_loss:0.353\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:54: global_step:69099  current_step:4100\n",
      "speed: 0.153s, remaining training time: 00:02:35:16\n",
      "total_losses:0.638\n",
      "cls_loss:0.253\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:34:57: global_step:69119  current_step:4120\n",
      "speed: 0.155s, remaining training time: 00:02:37:20\n",
      "total_losses:0.553\n",
      "cls_loss:0.040\n",
      "reg_loss:0.513\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:00: global_step:69139  current_step:4140\n",
      "speed: 0.167s, remaining training time: 00:02:49:25\n",
      "total_losses:0.508\n",
      "cls_loss:0.058\n",
      "reg_loss:0.450\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:04: global_step:69159  current_step:4160\n",
      "speed: 0.163s, remaining training time: 00:02:44:53\n",
      "total_losses:1.004\n",
      "cls_loss:0.390\n",
      "reg_loss:0.614\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:07: global_step:69179  current_step:4180\n",
      "speed: 0.180s, remaining training time: 00:03:02:34\n",
      "total_losses:0.251\n",
      "cls_loss:0.015\n",
      "reg_loss:0.236\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:14: global_step:69219  current_step:4220\n",
      "speed: 0.154s, remaining training time: 00:02:35:42\n",
      "total_losses:0.745\n",
      "cls_loss:0.140\n",
      "reg_loss:0.606\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:17: global_step:69239  current_step:4240\n",
      "speed: 0.171s, remaining training time: 00:02:52:45\n",
      "total_losses:0.359\n",
      "cls_loss:0.039\n",
      "reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:21: global_step:69259  current_step:4260\n",
      "speed: 0.167s, remaining training time: 00:02:49:24\n",
      "total_losses:0.873\n",
      "cls_loss:0.188\n",
      "reg_loss:0.685\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:24: global_step:69279  current_step:4280\n",
      "speed: 0.169s, remaining training time: 00:02:50:59\n",
      "total_losses:0.522\n",
      "cls_loss:0.074\n",
      "reg_loss:0.447\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:27: global_step:69299  current_step:4300\n",
      "speed: 0.163s, remaining training time: 00:02:45:12\n",
      "total_losses:0.361\n",
      "cls_loss:0.072\n",
      "reg_loss:0.289\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:31: global_step:69319  current_step:4320\n",
      "speed: 0.160s, remaining training time: 00:02:41:46\n",
      "total_losses:0.705\n",
      "cls_loss:0.083\n",
      "reg_loss:0.622\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:34: global_step:69339  current_step:4340\n",
      "speed: 0.176s, remaining training time: 00:02:57:55\n",
      "total_losses:0.634\n",
      "cls_loss:0.132\n",
      "reg_loss:0.501\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:37: global_step:69359  current_step:4360\n",
      "speed: 0.164s, remaining training time: 00:02:45:30\n",
      "total_losses:0.400\n",
      "cls_loss:0.064\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:41: global_step:69379  current_step:4380\n",
      "speed: 0.170s, remaining training time: 00:02:51:25\n",
      "total_losses:0.668\n",
      "cls_loss:0.149\n",
      "reg_loss:0.519\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:47: global_step:69419  current_step:4420\n",
      "speed: 0.183s, remaining training time: 00:03:04:28\n",
      "total_losses:0.830\n",
      "cls_loss:0.270\n",
      "reg_loss:0.559\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:51: global_step:69439  current_step:4440\n",
      "speed: 0.169s, remaining training time: 00:02:50:28\n",
      "total_losses:0.490\n",
      "cls_loss:0.070\n",
      "reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:54: global_step:69459  current_step:4460\n",
      "speed: 0.168s, remaining training time: 00:02:49:12\n",
      "total_losses:0.768\n",
      "cls_loss:0.191\n",
      "reg_loss:0.577\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:35:57: global_step:69479  current_step:4480\n",
      "speed: 0.173s, remaining training time: 00:02:54:04\n",
      "total_losses:0.441\n",
      "cls_loss:0.076\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:01: global_step:69499  current_step:4500\n",
      "speed: 0.192s, remaining training time: 00:03:14:01\n",
      "total_losses:0.391\n",
      "cls_loss:0.092\n",
      "reg_loss:0.300\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:04: global_step:69519  current_step:4520\n",
      "speed: 0.176s, remaining training time: 00:02:57:36\n",
      "total_losses:0.461\n",
      "cls_loss:0.042\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:07: global_step:69539  current_step:4540\n",
      "speed: 0.163s, remaining training time: 00:02:44:15\n",
      "total_losses:0.351\n",
      "cls_loss:0.055\n",
      "reg_loss:0.296\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:11: global_step:69559  current_step:4560\n",
      "speed: 0.182s, remaining training time: 00:03:03:44\n",
      "total_losses:0.747\n",
      "cls_loss:0.231\n",
      "reg_loss:0.517\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:14: global_step:69579  current_step:4580\n",
      "speed: 0.191s, remaining training time: 00:03:12:02\n",
      "total_losses:1.280\n",
      "cls_loss:0.701\n",
      "reg_loss:0.579\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:21: global_step:69619  current_step:4620\n",
      "speed: 0.172s, remaining training time: 00:02:52:51\n",
      "total_losses:0.758\n",
      "cls_loss:0.249\n",
      "reg_loss:0.509\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:24: global_step:69639  current_step:4640\n",
      "speed: 0.174s, remaining training time: 00:02:55:00\n",
      "total_losses:0.596\n",
      "cls_loss:0.059\n",
      "reg_loss:0.537\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:28: global_step:69659  current_step:4660\n",
      "speed: 0.174s, remaining training time: 00:02:54:54\n",
      "total_losses:0.673\n",
      "cls_loss:0.157\n",
      "reg_loss:0.516\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:31: global_step:69679  current_step:4680\n",
      "speed: 0.147s, remaining training time: 00:02:28:12\n",
      "total_losses:0.722\n",
      "cls_loss:0.188\n",
      "reg_loss:0.534\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:34: global_step:69699  current_step:4700\n",
      "speed: 0.178s, remaining training time: 00:02:58:37\n",
      "total_losses:0.678\n",
      "cls_loss:0.350\n",
      "reg_loss:0.328\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:38: global_step:69719  current_step:4720\n",
      "speed: 0.194s, remaining training time: 00:03:14:38\n",
      "total_losses:0.637\n",
      "cls_loss:0.272\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:41: global_step:69739  current_step:4740\n",
      "speed: 0.166s, remaining training time: 00:02:46:49\n",
      "total_losses:0.741\n",
      "cls_loss:0.143\n",
      "reg_loss:0.599\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:44: global_step:69759  current_step:4760\n",
      "speed: 0.203s, remaining training time: 00:03:23:32\n",
      "total_losses:0.548\n",
      "cls_loss:0.162\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:48: global_step:69779  current_step:4780\n",
      "speed: 0.174s, remaining training time: 00:02:54:47\n",
      "total_losses:0.476\n",
      "cls_loss:0.083\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:54: global_step:69819  current_step:4820\n",
      "speed: 0.173s, remaining training time: 00:02:53:36\n",
      "total_losses:0.414\n",
      "cls_loss:0.072\n",
      "reg_loss:0.343\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:36:58: global_step:69839  current_step:4840\n",
      "speed: 0.167s, remaining training time: 00:02:47:36\n",
      "total_losses:0.020\n",
      "cls_loss:0.020\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:01: global_step:69859  current_step:4860\n",
      "speed: 0.170s, remaining training time: 00:02:50:11\n",
      "total_losses:1.026\n",
      "cls_loss:0.344\n",
      "reg_loss:0.682\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:04: global_step:69879  current_step:4880\n",
      "speed: 0.164s, remaining training time: 00:02:44:41\n",
      "total_losses:0.523\n",
      "cls_loss:0.039\n",
      "reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:08: global_step:69899  current_step:4900\n",
      "speed: 0.185s, remaining training time: 00:03:05:06\n",
      "total_losses:0.592\n",
      "cls_loss:0.061\n",
      "reg_loss:0.532\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:11: global_step:69919  current_step:4920\n",
      "speed: 0.191s, remaining training time: 00:03:11:11\n",
      "total_losses:0.455\n",
      "cls_loss:0.053\n",
      "reg_loss:0.402\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:14: global_step:69939  current_step:4940\n",
      "speed: 0.174s, remaining training time: 00:02:54:05\n",
      "total_losses:0.425\n",
      "cls_loss:0.107\n",
      "reg_loss:0.317\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:18: global_step:69959  current_step:4960\n",
      "speed: 0.158s, remaining training time: 00:02:37:51\n",
      "total_losses:0.330\n",
      "cls_loss:0.019\n",
      "reg_loss:0.311\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:21: global_step:69979  current_step:4980\n",
      "speed: 0.169s, remaining training time: 00:02:49:26\n",
      "total_losses:0.474\n",
      "cls_loss:0.046\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:28: global_step:70019  current_step:5020\n",
      "speed: 0.159s, remaining training time: 00:02:39:18\n",
      "total_losses:0.662\n",
      "cls_loss:0.072\n",
      "reg_loss:0.590\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:31: global_step:70039  current_step:5040\n",
      "speed: 0.155s, remaining training time: 00:02:35:06\n",
      "total_losses:0.562\n",
      "cls_loss:0.107\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:34: global_step:70059  current_step:5060\n",
      "speed: 0.166s, remaining training time: 00:02:45:54\n",
      "total_losses:0.617\n",
      "cls_loss:0.180\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:38: global_step:70079  current_step:5080\n",
      "speed: 0.158s, remaining training time: 00:02:37:39\n",
      "total_losses:0.507\n",
      "cls_loss:0.082\n",
      "reg_loss:0.424\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:41: global_step:70099  current_step:5100\n",
      "speed: 0.174s, remaining training time: 00:02:53:23\n",
      "total_losses:0.439\n",
      "cls_loss:0.035\n",
      "reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:44: global_step:70119  current_step:5120\n",
      "speed: 0.171s, remaining training time: 00:02:50:12\n",
      "total_losses:0.830\n",
      "cls_loss:0.223\n",
      "reg_loss:0.607\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:48: global_step:70139  current_step:5140\n",
      "speed: 0.173s, remaining training time: 00:02:52:30\n",
      "total_losses:0.479\n",
      "cls_loss:0.115\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:51: global_step:70159  current_step:5160\n",
      "speed: 0.154s, remaining training time: 00:02:33:58\n",
      "total_losses:0.414\n",
      "cls_loss:0.028\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:37:54: global_step:70179  current_step:5180\n",
      "speed: 0.166s, remaining training time: 00:02:45:35\n",
      "total_losses:0.310\n",
      "cls_loss:0.040\n",
      "reg_loss:0.270\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:01: global_step:70219  current_step:5220\n",
      "speed: 0.190s, remaining training time: 00:03:09:48\n",
      "total_losses:0.466\n",
      "cls_loss:0.032\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:05: global_step:70239  current_step:5240\n",
      "speed: 0.167s, remaining training time: 00:02:46:32\n",
      "total_losses:0.569\n",
      "cls_loss:0.029\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:08: global_step:70259  current_step:5260\n",
      "speed: 0.169s, remaining training time: 00:02:48:45\n",
      "total_losses:0.684\n",
      "cls_loss:0.216\n",
      "reg_loss:0.469\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:11: global_step:70279  current_step:5280\n",
      "speed: 0.167s, remaining training time: 00:02:46:34\n",
      "total_losses:0.328\n",
      "cls_loss:0.033\n",
      "reg_loss:0.294\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:15: global_step:70299  current_step:5300\n",
      "speed: 0.157s, remaining training time: 00:02:36:21\n",
      "total_losses:0.487\n",
      "cls_loss:0.053\n",
      "reg_loss:0.435\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:18: global_step:70319  current_step:5320\n",
      "speed: 0.169s, remaining training time: 00:02:47:44\n",
      "total_losses:0.346\n",
      "cls_loss:0.015\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:22: global_step:70339  current_step:5340\n",
      "speed: 0.162s, remaining training time: 00:02:41:04\n",
      "total_losses:0.527\n",
      "cls_loss:0.040\n",
      "reg_loss:0.487\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:25: global_step:70359  current_step:5360\n",
      "speed: 0.173s, remaining training time: 00:02:52:04\n",
      "total_losses:1.392\n",
      "cls_loss:0.578\n",
      "reg_loss:0.814\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:28: global_step:70379  current_step:5380\n",
      "speed: 0.153s, remaining training time: 00:02:32:16\n",
      "total_losses:0.704\n",
      "cls_loss:0.237\n",
      "reg_loss:0.467\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:35: global_step:70419  current_step:5420\n",
      "speed: 0.173s, remaining training time: 00:02:51:50\n",
      "total_losses:0.715\n",
      "cls_loss:0.166\n",
      "reg_loss:0.548\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:38: global_step:70439  current_step:5440\n",
      "speed: 0.163s, remaining training time: 00:02:42:14\n",
      "total_losses:0.369\n",
      "cls_loss:0.039\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:42: global_step:70459  current_step:5460\n",
      "speed: 0.167s, remaining training time: 00:02:45:41\n",
      "total_losses:0.362\n",
      "cls_loss:0.089\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:45: global_step:70479  current_step:5480\n",
      "speed: 0.162s, remaining training time: 00:02:40:20\n",
      "total_losses:0.542\n",
      "cls_loss:0.150\n",
      "reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:48: global_step:70499  current_step:5500\n",
      "speed: 0.172s, remaining training time: 00:02:50:05\n",
      "total_losses:0.404\n",
      "cls_loss:0.107\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:52: global_step:70519  current_step:5520\n",
      "speed: 0.167s, remaining training time: 00:02:45:39\n",
      "total_losses:0.264\n",
      "cls_loss:0.016\n",
      "reg_loss:0.248\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:55: global_step:70539  current_step:5540\n",
      "speed: 0.206s, remaining training time: 00:03:23:51\n",
      "total_losses:0.487\n",
      "cls_loss:0.100\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:38:59: global_step:70559  current_step:5560\n",
      "speed: 0.165s, remaining training time: 00:02:43:01\n",
      "total_losses:0.696\n",
      "cls_loss:0.147\n",
      "reg_loss:0.550\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:02: global_step:70579  current_step:5580\n",
      "speed: 0.184s, remaining training time: 00:03:02:20\n",
      "total_losses:0.303\n",
      "cls_loss:0.028\n",
      "reg_loss:0.276\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:09: global_step:70619  current_step:5620\n",
      "speed: 0.176s, remaining training time: 00:02:54:21\n",
      "total_losses:0.485\n",
      "cls_loss:0.067\n",
      "reg_loss:0.418\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:12: global_step:70639  current_step:5640\n",
      "speed: 0.169s, remaining training time: 00:02:47:34\n",
      "total_losses:0.494\n",
      "cls_loss:0.139\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:15: global_step:70659  current_step:5660\n",
      "speed: 0.164s, remaining training time: 00:02:42:13\n",
      "total_losses:0.726\n",
      "cls_loss:0.232\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:19: global_step:70679  current_step:5680\n",
      "speed: 0.155s, remaining training time: 00:02:32:48\n",
      "total_losses:0.563\n",
      "cls_loss:0.083\n",
      "reg_loss:0.480\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:22: global_step:70699  current_step:5700\n",
      "speed: 0.176s, remaining training time: 00:02:53:57\n",
      "total_losses:0.638\n",
      "cls_loss:0.237\n",
      "reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:25: global_step:70719  current_step:5720\n",
      "speed: 0.168s, remaining training time: 00:02:45:58\n",
      "total_losses:0.641\n",
      "cls_loss:0.102\n",
      "reg_loss:0.539\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:29: global_step:70739  current_step:5740\n",
      "speed: 0.160s, remaining training time: 00:02:38:07\n",
      "total_losses:0.815\n",
      "cls_loss:0.236\n",
      "reg_loss:0.579\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:32: global_step:70759  current_step:5760\n",
      "speed: 0.166s, remaining training time: 00:02:43:35\n",
      "total_losses:0.355\n",
      "cls_loss:0.062\n",
      "reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:35: global_step:70779  current_step:5780\n",
      "speed: 0.161s, remaining training time: 00:02:38:43\n",
      "total_losses:0.645\n",
      "cls_loss:0.118\n",
      "reg_loss:0.527\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:42: global_step:70819  current_step:5820\n",
      "speed: 0.161s, remaining training time: 00:02:38:23\n",
      "total_losses:0.429\n",
      "cls_loss:0.033\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:45: global_step:70839  current_step:5840\n",
      "speed: 0.172s, remaining training time: 00:02:49:32\n",
      "total_losses:0.557\n",
      "cls_loss:0.144\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:49: global_step:70859  current_step:5860\n",
      "speed: 0.188s, remaining training time: 00:03:05:37\n",
      "total_losses:0.394\n",
      "cls_loss:0.031\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:52: global_step:70879  current_step:5880\n",
      "speed: 0.160s, remaining training time: 00:02:37:22\n",
      "total_losses:0.497\n",
      "cls_loss:0.049\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:55: global_step:70899  current_step:5900\n",
      "speed: 0.167s, remaining training time: 00:02:44:13\n",
      "total_losses:0.743\n",
      "cls_loss:0.316\n",
      "reg_loss:0.427\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:39:59: global_step:70919  current_step:5920\n",
      "speed: 0.161s, remaining training time: 00:02:38:22\n",
      "total_losses:0.473\n",
      "cls_loss:0.085\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:02: global_step:70939  current_step:5940\n",
      "speed: 0.166s, remaining training time: 00:02:43:12\n",
      "total_losses:0.488\n",
      "cls_loss:0.019\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:06: global_step:70959  current_step:5960\n",
      "speed: 0.159s, remaining training time: 00:02:36:44\n",
      "total_losses:0.517\n",
      "cls_loss:0.155\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:09: global_step:70979  current_step:5980\n",
      "speed: 0.168s, remaining training time: 00:02:45:09\n",
      "total_losses:0.622\n",
      "cls_loss:0.082\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:16: global_step:71019  current_step:6020\n",
      "speed: 0.168s, remaining training time: 00:02:45:30\n",
      "total_losses:0.981\n",
      "cls_loss:0.171\n",
      "reg_loss:0.810\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:19: global_step:71039  current_step:6040\n",
      "speed: 0.168s, remaining training time: 00:02:44:54\n",
      "total_losses:0.362\n",
      "cls_loss:0.037\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:22: global_step:71059  current_step:6060\n",
      "speed: 0.152s, remaining training time: 00:02:29:34\n",
      "total_losses:0.366\n",
      "cls_loss:0.094\n",
      "reg_loss:0.272\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:26: global_step:71079  current_step:6080\n",
      "speed: 0.163s, remaining training time: 00:02:40:03\n",
      "total_losses:0.548\n",
      "cls_loss:0.049\n",
      "reg_loss:0.499\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:29: global_step:71099  current_step:6100\n",
      "speed: 0.155s, remaining training time: 00:02:32:05\n",
      "total_losses:0.667\n",
      "cls_loss:0.040\n",
      "reg_loss:0.627\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:32: global_step:71119  current_step:6120\n",
      "speed: 0.159s, remaining training time: 00:02:35:37\n",
      "total_losses:0.397\n",
      "cls_loss:0.083\n",
      "reg_loss:0.314\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:36: global_step:71139  current_step:6140\n",
      "speed: 0.152s, remaining training time: 00:02:29:28\n",
      "total_losses:0.866\n",
      "cls_loss:0.130\n",
      "reg_loss:0.737\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:39: global_step:71159  current_step:6160\n",
      "speed: 0.178s, remaining training time: 00:02:54:14\n",
      "total_losses:0.508\n",
      "cls_loss:0.078\n",
      "reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:43: global_step:71179  current_step:6180\n",
      "speed: 0.162s, remaining training time: 00:02:38:33\n",
      "total_losses:0.459\n",
      "cls_loss:0.145\n",
      "reg_loss:0.314\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:49: global_step:71219  current_step:6220\n",
      "speed: 0.164s, remaining training time: 00:02:41:00\n",
      "total_losses:0.399\n",
      "cls_loss:0.058\n",
      "reg_loss:0.341\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:53: global_step:71239  current_step:6240\n",
      "speed: 0.167s, remaining training time: 00:02:43:15\n",
      "total_losses:0.648\n",
      "cls_loss:0.147\n",
      "reg_loss:0.501\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:56: global_step:71259  current_step:6260\n",
      "speed: 0.153s, remaining training time: 00:02:30:11\n",
      "total_losses:0.543\n",
      "cls_loss:0.104\n",
      "reg_loss:0.439\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:40:59: global_step:71279  current_step:6280\n",
      "speed: 0.157s, remaining training time: 00:02:33:44\n",
      "total_losses:0.761\n",
      "cls_loss:0.069\n",
      "reg_loss:0.692\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:03: global_step:71299  current_step:6300\n",
      "speed: 0.164s, remaining training time: 00:02:40:43\n",
      "total_losses:0.610\n",
      "cls_loss:0.061\n",
      "reg_loss:0.549\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:06: global_step:71319  current_step:6320\n",
      "speed: 0.167s, remaining training time: 00:02:42:57\n",
      "total_losses:0.794\n",
      "cls_loss:0.169\n",
      "reg_loss:0.625\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:09: global_step:71339  current_step:6340\n",
      "speed: 0.154s, remaining training time: 00:02:30:16\n",
      "total_losses:0.660\n",
      "cls_loss:0.120\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:13: global_step:71359  current_step:6360\n",
      "speed: 0.184s, remaining training time: 00:02:59:21\n",
      "total_losses:0.725\n",
      "cls_loss:0.139\n",
      "reg_loss:0.585\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:16: global_step:71379  current_step:6380\n",
      "speed: 0.177s, remaining training time: 00:02:52:51\n",
      "total_losses:0.696\n",
      "cls_loss:0.139\n",
      "reg_loss:0.557\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:23: global_step:71419  current_step:6420\n",
      "speed: 0.163s, remaining training time: 00:02:39:35\n",
      "total_losses:0.340\n",
      "cls_loss:0.045\n",
      "reg_loss:0.295\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:26: global_step:71439  current_step:6440\n",
      "speed: 0.187s, remaining training time: 00:03:02:04\n",
      "total_losses:0.662\n",
      "cls_loss:0.117\n",
      "reg_loss:0.546\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:29: global_step:71459  current_step:6460\n",
      "speed: 0.150s, remaining training time: 00:02:25:53\n",
      "total_losses:0.592\n",
      "cls_loss:0.121\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:33: global_step:71479  current_step:6480\n",
      "speed: 0.153s, remaining training time: 00:02:29:00\n",
      "total_losses:0.434\n",
      "cls_loss:0.065\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:36: global_step:71499  current_step:6500\n",
      "speed: 0.164s, remaining training time: 00:02:40:09\n",
      "total_losses:0.498\n",
      "cls_loss:0.097\n",
      "reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:40: global_step:71519  current_step:6520\n",
      "speed: 0.168s, remaining training time: 00:02:43:49\n",
      "total_losses:0.473\n",
      "cls_loss:0.025\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:43: global_step:71539  current_step:6540\n",
      "speed: 0.157s, remaining training time: 00:02:33:01\n",
      "total_losses:0.572\n",
      "cls_loss:0.088\n",
      "reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:46: global_step:71559  current_step:6560\n",
      "speed: 0.154s, remaining training time: 00:02:30:13\n",
      "total_losses:0.821\n",
      "cls_loss:0.332\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:50: global_step:71579  current_step:6580\n",
      "speed: 0.159s, remaining training time: 00:02:35:05\n",
      "total_losses:0.657\n",
      "cls_loss:0.198\n",
      "reg_loss:0.459\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:41:56: global_step:71619  current_step:6620\n",
      "speed: 0.152s, remaining training time: 00:02:27:51\n",
      "total_losses:0.466\n",
      "cls_loss:0.120\n",
      "reg_loss:0.346\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:00: global_step:71639  current_step:6640\n",
      "speed: 0.160s, remaining training time: 00:02:35:19\n",
      "total_losses:0.601\n",
      "cls_loss:0.039\n",
      "reg_loss:0.562\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:03: global_step:71659  current_step:6660\n",
      "speed: 0.151s, remaining training time: 00:02:26:29\n",
      "total_losses:0.914\n",
      "cls_loss:0.449\n",
      "reg_loss:0.465\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:06: global_step:71679  current_step:6680\n",
      "speed: 0.162s, remaining training time: 00:02:37:45\n",
      "total_losses:0.453\n",
      "cls_loss:0.092\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:10: global_step:71699  current_step:6700\n",
      "speed: 0.158s, remaining training time: 00:02:33:44\n",
      "total_losses:0.598\n",
      "cls_loss:0.076\n",
      "reg_loss:0.522\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:13: global_step:71719  current_step:6720\n",
      "speed: 0.183s, remaining training time: 00:02:58:08\n",
      "total_losses:0.632\n",
      "cls_loss:0.035\n",
      "reg_loss:0.597\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:16: global_step:71739  current_step:6740\n",
      "speed: 0.178s, remaining training time: 00:02:52:52\n",
      "total_losses:0.605\n",
      "cls_loss:0.045\n",
      "reg_loss:0.560\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:20: global_step:71759  current_step:6760\n",
      "speed: 0.186s, remaining training time: 00:03:00:11\n",
      "total_losses:0.334\n",
      "cls_loss:0.060\n",
      "reg_loss:0.274\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:23: global_step:71779  current_step:6780\n",
      "speed: 0.176s, remaining training time: 00:02:50:57\n",
      "total_losses:0.664\n",
      "cls_loss:0.206\n",
      "reg_loss:0.458\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:30: global_step:71819  current_step:6820\n",
      "speed: 0.154s, remaining training time: 00:02:29:31\n",
      "total_losses:0.567\n",
      "cls_loss:0.045\n",
      "reg_loss:0.521\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:33: global_step:71839  current_step:6840\n",
      "speed: 0.172s, remaining training time: 00:02:46:18\n",
      "total_losses:0.664\n",
      "cls_loss:0.216\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:36: global_step:71859  current_step:6860\n",
      "speed: 0.166s, remaining training time: 00:02:40:28\n",
      "total_losses:0.541\n",
      "cls_loss:0.049\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:40: global_step:71879  current_step:6880\n",
      "speed: 0.170s, remaining training time: 00:02:44:32\n",
      "total_losses:0.684\n",
      "cls_loss:0.141\n",
      "reg_loss:0.543\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:43: global_step:71899  current_step:6900\n",
      "speed: 0.163s, remaining training time: 00:02:37:38\n",
      "total_losses:0.945\n",
      "cls_loss:0.357\n",
      "reg_loss:0.589\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:46: global_step:71919  current_step:6920\n",
      "speed: 0.170s, remaining training time: 00:02:44:11\n",
      "total_losses:0.423\n",
      "cls_loss:0.096\n",
      "reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:50: global_step:71939  current_step:6940\n",
      "speed: 0.164s, remaining training time: 00:02:39:03\n",
      "total_losses:0.742\n",
      "cls_loss:0.152\n",
      "reg_loss:0.590\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:53: global_step:71959  current_step:6960\n",
      "speed: 0.175s, remaining training time: 00:02:49:37\n",
      "total_losses:0.810\n",
      "cls_loss:0.066\n",
      "reg_loss:0.744\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:42:57: global_step:71979  current_step:6980\n",
      "speed: 0.168s, remaining training time: 00:02:42:34\n",
      "total_losses:0.413\n",
      "cls_loss:0.078\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:03: global_step:72019  current_step:7020\n",
      "speed: 0.144s, remaining training time: 00:02:18:41\n",
      "total_losses:0.452\n",
      "cls_loss:0.093\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:07: global_step:72039  current_step:7040\n",
      "speed: 0.166s, remaining training time: 00:02:40:26\n",
      "total_losses:0.557\n",
      "cls_loss:0.123\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:10: global_step:72059  current_step:7060\n",
      "speed: 0.185s, remaining training time: 00:02:58:57\n",
      "total_losses:0.293\n",
      "cls_loss:0.045\n",
      "reg_loss:0.248\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:13: global_step:72079  current_step:7080\n",
      "speed: 0.159s, remaining training time: 00:02:33:07\n",
      "total_losses:0.388\n",
      "cls_loss:0.053\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:17: global_step:72099  current_step:7100\n",
      "speed: 0.158s, remaining training time: 00:02:32:12\n",
      "total_losses:0.414\n",
      "cls_loss:0.053\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:20: global_step:72119  current_step:7120\n",
      "speed: 0.171s, remaining training time: 00:02:45:22\n",
      "total_losses:0.407\n",
      "cls_loss:0.061\n",
      "reg_loss:0.347\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:23: global_step:72139  current_step:7140\n",
      "speed: 0.158s, remaining training time: 00:02:32:16\n",
      "total_losses:0.382\n",
      "cls_loss:0.032\n",
      "reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:27: global_step:72159  current_step:7160\n",
      "speed: 0.153s, remaining training time: 00:02:27:39\n",
      "total_losses:0.453\n",
      "cls_loss:0.036\n",
      "reg_loss:0.417\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:30: global_step:72179  current_step:7180\n",
      "speed: 0.178s, remaining training time: 00:02:51:40\n",
      "total_losses:0.419\n",
      "cls_loss:0.022\n",
      "reg_loss:0.397\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:37: global_step:72219  current_step:7220\n",
      "speed: 0.168s, remaining training time: 00:02:41:36\n",
      "total_losses:0.436\n",
      "cls_loss:0.078\n",
      "reg_loss:0.358\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:40: global_step:72239  current_step:7240\n",
      "speed: 0.157s, remaining training time: 00:02:31:35\n",
      "total_losses:0.810\n",
      "cls_loss:0.335\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:43: global_step:72259  current_step:7260\n",
      "speed: 0.143s, remaining training time: 00:02:17:21\n",
      "total_losses:0.761\n",
      "cls_loss:0.174\n",
      "reg_loss:0.586\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:47: global_step:72279  current_step:7280\n",
      "speed: 0.161s, remaining training time: 00:02:34:37\n",
      "total_losses:0.410\n",
      "cls_loss:0.070\n",
      "reg_loss:0.340\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:50: global_step:72299  current_step:7300\n",
      "speed: 0.181s, remaining training time: 00:02:53:43\n",
      "total_losses:0.740\n",
      "cls_loss:0.076\n",
      "reg_loss:0.664\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:53: global_step:72319  current_step:7320\n",
      "speed: 0.191s, remaining training time: 00:03:03:59\n",
      "total_losses:0.518\n",
      "cls_loss:0.128\n",
      "reg_loss:0.390\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:43:57: global_step:72339  current_step:7340\n",
      "speed: 0.160s, remaining training time: 00:02:33:33\n",
      "total_losses:0.535\n",
      "cls_loss:0.067\n",
      "reg_loss:0.468\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:00: global_step:72359  current_step:7360\n",
      "speed: 0.163s, remaining training time: 00:02:36:54\n",
      "total_losses:0.619\n",
      "cls_loss:0.131\n",
      "reg_loss:0.488\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:03: global_step:72379  current_step:7380\n",
      "speed: 0.153s, remaining training time: 00:02:27:16\n",
      "total_losses:0.310\n",
      "cls_loss:0.020\n",
      "reg_loss:0.289\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:10: global_step:72419  current_step:7420\n",
      "speed: 0.153s, remaining training time: 00:02:27:05\n",
      "total_losses:0.463\n",
      "cls_loss:0.185\n",
      "reg_loss:0.277\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:13: global_step:72439  current_step:7440\n",
      "speed: 0.159s, remaining training time: 00:02:32:07\n",
      "total_losses:0.646\n",
      "cls_loss:0.099\n",
      "reg_loss:0.547\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:17: global_step:72459  current_step:7460\n",
      "speed: 0.187s, remaining training time: 00:02:59:28\n",
      "total_losses:0.597\n",
      "cls_loss:0.148\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:20: global_step:72479  current_step:7480\n",
      "speed: 0.165s, remaining training time: 00:02:38:33\n",
      "total_losses:0.316\n",
      "cls_loss:0.031\n",
      "reg_loss:0.285\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:24: global_step:72499  current_step:7500\n",
      "speed: 0.153s, remaining training time: 00:02:26:38\n",
      "total_losses:0.664\n",
      "cls_loss:0.055\n",
      "reg_loss:0.609\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:27: global_step:72519  current_step:7520\n",
      "speed: 0.180s, remaining training time: 00:02:52:50\n",
      "total_losses:0.400\n",
      "cls_loss:0.103\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:30: global_step:72539  current_step:7540\n",
      "speed: 0.166s, remaining training time: 00:02:39:21\n",
      "total_losses:0.365\n",
      "cls_loss:0.099\n",
      "reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:34: global_step:72559  current_step:7560\n",
      "speed: 0.174s, remaining training time: 00:02:46:14\n",
      "total_losses:0.510\n",
      "cls_loss:0.118\n",
      "reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:37: global_step:72579  current_step:7580\n",
      "speed: 0.173s, remaining training time: 00:02:45:16\n",
      "total_losses:0.580\n",
      "cls_loss:0.122\n",
      "reg_loss:0.457\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:44: global_step:72619  current_step:7620\n",
      "speed: 0.172s, remaining training time: 00:02:44:43\n",
      "total_losses:0.455\n",
      "cls_loss:0.023\n",
      "reg_loss:0.432\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:47: global_step:72639  current_step:7640\n",
      "speed: 0.155s, remaining training time: 00:02:28:20\n",
      "total_losses:0.524\n",
      "cls_loss:0.118\n",
      "reg_loss:0.405\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:50: global_step:72659  current_step:7660\n",
      "speed: 0.158s, remaining training time: 00:02:31:11\n",
      "total_losses:0.712\n",
      "cls_loss:0.116\n",
      "reg_loss:0.596\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:54: global_step:72679  current_step:7680\n",
      "speed: 0.152s, remaining training time: 00:02:25:00\n",
      "total_losses:0.433\n",
      "cls_loss:0.076\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:44:57: global_step:72699  current_step:7700\n",
      "speed: 0.173s, remaining training time: 00:02:45:30\n",
      "total_losses:0.857\n",
      "cls_loss:0.318\n",
      "reg_loss:0.539\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:00: global_step:72719  current_step:7720\n",
      "speed: 0.166s, remaining training time: 00:02:38:27\n",
      "total_losses:0.281\n",
      "cls_loss:0.029\n",
      "reg_loss:0.253\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:04: global_step:72739  current_step:7740\n",
      "speed: 0.192s, remaining training time: 00:03:03:30\n",
      "total_losses:0.999\n",
      "cls_loss:0.129\n",
      "reg_loss:0.871\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:07: global_step:72759  current_step:7760\n",
      "speed: 0.160s, remaining training time: 00:02:32:49\n",
      "total_losses:0.494\n",
      "cls_loss:0.020\n",
      "reg_loss:0.473\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:10: global_step:72779  current_step:7780\n",
      "speed: 0.158s, remaining training time: 00:02:30:57\n",
      "total_losses:0.679\n",
      "cls_loss:0.190\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:17: global_step:72819  current_step:7820\n",
      "speed: 0.156s, remaining training time: 00:02:28:25\n",
      "total_losses:0.617\n",
      "cls_loss:0.112\n",
      "reg_loss:0.505\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:20: global_step:72839  current_step:7840\n",
      "speed: 0.171s, remaining training time: 00:02:43:17\n",
      "total_losses:0.531\n",
      "cls_loss:0.128\n",
      "reg_loss:0.402\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:24: global_step:72859  current_step:7860\n",
      "speed: 0.193s, remaining training time: 00:03:04:00\n",
      "total_losses:0.950\n",
      "cls_loss:0.166\n",
      "reg_loss:0.784\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:27: global_step:72879  current_step:7880\n",
      "speed: 0.155s, remaining training time: 00:02:27:48\n",
      "total_losses:0.835\n",
      "cls_loss:0.294\n",
      "reg_loss:0.541\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:31: global_step:72899  current_step:7900\n",
      "speed: 0.180s, remaining training time: 00:02:51:20\n",
      "total_losses:0.666\n",
      "cls_loss:0.232\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:34: global_step:72919  current_step:7920\n",
      "speed: 0.170s, remaining training time: 00:02:41:41\n",
      "total_losses:0.277\n",
      "cls_loss:0.025\n",
      "reg_loss:0.252\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:37: global_step:72939  current_step:7940\n",
      "speed: 0.155s, remaining training time: 00:02:27:33\n",
      "total_losses:0.296\n",
      "cls_loss:0.009\n",
      "reg_loss:0.287\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:41: global_step:72959  current_step:7960\n",
      "speed: 0.163s, remaining training time: 00:02:34:34\n",
      "total_losses:0.386\n",
      "cls_loss:0.112\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:44: global_step:72979  current_step:7980\n",
      "speed: 0.160s, remaining training time: 00:02:32:26\n",
      "total_losses:0.479\n",
      "cls_loss:0.065\n",
      "reg_loss:0.414\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:51: global_step:73019  current_step:8020\n",
      "speed: 0.178s, remaining training time: 00:02:49:26\n",
      "total_losses:0.600\n",
      "cls_loss:0.091\n",
      "reg_loss:0.509\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:54: global_step:73039  current_step:8040\n",
      "speed: 0.168s, remaining training time: 00:02:39:27\n",
      "total_losses:0.439\n",
      "cls_loss:0.068\n",
      "reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:45:57: global_step:73059  current_step:8060\n",
      "speed: 0.148s, remaining training time: 00:02:20:20\n",
      "total_losses:0.310\n",
      "cls_loss:0.040\n",
      "reg_loss:0.270\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:01: global_step:73079  current_step:8080\n",
      "speed: 0.148s, remaining training time: 00:02:20:10\n",
      "total_losses:0.375\n",
      "cls_loss:0.053\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:04: global_step:73099  current_step:8100\n",
      "speed: 0.173s, remaining training time: 00:02:44:22\n",
      "total_losses:0.431\n",
      "cls_loss:0.122\n",
      "reg_loss:0.309\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:07: global_step:73119  current_step:8120\n",
      "speed: 0.170s, remaining training time: 00:02:41:18\n",
      "total_losses:0.283\n",
      "cls_loss:0.009\n",
      "reg_loss:0.274\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:11: global_step:73139  current_step:8140\n",
      "speed: 0.163s, remaining training time: 00:02:34:18\n",
      "total_losses:0.385\n",
      "cls_loss:0.088\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:14: global_step:73159  current_step:8160\n",
      "speed: 0.171s, remaining training time: 00:02:41:42\n",
      "total_losses:0.494\n",
      "cls_loss:0.109\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:17: global_step:73179  current_step:8180\n",
      "speed: 0.165s, remaining training time: 00:02:36:19\n",
      "total_losses:0.237\n",
      "cls_loss:0.017\n",
      "reg_loss:0.220\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:24: global_step:73219  current_step:8220\n",
      "speed: 0.172s, remaining training time: 00:02:43:09\n",
      "total_losses:0.598\n",
      "cls_loss:0.053\n",
      "reg_loss:0.546\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:27: global_step:73239  current_step:8240\n",
      "speed: 0.157s, remaining training time: 00:02:28:15\n",
      "total_losses:0.024\n",
      "cls_loss:0.024\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:31: global_step:73259  current_step:8260\n",
      "speed: 0.159s, remaining training time: 00:02:30:32\n",
      "total_losses:0.698\n",
      "cls_loss:0.105\n",
      "reg_loss:0.594\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:34: global_step:73279  current_step:8280\n",
      "speed: 0.162s, remaining training time: 00:02:32:52\n",
      "total_losses:0.567\n",
      "cls_loss:0.066\n",
      "reg_loss:0.501\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:38: global_step:73299  current_step:8300\n",
      "speed: 0.162s, remaining training time: 00:02:32:48\n",
      "total_losses:0.595\n",
      "cls_loss:0.135\n",
      "reg_loss:0.461\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:41: global_step:73319  current_step:8320\n",
      "speed: 0.161s, remaining training time: 00:02:32:29\n",
      "total_losses:0.371\n",
      "cls_loss:0.051\n",
      "reg_loss:0.320\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:44: global_step:73339  current_step:8340\n",
      "speed: 0.160s, remaining training time: 00:02:31:28\n",
      "total_losses:0.027\n",
      "cls_loss:0.027\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:48: global_step:73359  current_step:8360\n",
      "speed: 0.171s, remaining training time: 00:02:41:04\n",
      "total_losses:0.366\n",
      "cls_loss:0.031\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:51: global_step:73379  current_step:8380\n",
      "speed: 0.166s, remaining training time: 00:02:36:30\n",
      "total_losses:1.091\n",
      "cls_loss:0.238\n",
      "reg_loss:0.853\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:46:58: global_step:73419  current_step:8420\n",
      "speed: 0.156s, remaining training time: 00:02:27:20\n",
      "total_losses:0.464\n",
      "cls_loss:0.092\n",
      "reg_loss:0.372\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:01: global_step:73439  current_step:8440\n",
      "speed: 0.178s, remaining training time: 00:02:47:34\n",
      "total_losses:0.646\n",
      "cls_loss:0.099\n",
      "reg_loss:0.547\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:05: global_step:73459  current_step:8460\n",
      "speed: 0.165s, remaining training time: 00:02:35:06\n",
      "total_losses:0.521\n",
      "cls_loss:0.152\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:08: global_step:73479  current_step:8480\n",
      "speed: 0.172s, remaining training time: 00:02:41:42\n",
      "total_losses:0.366\n",
      "cls_loss:0.063\n",
      "reg_loss:0.302\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:11: global_step:73499  current_step:8500\n",
      "speed: 0.175s, remaining training time: 00:02:45:01\n",
      "total_losses:0.382\n",
      "cls_loss:0.046\n",
      "reg_loss:0.336\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:15: global_step:73519  current_step:8520\n",
      "speed: 0.164s, remaining training time: 00:02:34:27\n",
      "total_losses:0.720\n",
      "cls_loss:0.250\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:18: global_step:73539  current_step:8540\n",
      "speed: 0.154s, remaining training time: 00:02:25:07\n",
      "total_losses:0.473\n",
      "cls_loss:0.063\n",
      "reg_loss:0.410\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:21: global_step:73559  current_step:8560\n",
      "speed: 0.163s, remaining training time: 00:02:33:06\n",
      "total_losses:0.422\n",
      "cls_loss:0.084\n",
      "reg_loss:0.338\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:25: global_step:73579  current_step:8580\n",
      "speed: 0.171s, remaining training time: 00:02:40:53\n",
      "total_losses:0.305\n",
      "cls_loss:0.012\n",
      "reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:31: global_step:73619  current_step:8620\n",
      "speed: 0.171s, remaining training time: 00:02:41:08\n",
      "total_losses:0.378\n",
      "cls_loss:0.093\n",
      "reg_loss:0.285\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:35: global_step:73639  current_step:8640\n",
      "speed: 0.170s, remaining training time: 00:02:39:37\n",
      "total_losses:0.385\n",
      "cls_loss:0.063\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:38: global_step:73659  current_step:8660\n",
      "speed: 0.173s, remaining training time: 00:02:42:18\n",
      "total_losses:0.416\n",
      "cls_loss:0.063\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:41: global_step:73679  current_step:8680\n",
      "speed: 0.182s, remaining training time: 00:02:51:14\n",
      "total_losses:0.938\n",
      "cls_loss:0.346\n",
      "reg_loss:0.592\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:45: global_step:73699  current_step:8700\n",
      "speed: 0.174s, remaining training time: 00:02:43:16\n",
      "total_losses:0.533\n",
      "cls_loss:0.115\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:48: global_step:73719  current_step:8720\n",
      "speed: 0.168s, remaining training time: 00:02:37:54\n",
      "total_losses:0.644\n",
      "cls_loss:0.106\n",
      "reg_loss:0.538\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:52: global_step:73739  current_step:8740\n",
      "speed: 0.164s, remaining training time: 00:02:34:07\n",
      "total_losses:0.450\n",
      "cls_loss:0.088\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:55: global_step:73759  current_step:8760\n",
      "speed: 0.158s, remaining training time: 00:02:28:12\n",
      "total_losses:0.531\n",
      "cls_loss:0.064\n",
      "reg_loss:0.467\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:47:58: global_step:73779  current_step:8780\n",
      "speed: 0.171s, remaining training time: 00:02:40:11\n",
      "total_losses:0.118\n",
      "cls_loss:0.118\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:05: global_step:73819  current_step:8820\n",
      "speed: 0.169s, remaining training time: 00:02:37:48\n",
      "total_losses:0.212\n",
      "cls_loss:0.009\n",
      "reg_loss:0.202\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:08: global_step:73839  current_step:8840\n",
      "speed: 0.162s, remaining training time: 00:02:31:53\n",
      "total_losses:0.444\n",
      "cls_loss:0.020\n",
      "reg_loss:0.424\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:12: global_step:73859  current_step:8860\n",
      "speed: 0.168s, remaining training time: 00:02:36:58\n",
      "total_losses:0.339\n",
      "cls_loss:0.044\n",
      "reg_loss:0.295\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:15: global_step:73879  current_step:8880\n",
      "speed: 0.170s, remaining training time: 00:02:39:13\n",
      "total_losses:0.628\n",
      "cls_loss:0.176\n",
      "reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:18: global_step:73899  current_step:8900\n",
      "speed: 0.147s, remaining training time: 00:02:17:53\n",
      "total_losses:0.874\n",
      "cls_loss:0.298\n",
      "reg_loss:0.576\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:22: global_step:73919  current_step:8920\n",
      "speed: 0.167s, remaining training time: 00:02:36:06\n",
      "total_losses:0.241\n",
      "cls_loss:0.022\n",
      "reg_loss:0.219\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:25: global_step:73939  current_step:8940\n",
      "speed: 0.176s, remaining training time: 00:02:44:51\n",
      "total_losses:0.436\n",
      "cls_loss:0.076\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:28: global_step:73959  current_step:8960\n",
      "speed: 0.158s, remaining training time: 00:02:27:16\n",
      "total_losses:0.605\n",
      "cls_loss:0.065\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:32: global_step:73979  current_step:8980\n",
      "speed: 0.172s, remaining training time: 00:02:40:57\n",
      "total_losses:0.548\n",
      "cls_loss:0.114\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:39: global_step:74019  current_step:9020\n",
      "speed: 0.179s, remaining training time: 00:02:47:13\n",
      "total_losses:0.474\n",
      "cls_loss:0.091\n",
      "reg_loss:0.383\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:42: global_step:74039  current_step:9040\n",
      "speed: 0.166s, remaining training time: 00:02:35:15\n",
      "total_losses:0.514\n",
      "cls_loss:0.154\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:45: global_step:74059  current_step:9060\n",
      "speed: 0.172s, remaining training time: 00:02:40:05\n",
      "total_losses:0.370\n",
      "cls_loss:0.031\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:49: global_step:74079  current_step:9080\n",
      "speed: 0.170s, remaining training time: 00:02:38:36\n",
      "total_losses:0.710\n",
      "cls_loss:0.169\n",
      "reg_loss:0.540\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:52: global_step:74099  current_step:9100\n",
      "speed: 0.177s, remaining training time: 00:02:44:55\n",
      "total_losses:1.105\n",
      "cls_loss:0.454\n",
      "reg_loss:0.651\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:55: global_step:74119  current_step:9120\n",
      "speed: 0.171s, remaining training time: 00:02:39:15\n",
      "total_losses:0.611\n",
      "cls_loss:0.112\n",
      "reg_loss:0.498\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:48:59: global_step:74139  current_step:9140\n",
      "speed: 0.164s, remaining training time: 00:02:32:24\n",
      "total_losses:0.549\n",
      "cls_loss:0.139\n",
      "reg_loss:0.410\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:02: global_step:74159  current_step:9160\n",
      "speed: 0.156s, remaining training time: 00:02:24:57\n",
      "total_losses:0.388\n",
      "cls_loss:0.090\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:05: global_step:74179  current_step:9180\n",
      "speed: 0.172s, remaining training time: 00:02:40:14\n",
      "total_losses:0.351\n",
      "cls_loss:0.062\n",
      "reg_loss:0.289\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:12: global_step:74219  current_step:9220\n",
      "speed: 0.149s, remaining training time: 00:02:18:12\n",
      "total_losses:0.352\n",
      "cls_loss:0.025\n",
      "reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:15: global_step:74239  current_step:9240\n",
      "speed: 0.170s, remaining training time: 00:02:37:54\n",
      "total_losses:0.528\n",
      "cls_loss:0.108\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:19: global_step:74259  current_step:9260\n",
      "speed: 0.173s, remaining training time: 00:02:40:36\n",
      "total_losses:0.445\n",
      "cls_loss:0.031\n",
      "reg_loss:0.414\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:22: global_step:74279  current_step:9280\n",
      "speed: 0.153s, remaining training time: 00:02:22:09\n",
      "total_losses:0.340\n",
      "cls_loss:0.068\n",
      "reg_loss:0.271\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:26: global_step:74299  current_step:9300\n",
      "speed: 0.175s, remaining training time: 00:02:42:05\n",
      "total_losses:0.530\n",
      "cls_loss:0.039\n",
      "reg_loss:0.491\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:29: global_step:74319  current_step:9320\n",
      "speed: 0.174s, remaining training time: 00:02:41:28\n",
      "total_losses:0.690\n",
      "cls_loss:0.096\n",
      "reg_loss:0.594\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:32: global_step:74339  current_step:9340\n",
      "speed: 0.172s, remaining training time: 00:02:39:25\n",
      "total_losses:0.854\n",
      "cls_loss:0.270\n",
      "reg_loss:0.584\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:36: global_step:74359  current_step:9360\n",
      "speed: 0.167s, remaining training time: 00:02:34:45\n",
      "total_losses:0.535\n",
      "cls_loss:0.052\n",
      "reg_loss:0.483\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:39: global_step:74379  current_step:9380\n",
      "speed: 0.169s, remaining training time: 00:02:36:27\n",
      "total_losses:0.774\n",
      "cls_loss:0.366\n",
      "reg_loss:0.408\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:46: global_step:74419  current_step:9420\n",
      "speed: 0.170s, remaining training time: 00:02:37:04\n",
      "total_losses:1.220\n",
      "cls_loss:0.701\n",
      "reg_loss:0.519\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:49: global_step:74439  current_step:9440\n",
      "speed: 0.154s, remaining training time: 00:02:22:43\n",
      "total_losses:0.667\n",
      "cls_loss:0.138\n",
      "reg_loss:0.529\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:52: global_step:74459  current_step:9460\n",
      "speed: 0.176s, remaining training time: 00:02:43:13\n",
      "total_losses:0.448\n",
      "cls_loss:0.183\n",
      "reg_loss:0.265\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:56: global_step:74479  current_step:9480\n",
      "speed: 0.161s, remaining training time: 00:02:29:05\n",
      "total_losses:0.352\n",
      "cls_loss:0.016\n",
      "reg_loss:0.336\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:49:59: global_step:74499  current_step:9500\n",
      "speed: 0.169s, remaining training time: 00:02:36:23\n",
      "total_losses:0.456\n",
      "cls_loss:0.043\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:02: global_step:74519  current_step:9520\n",
      "speed: 0.164s, remaining training time: 00:02:31:34\n",
      "total_losses:0.950\n",
      "cls_loss:0.525\n",
      "reg_loss:0.426\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:06: global_step:74539  current_step:9540\n",
      "speed: 0.165s, remaining training time: 00:02:32:26\n",
      "total_losses:0.438\n",
      "cls_loss:0.082\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:09: global_step:74559  current_step:9560\n",
      "speed: 0.166s, remaining training time: 00:02:33:44\n",
      "total_losses:0.492\n",
      "cls_loss:0.079\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:12: global_step:74579  current_step:9580\n",
      "speed: 0.164s, remaining training time: 00:02:31:16\n",
      "total_losses:0.998\n",
      "cls_loss:0.299\n",
      "reg_loss:0.699\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:19: global_step:74619  current_step:9620\n",
      "speed: 0.169s, remaining training time: 00:02:36:11\n",
      "total_losses:0.628\n",
      "cls_loss:0.084\n",
      "reg_loss:0.544\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:22: global_step:74639  current_step:9640\n",
      "speed: 0.171s, remaining training time: 00:02:37:30\n",
      "total_losses:0.691\n",
      "cls_loss:0.302\n",
      "reg_loss:0.389\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:26: global_step:74659  current_step:9660\n",
      "speed: 0.158s, remaining training time: 00:02:25:51\n",
      "total_losses:0.268\n",
      "cls_loss:0.017\n",
      "reg_loss:0.251\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:29: global_step:74679  current_step:9680\n",
      "speed: 0.170s, remaining training time: 00:02:36:53\n",
      "total_losses:0.527\n",
      "cls_loss:0.182\n",
      "reg_loss:0.346\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:33: global_step:74699  current_step:9700\n",
      "speed: 0.168s, remaining training time: 00:02:34:27\n",
      "total_losses:0.337\n",
      "cls_loss:0.031\n",
      "reg_loss:0.306\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:36: global_step:74719  current_step:9720\n",
      "speed: 0.184s, remaining training time: 00:02:49:59\n",
      "total_losses:0.552\n",
      "cls_loss:0.198\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:39: global_step:74739  current_step:9740\n",
      "speed: 0.157s, remaining training time: 00:02:24:52\n",
      "total_losses:0.588\n",
      "cls_loss:0.161\n",
      "reg_loss:0.427\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:43: global_step:74759  current_step:9760\n",
      "speed: 0.180s, remaining training time: 00:02:45:42\n",
      "total_losses:0.701\n",
      "cls_loss:0.099\n",
      "reg_loss:0.602\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:46: global_step:74779  current_step:9780\n",
      "speed: 0.173s, remaining training time: 00:02:38:52\n",
      "total_losses:0.240\n",
      "cls_loss:0.015\n",
      "reg_loss:0.225\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:53: global_step:74819  current_step:9820\n",
      "speed: 0.161s, remaining training time: 00:02:28:15\n",
      "total_losses:0.554\n",
      "cls_loss:0.144\n",
      "reg_loss:0.410\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:56: global_step:74839  current_step:9840\n",
      "speed: 0.162s, remaining training time: 00:02:29:01\n",
      "total_losses:0.633\n",
      "cls_loss:0.071\n",
      "reg_loss:0.562\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:50:59: global_step:74859  current_step:9860\n",
      "speed: 0.170s, remaining training time: 00:02:36:13\n",
      "total_losses:0.450\n",
      "cls_loss:0.056\n",
      "reg_loss:0.394\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:03: global_step:74879  current_step:9880\n",
      "speed: 0.172s, remaining training time: 00:02:38:21\n",
      "total_losses:0.676\n",
      "cls_loss:0.205\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:06: global_step:74899  current_step:9900\n",
      "speed: 0.168s, remaining training time: 00:02:34:20\n",
      "total_losses:0.521\n",
      "cls_loss:0.127\n",
      "reg_loss:0.394\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:09: global_step:74919  current_step:9920\n",
      "speed: 0.164s, remaining training time: 00:02:30:49\n",
      "total_losses:0.483\n",
      "cls_loss:0.022\n",
      "reg_loss:0.460\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:13: global_step:74939  current_step:9940\n",
      "speed: 0.153s, remaining training time: 00:02:20:14\n",
      "total_losses:0.351\n",
      "cls_loss:0.055\n",
      "reg_loss:0.295\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:16: global_step:74959  current_step:9960\n",
      "speed: 0.176s, remaining training time: 00:02:41:34\n",
      "total_losses:0.424\n",
      "cls_loss:0.132\n",
      "reg_loss:0.291\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:19: global_step:74979  current_step:9980\n",
      "speed: 0.171s, remaining training time: 00:02:36:56\n",
      "total_losses:0.509\n",
      "cls_loss:0.077\n",
      "reg_loss:0.433\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2021-06-01 17:51:28: global_step:75019  current_step:10020\n",
      "speed: 0.174s, remaining training time: 00:02:39:13\n",
      "total_losses:0.253\n",
      "cls_loss:0.028\n",
      "reg_loss:0.226\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:31: global_step:75039  current_step:10040\n",
      "speed: 0.162s, remaining training time: 00:02:28:24\n",
      "total_losses:0.486\n",
      "cls_loss:0.031\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:34: global_step:75059  current_step:10060\n",
      "speed: 0.165s, remaining training time: 00:02:31:19\n",
      "total_losses:0.377\n",
      "cls_loss:0.018\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:38: global_step:75079  current_step:10080\n",
      "speed: 0.146s, remaining training time: 00:02:13:23\n",
      "total_losses:0.426\n",
      "cls_loss:0.110\n",
      "reg_loss:0.316\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:41: global_step:75099  current_step:10100\n",
      "speed: 0.191s, remaining training time: 00:02:54:23\n",
      "total_losses:0.495\n",
      "cls_loss:0.086\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:44: global_step:75119  current_step:10120\n",
      "speed: 0.174s, remaining training time: 00:02:38:49\n",
      "total_losses:0.603\n",
      "cls_loss:0.151\n",
      "reg_loss:0.452\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:48: global_step:75139  current_step:10140\n",
      "speed: 0.166s, remaining training time: 00:02:31:57\n",
      "total_losses:0.335\n",
      "cls_loss:0.052\n",
      "reg_loss:0.284\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:51: global_step:75159  current_step:10160\n",
      "speed: 0.176s, remaining training time: 00:02:41:04\n",
      "total_losses:0.599\n",
      "cls_loss:0.228\n",
      "reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:51:55: global_step:75179  current_step:10180\n",
      "speed: 0.159s, remaining training time: 00:02:25:41\n",
      "total_losses:0.562\n",
      "cls_loss:0.102\n",
      "reg_loss:0.460\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:01: global_step:75219  current_step:10220\n",
      "speed: 0.168s, remaining training time: 00:02:33:47\n",
      "total_losses:0.351\n",
      "cls_loss:0.036\n",
      "reg_loss:0.315\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:05: global_step:75239  current_step:10240\n",
      "speed: 0.161s, remaining training time: 00:02:26:57\n",
      "total_losses:0.452\n",
      "cls_loss:0.041\n",
      "reg_loss:0.411\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:08: global_step:75259  current_step:10260\n",
      "speed: 0.165s, remaining training time: 00:02:30:37\n",
      "total_losses:0.426\n",
      "cls_loss:0.040\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:11: global_step:75279  current_step:10280\n",
      "speed: 0.150s, remaining training time: 00:02:16:56\n",
      "total_losses:0.579\n",
      "cls_loss:0.194\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:15: global_step:75299  current_step:10300\n",
      "speed: 0.173s, remaining training time: 00:02:37:43\n",
      "total_losses:0.444\n",
      "cls_loss:0.045\n",
      "reg_loss:0.399\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:18: global_step:75319  current_step:10320\n",
      "speed: 0.164s, remaining training time: 00:02:29:33\n",
      "total_losses:0.592\n",
      "cls_loss:0.139\n",
      "reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:21: global_step:75339  current_step:10340\n",
      "speed: 0.151s, remaining training time: 00:02:17:56\n",
      "total_losses:0.439\n",
      "cls_loss:0.090\n",
      "reg_loss:0.349\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:25: global_step:75359  current_step:10360\n",
      "speed: 0.175s, remaining training time: 00:02:38:55\n",
      "total_losses:0.387\n",
      "cls_loss:0.072\n",
      "reg_loss:0.315\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:28: global_step:75379  current_step:10380\n",
      "speed: 0.164s, remaining training time: 00:02:29:25\n",
      "total_losses:0.569\n",
      "cls_loss:0.061\n",
      "reg_loss:0.507\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:35: global_step:75419  current_step:10420\n",
      "speed: 0.166s, remaining training time: 00:02:31:19\n",
      "total_losses:0.871\n",
      "cls_loss:0.247\n",
      "reg_loss:0.623\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:38: global_step:75439  current_step:10440\n",
      "speed: 0.149s, remaining training time: 00:02:15:05\n",
      "total_losses:0.226\n",
      "cls_loss:0.011\n",
      "reg_loss:0.215\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:41: global_step:75459  current_step:10460\n",
      "speed: 0.181s, remaining training time: 00:02:44:43\n",
      "total_losses:0.560\n",
      "cls_loss:0.113\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:45: global_step:75479  current_step:10480\n",
      "speed: 0.167s, remaining training time: 00:02:31:47\n",
      "total_losses:0.556\n",
      "cls_loss:0.077\n",
      "reg_loss:0.479\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:48: global_step:75499  current_step:10500\n",
      "speed: 0.172s, remaining training time: 00:02:36:38\n",
      "total_losses:0.417\n",
      "cls_loss:0.030\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:51: global_step:75519  current_step:10520\n",
      "speed: 0.163s, remaining training time: 00:02:28:10\n",
      "total_losses:0.687\n",
      "cls_loss:0.196\n",
      "reg_loss:0.491\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:55: global_step:75539  current_step:10540\n",
      "speed: 0.154s, remaining training time: 00:02:19:31\n",
      "total_losses:0.401\n",
      "cls_loss:0.059\n",
      "reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:52:58: global_step:75559  current_step:10560\n",
      "speed: 0.176s, remaining training time: 00:02:40:00\n",
      "total_losses:0.406\n",
      "cls_loss:0.038\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:01: global_step:75579  current_step:10580\n",
      "speed: 0.173s, remaining training time: 00:02:37:00\n",
      "total_losses:0.519\n",
      "cls_loss:0.060\n",
      "reg_loss:0.459\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:08: global_step:75619  current_step:10620\n",
      "speed: 0.174s, remaining training time: 00:02:37:17\n",
      "total_losses:0.464\n",
      "cls_loss:0.083\n",
      "reg_loss:0.381\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:12: global_step:75639  current_step:10640\n",
      "speed: 0.174s, remaining training time: 00:02:37:49\n",
      "total_losses:0.606\n",
      "cls_loss:0.100\n",
      "reg_loss:0.506\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:15: global_step:75659  current_step:10660\n",
      "speed: 0.161s, remaining training time: 00:02:26:09\n",
      "total_losses:0.397\n",
      "cls_loss:0.029\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:18: global_step:75679  current_step:10680\n",
      "speed: 0.167s, remaining training time: 00:02:31:01\n",
      "total_losses:0.898\n",
      "cls_loss:0.177\n",
      "reg_loss:0.720\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:22: global_step:75699  current_step:10700\n",
      "speed: 0.160s, remaining training time: 00:02:24:23\n",
      "total_losses:0.413\n",
      "cls_loss:0.055\n",
      "reg_loss:0.358\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:25: global_step:75719  current_step:10720\n",
      "speed: 0.167s, remaining training time: 00:02:30:49\n",
      "total_losses:0.374\n",
      "cls_loss:0.042\n",
      "reg_loss:0.332\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:28: global_step:75739  current_step:10740\n",
      "speed: 0.192s, remaining training time: 00:02:53:33\n",
      "total_losses:0.319\n",
      "cls_loss:0.040\n",
      "reg_loss:0.278\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:32: global_step:75759  current_step:10760\n",
      "speed: 0.148s, remaining training time: 00:02:13:37\n",
      "total_losses:0.339\n",
      "cls_loss:0.033\n",
      "reg_loss:0.306\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:35: global_step:75779  current_step:10780\n",
      "speed: 0.177s, remaining training time: 00:02:40:23\n",
      "total_losses:0.401\n",
      "cls_loss:0.020\n",
      "reg_loss:0.381\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:42: global_step:75819  current_step:10820\n",
      "speed: 0.178s, remaining training time: 00:02:41:06\n",
      "total_losses:0.586\n",
      "cls_loss:0.148\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:45: global_step:75839  current_step:10840\n",
      "speed: 0.177s, remaining training time: 00:02:39:34\n",
      "total_losses:0.620\n",
      "cls_loss:0.143\n",
      "reg_loss:0.477\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:48: global_step:75859  current_step:10860\n",
      "speed: 0.159s, remaining training time: 00:02:23:40\n",
      "total_losses:0.394\n",
      "cls_loss:0.057\n",
      "reg_loss:0.338\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:52: global_step:75879  current_step:10880\n",
      "speed: 0.166s, remaining training time: 00:02:29:49\n",
      "total_losses:0.499\n",
      "cls_loss:0.156\n",
      "reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:55: global_step:75899  current_step:10900\n",
      "speed: 0.165s, remaining training time: 00:02:28:46\n",
      "total_losses:0.349\n",
      "cls_loss:0.026\n",
      "reg_loss:0.324\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:53:58: global_step:75919  current_step:10920\n",
      "speed: 0.172s, remaining training time: 00:02:34:40\n",
      "total_losses:0.454\n",
      "cls_loss:0.039\n",
      "reg_loss:0.416\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:02: global_step:75939  current_step:10940\n",
      "speed: 0.172s, remaining training time: 00:02:35:01\n",
      "total_losses:0.771\n",
      "cls_loss:0.365\n",
      "reg_loss:0.407\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:05: global_step:75959  current_step:10960\n",
      "speed: 0.168s, remaining training time: 00:02:31:21\n",
      "total_losses:0.716\n",
      "cls_loss:0.230\n",
      "reg_loss:0.486\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:08: global_step:75979  current_step:10980\n",
      "speed: 0.172s, remaining training time: 00:02:34:30\n",
      "total_losses:0.810\n",
      "cls_loss:0.274\n",
      "reg_loss:0.536\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:15: global_step:76019  current_step:11020\n",
      "speed: 0.164s, remaining training time: 00:02:27:19\n",
      "total_losses:0.322\n",
      "cls_loss:0.039\n",
      "reg_loss:0.283\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:19: global_step:76039  current_step:11040\n",
      "speed: 0.171s, remaining training time: 00:02:33:42\n",
      "total_losses:0.494\n",
      "cls_loss:0.063\n",
      "reg_loss:0.431\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:22: global_step:76059  current_step:11060\n",
      "speed: 0.175s, remaining training time: 00:02:37:25\n",
      "total_losses:0.484\n",
      "cls_loss:0.108\n",
      "reg_loss:0.377\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:25: global_step:76079  current_step:11080\n",
      "speed: 0.170s, remaining training time: 00:02:33:08\n",
      "total_losses:0.449\n",
      "cls_loss:0.025\n",
      "reg_loss:0.425\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:29: global_step:76099  current_step:11100\n",
      "speed: 0.156s, remaining training time: 00:02:20:05\n",
      "total_losses:0.023\n",
      "cls_loss:0.023\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:32: global_step:76119  current_step:11120\n",
      "speed: 0.167s, remaining training time: 00:02:29:56\n",
      "total_losses:0.668\n",
      "cls_loss:0.203\n",
      "reg_loss:0.465\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:35: global_step:76139  current_step:11140\n",
      "speed: 0.153s, remaining training time: 00:02:17:13\n",
      "total_losses:0.495\n",
      "cls_loss:0.048\n",
      "reg_loss:0.447\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:39: global_step:76159  current_step:11160\n",
      "speed: 0.164s, remaining training time: 00:02:27:31\n",
      "total_losses:0.553\n",
      "cls_loss:0.036\n",
      "reg_loss:0.518\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:42: global_step:76179  current_step:11180\n",
      "speed: 0.175s, remaining training time: 00:02:36:48\n",
      "total_losses:0.385\n",
      "cls_loss:0.062\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:49: global_step:76219  current_step:11220\n",
      "speed: 0.153s, remaining training time: 00:02:17:13\n",
      "total_losses:0.324\n",
      "cls_loss:0.038\n",
      "reg_loss:0.286\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:52: global_step:76239  current_step:11240\n",
      "speed: 0.176s, remaining training time: 00:02:38:03\n",
      "total_losses:0.323\n",
      "cls_loss:0.014\n",
      "reg_loss:0.309\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:55: global_step:76259  current_step:11260\n",
      "speed: 0.160s, remaining training time: 00:02:23:41\n",
      "total_losses:0.467\n",
      "cls_loss:0.017\n",
      "reg_loss:0.450\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:54:59: global_step:76279  current_step:11280\n",
      "speed: 0.163s, remaining training time: 00:02:26:00\n",
      "total_losses:0.727\n",
      "cls_loss:0.123\n",
      "reg_loss:0.603\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:02: global_step:76299  current_step:11300\n",
      "speed: 0.161s, remaining training time: 00:02:23:46\n",
      "total_losses:0.557\n",
      "cls_loss:0.071\n",
      "reg_loss:0.486\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:05: global_step:76319  current_step:11320\n",
      "speed: 0.179s, remaining training time: 00:02:40:26\n",
      "total_losses:0.342\n",
      "cls_loss:0.016\n",
      "reg_loss:0.326\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:09: global_step:76339  current_step:11340\n",
      "speed: 0.161s, remaining training time: 00:02:24:05\n",
      "total_losses:0.528\n",
      "cls_loss:0.099\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:12: global_step:76359  current_step:11360\n",
      "speed: 0.166s, remaining training time: 00:02:28:22\n",
      "total_losses:0.393\n",
      "cls_loss:0.008\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:15: global_step:76379  current_step:11380\n",
      "speed: 0.184s, remaining training time: 00:02:44:30\n",
      "total_losses:0.700\n",
      "cls_loss:0.163\n",
      "reg_loss:0.537\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:22: global_step:76419  current_step:11420\n",
      "speed: 0.168s, remaining training time: 00:02:29:47\n",
      "total_losses:0.263\n",
      "cls_loss:0.026\n",
      "reg_loss:0.238\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:25: global_step:76439  current_step:11440\n",
      "speed: 0.149s, remaining training time: 00:02:12:44\n",
      "total_losses:0.547\n",
      "cls_loss:0.061\n",
      "reg_loss:0.486\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:29: global_step:76459  current_step:11460\n",
      "speed: 0.153s, remaining training time: 00:02:16:09\n",
      "total_losses:0.406\n",
      "cls_loss:0.036\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:32: global_step:76479  current_step:11480\n",
      "speed: 0.155s, remaining training time: 00:02:18:08\n",
      "total_losses:0.599\n",
      "cls_loss:0.222\n",
      "reg_loss:0.376\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:35: global_step:76499  current_step:11500\n",
      "speed: 0.165s, remaining training time: 00:02:27:24\n",
      "total_losses:0.475\n",
      "cls_loss:0.025\n",
      "reg_loss:0.450\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:39: global_step:76519  current_step:11520\n",
      "speed: 0.144s, remaining training time: 00:02:08:19\n",
      "total_losses:0.477\n",
      "cls_loss:0.052\n",
      "reg_loss:0.425\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:42: global_step:76539  current_step:11540\n",
      "speed: 0.168s, remaining training time: 00:02:29:59\n",
      "total_losses:0.359\n",
      "cls_loss:0.025\n",
      "reg_loss:0.333\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:45: global_step:76559  current_step:11560\n",
      "speed: 0.168s, remaining training time: 00:02:29:46\n",
      "total_losses:0.427\n",
      "cls_loss:0.028\n",
      "reg_loss:0.400\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:49: global_step:76579  current_step:11580\n",
      "speed: 0.169s, remaining training time: 00:02:30:36\n",
      "total_losses:0.719\n",
      "cls_loss:0.256\n",
      "reg_loss:0.462\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:55: global_step:76619  current_step:11620\n",
      "speed: 0.154s, remaining training time: 00:02:17:26\n",
      "total_losses:0.893\n",
      "cls_loss:0.299\n",
      "reg_loss:0.594\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:55:59: global_step:76639  current_step:11640\n",
      "speed: 0.164s, remaining training time: 00:02:25:34\n",
      "total_losses:0.659\n",
      "cls_loss:0.085\n",
      "reg_loss:0.574\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:02: global_step:76659  current_step:11660\n",
      "speed: 0.145s, remaining training time: 00:02:08:55\n",
      "total_losses:0.285\n",
      "cls_loss:0.039\n",
      "reg_loss:0.246\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:05: global_step:76679  current_step:11680\n",
      "speed: 0.163s, remaining training time: 00:02:25:00\n",
      "total_losses:0.588\n",
      "cls_loss:0.050\n",
      "reg_loss:0.538\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:09: global_step:76699  current_step:11700\n",
      "speed: 0.164s, remaining training time: 00:02:25:31\n",
      "total_losses:0.337\n",
      "cls_loss:0.044\n",
      "reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:12: global_step:76719  current_step:11720\n",
      "speed: 0.171s, remaining training time: 00:02:31:27\n",
      "total_losses:0.327\n",
      "cls_loss:0.005\n",
      "reg_loss:0.321\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:15: global_step:76739  current_step:11740\n",
      "speed: 0.158s, remaining training time: 00:02:20:37\n",
      "total_losses:0.403\n",
      "cls_loss:0.032\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:19: global_step:76759  current_step:11760\n",
      "speed: 0.180s, remaining training time: 00:02:39:31\n",
      "total_losses:0.598\n",
      "cls_loss:0.029\n",
      "reg_loss:0.569\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:22: global_step:76779  current_step:11780\n",
      "speed: 0.165s, remaining training time: 00:02:26:40\n",
      "total_losses:0.547\n",
      "cls_loss:0.110\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:29: global_step:76819  current_step:11820\n",
      "speed: 0.160s, remaining training time: 00:02:21:37\n",
      "total_losses:0.641\n",
      "cls_loss:0.151\n",
      "reg_loss:0.490\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:32: global_step:76839  current_step:11840\n",
      "speed: 0.170s, remaining training time: 00:02:30:36\n",
      "total_losses:0.237\n",
      "cls_loss:0.024\n",
      "reg_loss:0.213\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:36: global_step:76859  current_step:11860\n",
      "speed: 0.165s, remaining training time: 00:02:25:52\n",
      "total_losses:0.459\n",
      "cls_loss:0.072\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:39: global_step:76879  current_step:11880\n",
      "speed: 0.166s, remaining training time: 00:02:27:17\n",
      "total_losses:0.397\n",
      "cls_loss:0.028\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:42: global_step:76899  current_step:11900\n",
      "speed: 0.156s, remaining training time: 00:02:18:15\n",
      "total_losses:0.388\n",
      "cls_loss:0.040\n",
      "reg_loss:0.348\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:46: global_step:76919  current_step:11920\n",
      "speed: 0.178s, remaining training time: 00:02:37:17\n",
      "total_losses:0.744\n",
      "cls_loss:0.306\n",
      "reg_loss:0.438\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:49: global_step:76939  current_step:11940\n",
      "speed: 0.177s, remaining training time: 00:02:36:51\n",
      "total_losses:0.699\n",
      "cls_loss:0.223\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:52: global_step:76959  current_step:11960\n",
      "speed: 0.162s, remaining training time: 00:02:22:57\n",
      "total_losses:0.533\n",
      "cls_loss:0.104\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:56:56: global_step:76979  current_step:11980\n",
      "speed: 0.171s, remaining training time: 00:02:30:41\n",
      "total_losses:0.594\n",
      "cls_loss:0.118\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:03: global_step:77019  current_step:12020\n",
      "speed: 0.183s, remaining training time: 00:02:41:11\n",
      "total_losses:0.781\n",
      "cls_loss:0.197\n",
      "reg_loss:0.584\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:06: global_step:77039  current_step:12040\n",
      "speed: 0.154s, remaining training time: 00:02:16:18\n",
      "total_losses:0.444\n",
      "cls_loss:0.088\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:09: global_step:77059  current_step:12060\n",
      "speed: 0.162s, remaining training time: 00:02:22:58\n",
      "total_losses:0.465\n",
      "cls_loss:0.063\n",
      "reg_loss:0.402\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:13: global_step:77079  current_step:12080\n",
      "speed: 0.170s, remaining training time: 00:02:29:36\n",
      "total_losses:0.391\n",
      "cls_loss:0.028\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:16: global_step:77099  current_step:12100\n",
      "speed: 0.153s, remaining training time: 00:02:14:57\n",
      "total_losses:0.681\n",
      "cls_loss:0.041\n",
      "reg_loss:0.639\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:19: global_step:77119  current_step:12120\n",
      "speed: 0.153s, remaining training time: 00:02:15:05\n",
      "total_losses:0.424\n",
      "cls_loss:0.052\n",
      "reg_loss:0.372\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:23: global_step:77139  current_step:12140\n",
      "speed: 0.168s, remaining training time: 00:02:28:23\n",
      "total_losses:0.534\n",
      "cls_loss:0.112\n",
      "reg_loss:0.422\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:26: global_step:77159  current_step:12160\n",
      "speed: 0.160s, remaining training time: 00:02:20:56\n",
      "total_losses:0.464\n",
      "cls_loss:0.091\n",
      "reg_loss:0.373\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:29: global_step:77179  current_step:12180\n",
      "speed: 0.192s, remaining training time: 00:02:49:17\n",
      "total_losses:0.483\n",
      "cls_loss:0.069\n",
      "reg_loss:0.414\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:36: global_step:77219  current_step:12220\n",
      "speed: 0.170s, remaining training time: 00:02:29:28\n",
      "total_losses:0.632\n",
      "cls_loss:0.163\n",
      "reg_loss:0.469\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:39: global_step:77239  current_step:12240\n",
      "speed: 0.156s, remaining training time: 00:02:16:52\n",
      "total_losses:0.724\n",
      "cls_loss:0.080\n",
      "reg_loss:0.644\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:42: global_step:77259  current_step:12260\n",
      "speed: 0.166s, remaining training time: 00:02:26:09\n",
      "total_losses:0.015\n",
      "cls_loss:0.015\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:46: global_step:77279  current_step:12280\n",
      "speed: 0.168s, remaining training time: 00:02:27:21\n",
      "total_losses:1.012\n",
      "cls_loss:0.318\n",
      "reg_loss:0.694\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:49: global_step:77299  current_step:12300\n",
      "speed: 0.156s, remaining training time: 00:02:17:17\n",
      "total_losses:0.298\n",
      "cls_loss:0.017\n",
      "reg_loss:0.281\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:53: global_step:77319  current_step:12320\n",
      "speed: 0.175s, remaining training time: 00:02:33:39\n",
      "total_losses:0.445\n",
      "cls_loss:0.031\n",
      "reg_loss:0.414\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:56: global_step:77339  current_step:12340\n",
      "speed: 0.169s, remaining training time: 00:02:28:21\n",
      "total_losses:0.545\n",
      "cls_loss:0.059\n",
      "reg_loss:0.486\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:57:59: global_step:77359  current_step:12360\n",
      "speed: 0.150s, remaining training time: 00:02:11:52\n",
      "total_losses:0.983\n",
      "cls_loss:0.203\n",
      "reg_loss:0.781\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:03: global_step:77379  current_step:12380\n",
      "speed: 0.162s, remaining training time: 00:02:21:54\n",
      "total_losses:0.381\n",
      "cls_loss:0.012\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:09: global_step:77419  current_step:12420\n",
      "speed: 0.185s, remaining training time: 00:02:42:22\n",
      "total_losses:0.340\n",
      "cls_loss:0.042\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:13: global_step:77439  current_step:12440\n",
      "speed: 0.157s, remaining training time: 00:02:17:13\n",
      "total_losses:0.315\n",
      "cls_loss:0.039\n",
      "reg_loss:0.275\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:16: global_step:77459  current_step:12460\n",
      "speed: 0.170s, remaining training time: 00:02:28:31\n",
      "total_losses:0.425\n",
      "cls_loss:0.032\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:19: global_step:77479  current_step:12480\n",
      "speed: 0.147s, remaining training time: 00:02:08:19\n",
      "total_losses:0.332\n",
      "cls_loss:0.032\n",
      "reg_loss:0.300\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:23: global_step:77499  current_step:12500\n",
      "speed: 0.173s, remaining training time: 00:02:31:08\n",
      "total_losses:0.416\n",
      "cls_loss:0.046\n",
      "reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:26: global_step:77519  current_step:12520\n",
      "speed: 0.162s, remaining training time: 00:02:21:25\n",
      "total_losses:0.392\n",
      "cls_loss:0.031\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:29: global_step:77539  current_step:12540\n",
      "speed: 0.160s, remaining training time: 00:02:19:57\n",
      "total_losses:0.685\n",
      "cls_loss:0.059\n",
      "reg_loss:0.626\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:33: global_step:77559  current_step:12560\n",
      "speed: 0.164s, remaining training time: 00:02:23:23\n",
      "total_losses:0.461\n",
      "cls_loss:0.071\n",
      "reg_loss:0.390\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:36: global_step:77579  current_step:12580\n",
      "speed: 0.146s, remaining training time: 00:02:07:41\n",
      "total_losses:0.774\n",
      "cls_loss:0.110\n",
      "reg_loss:0.665\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:43: global_step:77619  current_step:12620\n",
      "speed: 0.157s, remaining training time: 00:02:17:29\n",
      "total_losses:0.645\n",
      "cls_loss:0.074\n",
      "reg_loss:0.571\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:46: global_step:77639  current_step:12640\n",
      "speed: 0.190s, remaining training time: 00:02:45:30\n",
      "total_losses:0.614\n",
      "cls_loss:0.118\n",
      "reg_loss:0.496\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:49: global_step:77659  current_step:12660\n",
      "speed: 0.177s, remaining training time: 00:02:34:07\n",
      "total_losses:0.376\n",
      "cls_loss:0.047\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:53: global_step:77679  current_step:12680\n",
      "speed: 0.172s, remaining training time: 00:02:29:35\n",
      "total_losses:0.318\n",
      "cls_loss:0.019\n",
      "reg_loss:0.299\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:58:56: global_step:77699  current_step:12700\n",
      "speed: 0.178s, remaining training time: 00:02:35:00\n",
      "total_losses:0.636\n",
      "cls_loss:0.068\n",
      "reg_loss:0.568\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:00: global_step:77719  current_step:12720\n",
      "speed: 0.167s, remaining training time: 00:02:25:25\n",
      "total_losses:0.652\n",
      "cls_loss:0.247\n",
      "reg_loss:0.405\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:03: global_step:77739  current_step:12740\n",
      "speed: 0.162s, remaining training time: 00:02:21:27\n",
      "total_losses:0.430\n",
      "cls_loss:0.062\n",
      "reg_loss:0.367\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:06: global_step:77759  current_step:12760\n",
      "speed: 0.165s, remaining training time: 00:02:23:41\n",
      "total_losses:0.419\n",
      "cls_loss:0.025\n",
      "reg_loss:0.394\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:09: global_step:77779  current_step:12780\n",
      "speed: 0.157s, remaining training time: 00:02:16:42\n",
      "total_losses:0.298\n",
      "cls_loss:0.018\n",
      "reg_loss:0.279\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:16: global_step:77819  current_step:12820\n",
      "speed: 0.154s, remaining training time: 00:02:14:00\n",
      "total_losses:0.506\n",
      "cls_loss:0.166\n",
      "reg_loss:0.340\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:20: global_step:77839  current_step:12840\n",
      "speed: 0.188s, remaining training time: 00:02:43:04\n",
      "total_losses:0.426\n",
      "cls_loss:0.070\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:23: global_step:77859  current_step:12860\n",
      "speed: 0.170s, remaining training time: 00:02:27:56\n",
      "total_losses:0.543\n",
      "cls_loss:0.155\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:26: global_step:77879  current_step:12880\n",
      "speed: 0.160s, remaining training time: 00:02:19:23\n",
      "total_losses:0.604\n",
      "cls_loss:0.280\n",
      "reg_loss:0.324\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:29: global_step:77899  current_step:12900\n",
      "speed: 0.177s, remaining training time: 00:02:33:20\n",
      "total_losses:0.570\n",
      "cls_loss:0.023\n",
      "reg_loss:0.547\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:33: global_step:77919  current_step:12920\n",
      "speed: 0.157s, remaining training time: 00:02:16:18\n",
      "total_losses:0.470\n",
      "cls_loss:0.018\n",
      "reg_loss:0.452\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:36: global_step:77939  current_step:12940\n",
      "speed: 0.164s, remaining training time: 00:02:21:57\n",
      "total_losses:0.370\n",
      "cls_loss:0.070\n",
      "reg_loss:0.300\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:39: global_step:77959  current_step:12960\n",
      "speed: 0.167s, remaining training time: 00:02:25:14\n",
      "total_losses:0.489\n",
      "cls_loss:0.067\n",
      "reg_loss:0.422\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:43: global_step:77979  current_step:12980\n",
      "speed: 0.167s, remaining training time: 00:02:24:25\n",
      "total_losses:0.434\n",
      "cls_loss:0.079\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:50: global_step:78019  current_step:13020\n",
      "speed: 0.146s, remaining training time: 00:02:06:54\n",
      "total_losses:0.456\n",
      "cls_loss:0.071\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:53: global_step:78039  current_step:13040\n",
      "speed: 0.172s, remaining training time: 00:02:28:57\n",
      "total_losses:0.793\n",
      "cls_loss:0.198\n",
      "reg_loss:0.595\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 17:59:56: global_step:78059  current_step:13060\n",
      "speed: 0.170s, remaining training time: 00:02:26:47\n",
      "total_losses:0.751\n",
      "cls_loss:0.180\n",
      "reg_loss:0.572\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:00: global_step:78079  current_step:13080\n",
      "speed: 0.169s, remaining training time: 00:02:26:32\n",
      "total_losses:0.487\n",
      "cls_loss:0.075\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:03: global_step:78099  current_step:13100\n",
      "speed: 0.165s, remaining training time: 00:02:23:08\n",
      "total_losses:0.462\n",
      "cls_loss:0.067\n",
      "reg_loss:0.395\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:06: global_step:78119  current_step:13120\n",
      "speed: 0.179s, remaining training time: 00:02:34:56\n",
      "total_losses:0.510\n",
      "cls_loss:0.113\n",
      "reg_loss:0.398\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:10: global_step:78139  current_step:13140\n",
      "speed: 0.167s, remaining training time: 00:02:24:23\n",
      "total_losses:0.626\n",
      "cls_loss:0.066\n",
      "reg_loss:0.561\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:13: global_step:78159  current_step:13160\n",
      "speed: 0.161s, remaining training time: 00:02:19:19\n",
      "total_losses:0.622\n",
      "cls_loss:0.111\n",
      "reg_loss:0.511\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:16: global_step:78179  current_step:13180\n",
      "speed: 0.172s, remaining training time: 00:02:28:26\n",
      "total_losses:0.719\n",
      "cls_loss:0.333\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:23: global_step:78219  current_step:13220\n",
      "speed: 0.181s, remaining training time: 00:02:36:31\n",
      "total_losses:0.683\n",
      "cls_loss:0.058\n",
      "reg_loss:0.625\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:27: global_step:78239  current_step:13240\n",
      "speed: 0.157s, remaining training time: 00:02:15:25\n",
      "total_losses:0.472\n",
      "cls_loss:0.072\n",
      "reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:30: global_step:78259  current_step:13260\n",
      "speed: 0.157s, remaining training time: 00:02:14:58\n",
      "total_losses:0.346\n",
      "cls_loss:0.019\n",
      "reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:33: global_step:78279  current_step:13280\n",
      "speed: 0.170s, remaining training time: 00:02:26:43\n",
      "total_losses:0.510\n",
      "cls_loss:0.089\n",
      "reg_loss:0.421\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:37: global_step:78299  current_step:13300\n",
      "speed: 0.142s, remaining training time: 00:02:01:58\n",
      "total_losses:0.736\n",
      "cls_loss:0.139\n",
      "reg_loss:0.597\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:40: global_step:78319  current_step:13320\n",
      "speed: 0.167s, remaining training time: 00:02:24:08\n",
      "total_losses:0.271\n",
      "cls_loss:0.035\n",
      "reg_loss:0.236\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:43: global_step:78339  current_step:13340\n",
      "speed: 0.145s, remaining training time: 00:02:05:04\n",
      "total_losses:0.384\n",
      "cls_loss:0.052\n",
      "reg_loss:0.332\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:46: global_step:78359  current_step:13360\n",
      "speed: 0.174s, remaining training time: 00:02:30:10\n",
      "total_losses:0.464\n",
      "cls_loss:0.052\n",
      "reg_loss:0.412\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:50: global_step:78379  current_step:13380\n",
      "speed: 0.156s, remaining training time: 00:02:14:30\n",
      "total_losses:0.430\n",
      "cls_loss:0.018\n",
      "reg_loss:0.412\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:00:57: global_step:78419  current_step:13420\n",
      "speed: 0.154s, remaining training time: 00:02:12:35\n",
      "total_losses:0.397\n",
      "cls_loss:0.041\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:00: global_step:78439  current_step:13440\n",
      "speed: 0.159s, remaining training time: 00:02:16:32\n",
      "total_losses:0.413\n",
      "cls_loss:0.024\n",
      "reg_loss:0.389\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:03: global_step:78459  current_step:13460\n",
      "speed: 0.166s, remaining training time: 00:02:23:01\n",
      "total_losses:0.373\n",
      "cls_loss:0.014\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:07: global_step:78479  current_step:13480\n",
      "speed: 0.175s, remaining training time: 00:02:30:03\n",
      "total_losses:0.509\n",
      "cls_loss:0.085\n",
      "reg_loss:0.424\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:10: global_step:78499  current_step:13500\n",
      "speed: 0.153s, remaining training time: 00:02:11:19\n",
      "total_losses:0.504\n",
      "cls_loss:0.131\n",
      "reg_loss:0.373\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:13: global_step:78519  current_step:13520\n",
      "speed: 0.165s, remaining training time: 00:02:21:20\n",
      "total_losses:0.538\n",
      "cls_loss:0.102\n",
      "reg_loss:0.436\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:17: global_step:78539  current_step:13540\n",
      "speed: 0.146s, remaining training time: 00:02:05:15\n",
      "total_losses:0.468\n",
      "cls_loss:0.038\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:20: global_step:78559  current_step:13560\n",
      "speed: 0.177s, remaining training time: 00:02:31:41\n",
      "total_losses:1.000\n",
      "cls_loss:0.230\n",
      "reg_loss:0.769\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:23: global_step:78579  current_step:13580\n",
      "speed: 0.177s, remaining training time: 00:02:31:48\n",
      "total_losses:0.542\n",
      "cls_loss:0.073\n",
      "reg_loss:0.468\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:30: global_step:78619  current_step:13620\n",
      "speed: 0.150s, remaining training time: 00:02:08:20\n",
      "total_losses:0.679\n",
      "cls_loss:0.246\n",
      "reg_loss:0.433\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:33: global_step:78639  current_step:13640\n",
      "speed: 0.161s, remaining training time: 00:02:17:29\n",
      "total_losses:0.392\n",
      "cls_loss:0.013\n",
      "reg_loss:0.379\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:36: global_step:78659  current_step:13660\n",
      "speed: 0.166s, remaining training time: 00:02:22:17\n",
      "total_losses:0.536\n",
      "cls_loss:0.090\n",
      "reg_loss:0.446\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:40: global_step:78679  current_step:13680\n",
      "speed: 0.166s, remaining training time: 00:02:22:23\n",
      "total_losses:0.620\n",
      "cls_loss:0.028\n",
      "reg_loss:0.593\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:43: global_step:78699  current_step:13700\n",
      "speed: 0.164s, remaining training time: 00:02:20:26\n",
      "total_losses:0.552\n",
      "cls_loss:0.112\n",
      "reg_loss:0.440\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:46: global_step:78719  current_step:13720\n",
      "speed: 0.183s, remaining training time: 00:02:36:25\n",
      "total_losses:0.505\n",
      "cls_loss:0.125\n",
      "reg_loss:0.380\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:50: global_step:78739  current_step:13740\n",
      "speed: 0.169s, remaining training time: 00:02:24:36\n",
      "total_losses:0.310\n",
      "cls_loss:0.053\n",
      "reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:53: global_step:78759  current_step:13760\n",
      "speed: 0.190s, remaining training time: 00:02:42:25\n",
      "total_losses:0.402\n",
      "cls_loss:0.039\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:01:56: global_step:78779  current_step:13780\n",
      "speed: 0.162s, remaining training time: 00:02:18:00\n",
      "total_losses:0.604\n",
      "cls_loss:0.281\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:03: global_step:78819  current_step:13820\n",
      "speed: 0.166s, remaining training time: 00:02:21:53\n",
      "total_losses:0.478\n",
      "cls_loss:0.067\n",
      "reg_loss:0.411\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:07: global_step:78839  current_step:13840\n",
      "speed: 0.174s, remaining training time: 00:02:28:04\n",
      "total_losses:0.693\n",
      "cls_loss:0.161\n",
      "reg_loss:0.533\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:10: global_step:78859  current_step:13860\n",
      "speed: 0.164s, remaining training time: 00:02:19:31\n",
      "total_losses:0.862\n",
      "cls_loss:0.247\n",
      "reg_loss:0.615\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:13: global_step:78879  current_step:13880\n",
      "speed: 0.161s, remaining training time: 00:02:16:49\n",
      "total_losses:0.585\n",
      "cls_loss:0.062\n",
      "reg_loss:0.523\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:17: global_step:78899  current_step:13900\n",
      "speed: 0.163s, remaining training time: 00:02:18:25\n",
      "total_losses:0.507\n",
      "cls_loss:0.124\n",
      "reg_loss:0.382\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:20: global_step:78919  current_step:13920\n",
      "speed: 0.164s, remaining training time: 00:02:19:46\n",
      "total_losses:0.727\n",
      "cls_loss:0.257\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:23: global_step:78939  current_step:13940\n",
      "speed: 0.188s, remaining training time: 00:02:39:51\n",
      "total_losses:0.567\n",
      "cls_loss:0.219\n",
      "reg_loss:0.348\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:27: global_step:78959  current_step:13960\n",
      "speed: 0.165s, remaining training time: 00:02:20:06\n",
      "total_losses:0.516\n",
      "cls_loss:0.191\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:30: global_step:78979  current_step:13980\n",
      "speed: 0.160s, remaining training time: 00:02:16:02\n",
      "total_losses:0.390\n",
      "cls_loss:0.021\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:37: global_step:79019  current_step:14020\n",
      "speed: 0.186s, remaining training time: 00:02:38:05\n",
      "total_losses:0.454\n",
      "cls_loss:0.045\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:40: global_step:79039  current_step:14040\n",
      "speed: 0.178s, remaining training time: 00:02:31:16\n",
      "total_losses:0.594\n",
      "cls_loss:0.127\n",
      "reg_loss:0.467\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:44: global_step:79059  current_step:14060\n",
      "speed: 0.179s, remaining training time: 00:02:31:36\n",
      "total_losses:0.539\n",
      "cls_loss:0.089\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:47: global_step:79079  current_step:14080\n",
      "speed: 0.153s, remaining training time: 00:02:09:34\n",
      "total_losses:0.565\n",
      "cls_loss:0.049\n",
      "reg_loss:0.516\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:50: global_step:79099  current_step:14100\n",
      "speed: 0.169s, remaining training time: 00:02:22:59\n",
      "total_losses:0.629\n",
      "cls_loss:0.110\n",
      "reg_loss:0.519\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:54: global_step:79119  current_step:14120\n",
      "speed: 0.148s, remaining training time: 00:02:05:42\n",
      "total_losses:1.013\n",
      "cls_loss:0.290\n",
      "reg_loss:0.723\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:02:57: global_step:79139  current_step:14140\n",
      "speed: 0.149s, remaining training time: 00:02:06:34\n",
      "total_losses:0.791\n",
      "cls_loss:0.237\n",
      "reg_loss:0.555\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:00: global_step:79159  current_step:14160\n",
      "speed: 0.144s, remaining training time: 00:02:02:19\n",
      "total_losses:0.359\n",
      "cls_loss:0.019\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:04: global_step:79179  current_step:14180\n",
      "speed: 0.160s, remaining training time: 00:02:15:16\n",
      "total_losses:0.634\n",
      "cls_loss:0.164\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:10: global_step:79219  current_step:14220\n",
      "speed: 0.165s, remaining training time: 00:02:19:48\n",
      "total_losses:0.447\n",
      "cls_loss:0.067\n",
      "reg_loss:0.380\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:14: global_step:79239  current_step:14240\n",
      "speed: 0.167s, remaining training time: 00:02:20:52\n",
      "total_losses:0.549\n",
      "cls_loss:0.051\n",
      "reg_loss:0.498\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:17: global_step:79259  current_step:14260\n",
      "speed: 0.170s, remaining training time: 00:02:23:21\n",
      "total_losses:0.502\n",
      "cls_loss:0.130\n",
      "reg_loss:0.373\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:20: global_step:79279  current_step:14280\n",
      "speed: 0.174s, remaining training time: 00:02:26:46\n",
      "total_losses:0.766\n",
      "cls_loss:0.055\n",
      "reg_loss:0.711\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:24: global_step:79299  current_step:14300\n",
      "speed: 0.156s, remaining training time: 00:02:11:25\n",
      "total_losses:0.439\n",
      "cls_loss:0.068\n",
      "reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:27: global_step:79319  current_step:14320\n",
      "speed: 0.189s, remaining training time: 00:02:39:40\n",
      "total_losses:0.459\n",
      "cls_loss:0.055\n",
      "reg_loss:0.405\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:30: global_step:79339  current_step:14340\n",
      "speed: 0.170s, remaining training time: 00:02:23:28\n",
      "total_losses:0.390\n",
      "cls_loss:0.065\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:34: global_step:79359  current_step:14360\n",
      "speed: 0.188s, remaining training time: 00:02:38:41\n",
      "total_losses:0.393\n",
      "cls_loss:0.030\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:37: global_step:79379  current_step:14380\n",
      "speed: 0.159s, remaining training time: 00:02:13:58\n",
      "total_losses:0.335\n",
      "cls_loss:0.048\n",
      "reg_loss:0.287\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:44: global_step:79419  current_step:14420\n",
      "speed: 0.181s, remaining training time: 00:02:32:33\n",
      "total_losses:0.530\n",
      "cls_loss:0.122\n",
      "reg_loss:0.407\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:47: global_step:79439  current_step:14440\n",
      "speed: 0.159s, remaining training time: 00:02:13:39\n",
      "total_losses:0.336\n",
      "cls_loss:0.062\n",
      "reg_loss:0.274\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:50: global_step:79459  current_step:14460\n",
      "speed: 0.169s, remaining training time: 00:02:22:23\n",
      "total_losses:0.560\n",
      "cls_loss:0.043\n",
      "reg_loss:0.517\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:54: global_step:79479  current_step:14480\n",
      "speed: 0.161s, remaining training time: 00:02:15:34\n",
      "total_losses:0.548\n",
      "cls_loss:0.080\n",
      "reg_loss:0.468\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:03:57: global_step:79499  current_step:14500\n",
      "speed: 0.150s, remaining training time: 00:02:05:59\n",
      "total_losses:0.011\n",
      "cls_loss:0.011\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:00: global_step:79519  current_step:14520\n",
      "speed: 0.162s, remaining training time: 00:02:16:29\n",
      "total_losses:0.522\n",
      "cls_loss:0.034\n",
      "reg_loss:0.488\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:04: global_step:79539  current_step:14540\n",
      "speed: 0.173s, remaining training time: 00:02:25:21\n",
      "total_losses:0.718\n",
      "cls_loss:0.132\n",
      "reg_loss:0.586\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:07: global_step:79559  current_step:14560\n",
      "speed: 0.162s, remaining training time: 00:02:16:05\n",
      "total_losses:0.532\n",
      "cls_loss:0.137\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:10: global_step:79579  current_step:14580\n",
      "speed: 0.153s, remaining training time: 00:02:08:31\n",
      "total_losses:0.323\n",
      "cls_loss:0.051\n",
      "reg_loss:0.272\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:17: global_step:79619  current_step:14620\n",
      "speed: 0.183s, remaining training time: 00:02:33:44\n",
      "total_losses:0.415\n",
      "cls_loss:0.038\n",
      "reg_loss:0.378\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:21: global_step:79639  current_step:14640\n",
      "speed: 0.163s, remaining training time: 00:02:16:49\n",
      "total_losses:0.667\n",
      "cls_loss:0.072\n",
      "reg_loss:0.595\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:24: global_step:79659  current_step:14660\n",
      "speed: 0.173s, remaining training time: 00:02:24:59\n",
      "total_losses:0.375\n",
      "cls_loss:0.155\n",
      "reg_loss:0.220\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:27: global_step:79679  current_step:14680\n",
      "speed: 0.166s, remaining training time: 00:02:19:14\n",
      "total_losses:0.531\n",
      "cls_loss:0.059\n",
      "reg_loss:0.472\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:31: global_step:79699  current_step:14700\n",
      "speed: 0.193s, remaining training time: 00:02:41:46\n",
      "total_losses:0.596\n",
      "cls_loss:0.234\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:34: global_step:79719  current_step:14720\n",
      "speed: 0.159s, remaining training time: 00:02:13:17\n",
      "total_losses:0.352\n",
      "cls_loss:0.007\n",
      "reg_loss:0.345\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:37: global_step:79739  current_step:14740\n",
      "speed: 0.159s, remaining training time: 00:02:13:24\n",
      "total_losses:0.337\n",
      "cls_loss:0.040\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:41: global_step:79759  current_step:14760\n",
      "speed: 0.162s, remaining training time: 00:02:15:26\n",
      "total_losses:0.545\n",
      "cls_loss:0.131\n",
      "reg_loss:0.414\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:44: global_step:79779  current_step:14780\n",
      "speed: 0.168s, remaining training time: 00:02:20:52\n",
      "total_losses:0.540\n",
      "cls_loss:0.099\n",
      "reg_loss:0.442\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:51: global_step:79819  current_step:14820\n",
      "speed: 0.155s, remaining training time: 00:02:09:22\n",
      "total_losses:0.353\n",
      "cls_loss:0.074\n",
      "reg_loss:0.279\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:54: global_step:79839  current_step:14840\n",
      "speed: 0.167s, remaining training time: 00:02:19:52\n",
      "total_losses:0.241\n",
      "cls_loss:0.011\n",
      "reg_loss:0.230\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:04:57: global_step:79859  current_step:14860\n",
      "speed: 0.161s, remaining training time: 00:02:14:43\n",
      "total_losses:0.525\n",
      "cls_loss:0.194\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:01: global_step:79879  current_step:14880\n",
      "speed: 0.169s, remaining training time: 00:02:21:14\n",
      "total_losses:0.645\n",
      "cls_loss:0.259\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:04: global_step:79899  current_step:14900\n",
      "speed: 0.166s, remaining training time: 00:02:18:35\n",
      "total_losses:0.577\n",
      "cls_loss:0.028\n",
      "reg_loss:0.549\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:07: global_step:79919  current_step:14920\n",
      "speed: 0.155s, remaining training time: 00:02:09:18\n",
      "total_losses:0.327\n",
      "cls_loss:0.060\n",
      "reg_loss:0.267\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:11: global_step:79939  current_step:14940\n",
      "speed: 0.158s, remaining training time: 00:02:12:09\n",
      "total_losses:0.604\n",
      "cls_loss:0.110\n",
      "reg_loss:0.494\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:14: global_step:79959  current_step:14960\n",
      "speed: 0.176s, remaining training time: 00:02:26:37\n",
      "total_losses:0.646\n",
      "cls_loss:0.153\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:17: global_step:79979  current_step:14980\n",
      "speed: 0.174s, remaining training time: 00:02:25:09\n",
      "total_losses:0.405\n",
      "cls_loss:0.055\n",
      "reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:24: global_step:80019  current_step:15020\n",
      "speed: 0.191s, remaining training time: 00:02:39:16\n",
      "total_losses:0.401\n",
      "cls_loss:0.034\n",
      "reg_loss:0.367\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:27: global_step:80039  current_step:15040\n",
      "speed: 0.178s, remaining training time: 00:02:28:13\n",
      "total_losses:0.104\n",
      "cls_loss:0.104\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:31: global_step:80059  current_step:15060\n",
      "speed: 0.158s, remaining training time: 00:02:11:34\n",
      "total_losses:0.535\n",
      "cls_loss:0.047\n",
      "reg_loss:0.488\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:34: global_step:80079  current_step:15080\n",
      "speed: 0.164s, remaining training time: 00:02:16:02\n",
      "total_losses:0.506\n",
      "cls_loss:0.017\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:37: global_step:80099  current_step:15100\n",
      "speed: 0.175s, remaining training time: 00:02:25:49\n",
      "total_losses:0.574\n",
      "cls_loss:0.088\n",
      "reg_loss:0.486\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:41: global_step:80119  current_step:15120\n",
      "speed: 0.167s, remaining training time: 00:02:19:02\n",
      "total_losses:0.249\n",
      "cls_loss:0.017\n",
      "reg_loss:0.231\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:44: global_step:80139  current_step:15140\n",
      "speed: 0.161s, remaining training time: 00:02:13:27\n",
      "total_losses:0.673\n",
      "cls_loss:0.167\n",
      "reg_loss:0.507\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:47: global_step:80159  current_step:15160\n",
      "speed: 0.165s, remaining training time: 00:02:17:02\n",
      "total_losses:0.511\n",
      "cls_loss:0.205\n",
      "reg_loss:0.307\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:51: global_step:80179  current_step:15180\n",
      "speed: 0.162s, remaining training time: 00:02:14:31\n",
      "total_losses:0.307\n",
      "cls_loss:0.030\n",
      "reg_loss:0.277\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:05:57: global_step:80219  current_step:15220\n",
      "speed: 0.165s, remaining training time: 00:02:16:56\n",
      "total_losses:0.648\n",
      "cls_loss:0.147\n",
      "reg_loss:0.501\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:01: global_step:80239  current_step:15240\n",
      "speed: 0.171s, remaining training time: 00:02:21:34\n",
      "total_losses:0.726\n",
      "cls_loss:0.144\n",
      "reg_loss:0.582\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:04: global_step:80259  current_step:15260\n",
      "speed: 0.176s, remaining training time: 00:02:25:33\n",
      "total_losses:0.418\n",
      "cls_loss:0.023\n",
      "reg_loss:0.395\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:07: global_step:80279  current_step:15280\n",
      "speed: 0.174s, remaining training time: 00:02:24:21\n",
      "total_losses:0.750\n",
      "cls_loss:0.130\n",
      "reg_loss:0.620\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:11: global_step:80299  current_step:15300\n",
      "speed: 0.154s, remaining training time: 00:02:07:47\n",
      "total_losses:0.538\n",
      "cls_loss:0.175\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:14: global_step:80319  current_step:15320\n",
      "speed: 0.171s, remaining training time: 00:02:21:11\n",
      "total_losses:0.464\n",
      "cls_loss:0.079\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:17: global_step:80339  current_step:15340\n",
      "speed: 0.147s, remaining training time: 00:02:01:57\n",
      "total_losses:0.618\n",
      "cls_loss:0.151\n",
      "reg_loss:0.467\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:21: global_step:80359  current_step:15360\n",
      "speed: 0.185s, remaining training time: 00:02:32:56\n",
      "total_losses:0.639\n",
      "cls_loss:0.149\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:24: global_step:80379  current_step:15380\n",
      "speed: 0.159s, remaining training time: 00:02:11:20\n",
      "total_losses:0.580\n",
      "cls_loss:0.123\n",
      "reg_loss:0.457\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:31: global_step:80419  current_step:15420\n",
      "speed: 0.163s, remaining training time: 00:02:14:19\n",
      "total_losses:0.326\n",
      "cls_loss:0.032\n",
      "reg_loss:0.293\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:34: global_step:80439  current_step:15440\n",
      "speed: 0.152s, remaining training time: 00:02:05:52\n",
      "total_losses:0.562\n",
      "cls_loss:0.078\n",
      "reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:37: global_step:80459  current_step:15460\n",
      "speed: 0.157s, remaining training time: 00:02:09:45\n",
      "total_losses:0.345\n",
      "cls_loss:0.053\n",
      "reg_loss:0.292\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:41: global_step:80479  current_step:15480\n",
      "speed: 0.161s, remaining training time: 00:02:12:33\n",
      "total_losses:0.534\n",
      "cls_loss:0.035\n",
      "reg_loss:0.499\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:44: global_step:80499  current_step:15500\n",
      "speed: 0.173s, remaining training time: 00:02:22:25\n",
      "total_losses:0.327\n",
      "cls_loss:0.020\n",
      "reg_loss:0.307\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:47: global_step:80519  current_step:15520\n",
      "speed: 0.165s, remaining training time: 00:02:16:07\n",
      "total_losses:0.736\n",
      "cls_loss:0.058\n",
      "reg_loss:0.677\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:51: global_step:80539  current_step:15540\n",
      "speed: 0.164s, remaining training time: 00:02:15:19\n",
      "total_losses:0.474\n",
      "cls_loss:0.073\n",
      "reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:54: global_step:80559  current_step:15560\n",
      "speed: 0.163s, remaining training time: 00:02:14:13\n",
      "total_losses:0.447\n",
      "cls_loss:0.031\n",
      "reg_loss:0.417\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:06:58: global_step:80579  current_step:15580\n",
      "speed: 0.169s, remaining training time: 00:02:19:21\n",
      "total_losses:0.674\n",
      "cls_loss:0.052\n",
      "reg_loss:0.621\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:04: global_step:80619  current_step:15620\n",
      "speed: 0.160s, remaining training time: 00:02:11:59\n",
      "total_losses:0.628\n",
      "cls_loss:0.117\n",
      "reg_loss:0.510\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:08: global_step:80639  current_step:15640\n",
      "speed: 0.191s, remaining training time: 00:02:37:22\n",
      "total_losses:0.717\n",
      "cls_loss:0.072\n",
      "reg_loss:0.645\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:11: global_step:80659  current_step:15660\n",
      "speed: 0.163s, remaining training time: 00:02:13:41\n",
      "total_losses:0.319\n",
      "cls_loss:0.020\n",
      "reg_loss:0.299\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:14: global_step:80679  current_step:15680\n",
      "speed: 0.166s, remaining training time: 00:02:16:05\n",
      "total_losses:0.952\n",
      "cls_loss:0.467\n",
      "reg_loss:0.485\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:18: global_step:80699  current_step:15700\n",
      "speed: 0.153s, remaining training time: 00:02:05:52\n",
      "total_losses:0.489\n",
      "cls_loss:0.034\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:21: global_step:80719  current_step:15720\n",
      "speed: 0.206s, remaining training time: 00:02:49:06\n",
      "total_losses:0.472\n",
      "cls_loss:0.068\n",
      "reg_loss:0.404\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:24: global_step:80739  current_step:15740\n",
      "speed: 0.153s, remaining training time: 00:02:05:21\n",
      "total_losses:0.397\n",
      "cls_loss:0.023\n",
      "reg_loss:0.375\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:28: global_step:80759  current_step:15760\n",
      "speed: 0.160s, remaining training time: 00:02:11:34\n",
      "total_losses:0.450\n",
      "cls_loss:0.028\n",
      "reg_loss:0.423\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:31: global_step:80779  current_step:15780\n",
      "speed: 0.156s, remaining training time: 00:02:07:54\n",
      "total_losses:0.890\n",
      "cls_loss:0.398\n",
      "reg_loss:0.492\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:38: global_step:80819  current_step:15820\n",
      "speed: 0.178s, remaining training time: 00:02:25:30\n",
      "total_losses:0.398\n",
      "cls_loss:0.051\n",
      "reg_loss:0.347\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:41: global_step:80839  current_step:15840\n",
      "speed: 0.172s, remaining training time: 00:02:20:52\n",
      "total_losses:0.774\n",
      "cls_loss:0.109\n",
      "reg_loss:0.665\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:44: global_step:80859  current_step:15860\n",
      "speed: 0.173s, remaining training time: 00:02:21:38\n",
      "total_losses:0.676\n",
      "cls_loss:0.221\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:48: global_step:80879  current_step:15880\n",
      "speed: 0.169s, remaining training time: 00:02:18:38\n",
      "total_losses:0.509\n",
      "cls_loss:0.029\n",
      "reg_loss:0.480\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:51: global_step:80899  current_step:15900\n",
      "speed: 0.176s, remaining training time: 00:02:24:09\n",
      "total_losses:0.559\n",
      "cls_loss:0.116\n",
      "reg_loss:0.443\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:55: global_step:80919  current_step:15920\n",
      "speed: 0.163s, remaining training time: 00:02:13:04\n",
      "total_losses:0.371\n",
      "cls_loss:0.014\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:07:58: global_step:80939  current_step:15940\n",
      "speed: 0.172s, remaining training time: 00:02:20:38\n",
      "total_losses:0.685\n",
      "cls_loss:0.209\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:01: global_step:80959  current_step:15960\n",
      "speed: 0.166s, remaining training time: 00:02:15:28\n",
      "total_losses:0.289\n",
      "cls_loss:0.057\n",
      "reg_loss:0.232\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:05: global_step:80979  current_step:15980\n",
      "speed: 0.164s, remaining training time: 00:02:14:10\n",
      "total_losses:0.478\n",
      "cls_loss:0.112\n",
      "reg_loss:0.366\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:11: global_step:81019  current_step:16020\n",
      "speed: 0.170s, remaining training time: 00:02:19:04\n",
      "total_losses:0.574\n",
      "cls_loss:0.038\n",
      "reg_loss:0.537\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:15: global_step:81039  current_step:16040\n",
      "speed: 0.175s, remaining training time: 00:02:23:01\n",
      "total_losses:0.264\n",
      "cls_loss:0.023\n",
      "reg_loss:0.240\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:18: global_step:81059  current_step:16060\n",
      "speed: 0.171s, remaining training time: 00:02:19:36\n",
      "total_losses:0.420\n",
      "cls_loss:0.078\n",
      "reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:22: global_step:81079  current_step:16080\n",
      "speed: 0.159s, remaining training time: 00:02:09:31\n",
      "total_losses:0.425\n",
      "cls_loss:0.056\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:25: global_step:81099  current_step:16100\n",
      "speed: 0.179s, remaining training time: 00:02:25:54\n",
      "total_losses:0.677\n",
      "cls_loss:0.121\n",
      "reg_loss:0.556\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:28: global_step:81119  current_step:16120\n",
      "speed: 0.163s, remaining training time: 00:02:12:48\n",
      "total_losses:0.500\n",
      "cls_loss:0.099\n",
      "reg_loss:0.401\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:32: global_step:81139  current_step:16140\n",
      "speed: 0.172s, remaining training time: 00:02:19:57\n",
      "total_losses:0.664\n",
      "cls_loss:0.170\n",
      "reg_loss:0.494\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:35: global_step:81159  current_step:16160\n",
      "speed: 0.149s, remaining training time: 00:02:01:01\n",
      "total_losses:0.413\n",
      "cls_loss:0.057\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:38: global_step:81179  current_step:16180\n",
      "speed: 0.175s, remaining training time: 00:02:22:01\n",
      "total_losses:0.464\n",
      "cls_loss:0.047\n",
      "reg_loss:0.417\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:45: global_step:81219  current_step:16220\n",
      "speed: 0.177s, remaining training time: 00:02:23:35\n",
      "total_losses:0.377\n",
      "cls_loss:0.066\n",
      "reg_loss:0.311\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:48: global_step:81239  current_step:16240\n",
      "speed: 0.170s, remaining training time: 00:02:18:09\n",
      "total_losses:0.400\n",
      "cls_loss:0.082\n",
      "reg_loss:0.318\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:52: global_step:81259  current_step:16260\n",
      "speed: 0.174s, remaining training time: 00:02:21:00\n",
      "total_losses:0.286\n",
      "cls_loss:0.023\n",
      "reg_loss:0.263\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:55: global_step:81279  current_step:16280\n",
      "speed: 0.180s, remaining training time: 00:02:26:31\n",
      "total_losses:0.359\n",
      "cls_loss:0.011\n",
      "reg_loss:0.348\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:08:58: global_step:81299  current_step:16300\n",
      "speed: 0.161s, remaining training time: 00:02:10:39\n",
      "total_losses:0.439\n",
      "cls_loss:0.024\n",
      "reg_loss:0.415\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:02: global_step:81319  current_step:16320\n",
      "speed: 0.173s, remaining training time: 00:02:20:10\n",
      "total_losses:0.221\n",
      "cls_loss:0.014\n",
      "reg_loss:0.206\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:05: global_step:81339  current_step:16340\n",
      "speed: 0.160s, remaining training time: 00:02:09:27\n",
      "total_losses:0.436\n",
      "cls_loss:0.073\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:08: global_step:81359  current_step:16360\n",
      "speed: 0.174s, remaining training time: 00:02:20:54\n",
      "total_losses:0.649\n",
      "cls_loss:0.126\n",
      "reg_loss:0.523\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:12: global_step:81379  current_step:16380\n",
      "speed: 0.170s, remaining training time: 00:02:17:49\n",
      "total_losses:0.649\n",
      "cls_loss:0.107\n",
      "reg_loss:0.542\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:18: global_step:81419  current_step:16420\n",
      "speed: 0.165s, remaining training time: 00:02:13:44\n",
      "total_losses:0.287\n",
      "cls_loss:0.020\n",
      "reg_loss:0.268\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:22: global_step:81439  current_step:16440\n",
      "speed: 0.166s, remaining training time: 00:02:14:03\n",
      "total_losses:0.413\n",
      "cls_loss:0.081\n",
      "reg_loss:0.332\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:25: global_step:81459  current_step:16460\n",
      "speed: 0.168s, remaining training time: 00:02:16:18\n",
      "total_losses:0.477\n",
      "cls_loss:0.125\n",
      "reg_loss:0.352\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:28: global_step:81479  current_step:16480\n",
      "speed: 0.177s, remaining training time: 00:02:22:59\n",
      "total_losses:0.419\n",
      "cls_loss:0.031\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:32: global_step:81499  current_step:16500\n",
      "speed: 0.173s, remaining training time: 00:02:19:38\n",
      "total_losses:0.296\n",
      "cls_loss:0.007\n",
      "reg_loss:0.289\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:35: global_step:81519  current_step:16520\n",
      "speed: 0.163s, remaining training time: 00:02:11:41\n",
      "total_losses:0.361\n",
      "cls_loss:0.033\n",
      "reg_loss:0.328\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:38: global_step:81539  current_step:16540\n",
      "speed: 0.163s, remaining training time: 00:02:11:50\n",
      "total_losses:0.381\n",
      "cls_loss:0.053\n",
      "reg_loss:0.328\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:42: global_step:81559  current_step:16560\n",
      "speed: 0.155s, remaining training time: 00:02:05:06\n",
      "total_losses:0.501\n",
      "cls_loss:0.056\n",
      "reg_loss:0.444\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:45: global_step:81579  current_step:16580\n",
      "speed: 0.167s, remaining training time: 00:02:14:53\n",
      "total_losses:0.513\n",
      "cls_loss:0.148\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:52: global_step:81619  current_step:16620\n",
      "speed: 0.154s, remaining training time: 00:02:04:18\n",
      "total_losses:0.539\n",
      "cls_loss:0.111\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:55: global_step:81639  current_step:16640\n",
      "speed: 0.178s, remaining training time: 00:02:23:09\n",
      "total_losses:0.516\n",
      "cls_loss:0.043\n",
      "reg_loss:0.473\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:09:59: global_step:81659  current_step:16660\n",
      "speed: 0.162s, remaining training time: 00:02:10:20\n",
      "total_losses:0.773\n",
      "cls_loss:0.437\n",
      "reg_loss:0.336\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:02: global_step:81679  current_step:16680\n",
      "speed: 0.171s, remaining training time: 00:02:17:54\n",
      "total_losses:0.759\n",
      "cls_loss:0.215\n",
      "reg_loss:0.544\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:05: global_step:81699  current_step:16700\n",
      "speed: 0.161s, remaining training time: 00:02:09:57\n",
      "total_losses:0.206\n",
      "cls_loss:0.010\n",
      "reg_loss:0.196\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:09: global_step:81719  current_step:16720\n",
      "speed: 0.166s, remaining training time: 00:02:13:17\n",
      "total_losses:0.515\n",
      "cls_loss:0.037\n",
      "reg_loss:0.478\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:12: global_step:81739  current_step:16740\n",
      "speed: 0.169s, remaining training time: 00:02:15:34\n",
      "total_losses:0.521\n",
      "cls_loss:0.072\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:15: global_step:81759  current_step:16760\n",
      "speed: 0.161s, remaining training time: 00:02:09:08\n",
      "total_losses:0.328\n",
      "cls_loss:0.018\n",
      "reg_loss:0.309\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:19: global_step:81779  current_step:16780\n",
      "speed: 0.159s, remaining training time: 00:02:07:55\n",
      "total_losses:0.451\n",
      "cls_loss:0.032\n",
      "reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:25: global_step:81819  current_step:16820\n",
      "speed: 0.159s, remaining training time: 00:02:08:00\n",
      "total_losses:0.409\n",
      "cls_loss:0.036\n",
      "reg_loss:0.373\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:29: global_step:81839  current_step:16840\n",
      "speed: 0.165s, remaining training time: 00:02:12:26\n",
      "total_losses:0.785\n",
      "cls_loss:0.158\n",
      "reg_loss:0.627\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:32: global_step:81859  current_step:16860\n",
      "speed: 0.165s, remaining training time: 00:02:12:42\n",
      "total_losses:0.593\n",
      "cls_loss:0.108\n",
      "reg_loss:0.485\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:35: global_step:81879  current_step:16880\n",
      "speed: 0.171s, remaining training time: 00:02:17:05\n",
      "total_losses:0.414\n",
      "cls_loss:0.031\n",
      "reg_loss:0.383\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:39: global_step:81899  current_step:16900\n",
      "speed: 0.164s, remaining training time: 00:02:11:06\n",
      "total_losses:0.574\n",
      "cls_loss:0.082\n",
      "reg_loss:0.492\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:42: global_step:81919  current_step:16920\n",
      "speed: 0.159s, remaining training time: 00:02:07:07\n",
      "total_losses:0.299\n",
      "cls_loss:0.038\n",
      "reg_loss:0.261\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:45: global_step:81939  current_step:16940\n",
      "speed: 0.154s, remaining training time: 00:02:03:34\n",
      "total_losses:0.911\n",
      "cls_loss:0.252\n",
      "reg_loss:0.659\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:49: global_step:81959  current_step:16960\n",
      "speed: 0.164s, remaining training time: 00:02:11:20\n",
      "total_losses:0.466\n",
      "cls_loss:0.079\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:52: global_step:81979  current_step:16980\n",
      "speed: 0.181s, remaining training time: 00:02:24:49\n",
      "total_losses:0.409\n",
      "cls_loss:0.055\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:10:59: global_step:82019  current_step:17020\n",
      "speed: 0.167s, remaining training time: 00:02:13:11\n",
      "total_losses:0.440\n",
      "cls_loss:0.055\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:02: global_step:82039  current_step:17040\n",
      "speed: 0.162s, remaining training time: 00:02:09:09\n",
      "total_losses:0.502\n",
      "cls_loss:0.205\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:05: global_step:82059  current_step:17060\n",
      "speed: 0.177s, remaining training time: 00:02:21:47\n",
      "total_losses:0.332\n",
      "cls_loss:0.058\n",
      "reg_loss:0.275\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:09: global_step:82079  current_step:17080\n",
      "speed: 0.168s, remaining training time: 00:02:13:55\n",
      "total_losses:0.774\n",
      "cls_loss:0.094\n",
      "reg_loss:0.679\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:12: global_step:82099  current_step:17100\n",
      "speed: 0.159s, remaining training time: 00:02:07:03\n",
      "total_losses:0.698\n",
      "cls_loss:0.276\n",
      "reg_loss:0.422\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:15: global_step:82119  current_step:17120\n",
      "speed: 0.214s, remaining training time: 00:02:50:29\n",
      "total_losses:0.407\n",
      "cls_loss:0.030\n",
      "reg_loss:0.377\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:19: global_step:82139  current_step:17140\n",
      "speed: 0.170s, remaining training time: 00:02:15:42\n",
      "total_losses:0.550\n",
      "cls_loss:0.109\n",
      "reg_loss:0.441\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:22: global_step:82159  current_step:17160\n",
      "speed: 0.177s, remaining training time: 00:02:21:16\n",
      "total_losses:0.409\n",
      "cls_loss:0.045\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:26: global_step:82179  current_step:17180\n",
      "speed: 0.154s, remaining training time: 00:02:03:03\n",
      "total_losses:0.583\n",
      "cls_loss:0.076\n",
      "reg_loss:0.507\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:32: global_step:82219  current_step:17220\n",
      "speed: 0.163s, remaining training time: 00:02:09:57\n",
      "total_losses:0.624\n",
      "cls_loss:0.175\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:36: global_step:82239  current_step:17240\n",
      "speed: 0.160s, remaining training time: 00:02:07:03\n",
      "total_losses:0.829\n",
      "cls_loss:0.348\n",
      "reg_loss:0.481\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:39: global_step:82259  current_step:17260\n",
      "speed: 0.168s, remaining training time: 00:02:13:37\n",
      "total_losses:0.633\n",
      "cls_loss:0.072\n",
      "reg_loss:0.560\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:42: global_step:82279  current_step:17280\n",
      "speed: 0.165s, remaining training time: 00:02:11:33\n",
      "total_losses:0.307\n",
      "cls_loss:0.019\n",
      "reg_loss:0.289\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:46: global_step:82299  current_step:17300\n",
      "speed: 0.166s, remaining training time: 00:02:12:04\n",
      "total_losses:0.441\n",
      "cls_loss:0.063\n",
      "reg_loss:0.378\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:49: global_step:82319  current_step:17320\n",
      "speed: 0.176s, remaining training time: 00:02:19:45\n",
      "total_losses:0.622\n",
      "cls_loss:0.193\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:52: global_step:82339  current_step:17340\n",
      "speed: 0.161s, remaining training time: 00:02:07:35\n",
      "total_losses:0.418\n",
      "cls_loss:0.092\n",
      "reg_loss:0.326\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:56: global_step:82359  current_step:17360\n",
      "speed: 0.174s, remaining training time: 00:02:18:27\n",
      "total_losses:0.015\n",
      "cls_loss:0.015\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:11:59: global_step:82379  current_step:17380\n",
      "speed: 0.167s, remaining training time: 00:02:12:47\n",
      "total_losses:0.771\n",
      "cls_loss:0.226\n",
      "reg_loss:0.545\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:06: global_step:82419  current_step:17420\n",
      "speed: 0.179s, remaining training time: 00:02:21:46\n",
      "total_losses:0.558\n",
      "cls_loss:0.022\n",
      "reg_loss:0.535\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:09: global_step:82439  current_step:17440\n",
      "speed: 0.190s, remaining training time: 00:02:30:51\n",
      "total_losses:0.459\n",
      "cls_loss:0.067\n",
      "reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:13: global_step:82459  current_step:17460\n",
      "speed: 0.159s, remaining training time: 00:02:06:17\n",
      "total_losses:0.416\n",
      "cls_loss:0.106\n",
      "reg_loss:0.309\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:16: global_step:82479  current_step:17480\n",
      "speed: 0.147s, remaining training time: 00:01:56:30\n",
      "total_losses:0.316\n",
      "cls_loss:0.056\n",
      "reg_loss:0.260\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:19: global_step:82499  current_step:17500\n",
      "speed: 0.157s, remaining training time: 00:02:04:10\n",
      "total_losses:0.329\n",
      "cls_loss:0.022\n",
      "reg_loss:0.307\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:23: global_step:82519  current_step:17520\n",
      "speed: 0.163s, remaining training time: 00:02:08:42\n",
      "total_losses:0.331\n",
      "cls_loss:0.027\n",
      "reg_loss:0.303\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:26: global_step:82539  current_step:17540\n",
      "speed: 0.162s, remaining training time: 00:02:07:55\n",
      "total_losses:0.600\n",
      "cls_loss:0.028\n",
      "reg_loss:0.572\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:29: global_step:82559  current_step:17560\n",
      "speed: 0.169s, remaining training time: 00:02:13:28\n",
      "total_losses:0.541\n",
      "cls_loss:0.044\n",
      "reg_loss:0.497\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:33: global_step:82579  current_step:17580\n",
      "speed: 0.151s, remaining training time: 00:01:59:34\n",
      "total_losses:0.400\n",
      "cls_loss:0.039\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:39: global_step:82619  current_step:17620\n",
      "speed: 0.153s, remaining training time: 00:02:00:54\n",
      "total_losses:0.243\n",
      "cls_loss:0.011\n",
      "reg_loss:0.233\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:43: global_step:82639  current_step:17640\n",
      "speed: 0.164s, remaining training time: 00:02:09:27\n",
      "total_losses:0.736\n",
      "cls_loss:0.220\n",
      "reg_loss:0.516\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:46: global_step:82659  current_step:17660\n",
      "speed: 0.162s, remaining training time: 00:02:07:52\n",
      "total_losses:0.383\n",
      "cls_loss:0.046\n",
      "reg_loss:0.337\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:49: global_step:82679  current_step:17680\n",
      "speed: 0.184s, remaining training time: 00:02:24:59\n",
      "total_losses:0.287\n",
      "cls_loss:0.019\n",
      "reg_loss:0.267\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:53: global_step:82699  current_step:17700\n",
      "speed: 0.163s, remaining training time: 00:02:08:11\n",
      "total_losses:0.558\n",
      "cls_loss:0.060\n",
      "reg_loss:0.499\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:56: global_step:82719  current_step:17720\n",
      "speed: 0.165s, remaining training time: 00:02:10:03\n",
      "total_losses:0.501\n",
      "cls_loss:0.029\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:12:59: global_step:82739  current_step:17740\n",
      "speed: 0.170s, remaining training time: 00:02:14:17\n",
      "total_losses:0.523\n",
      "cls_loss:0.079\n",
      "reg_loss:0.444\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:03: global_step:82759  current_step:17760\n",
      "speed: 0.170s, remaining training time: 00:02:13:31\n",
      "total_losses:0.515\n",
      "cls_loss:0.106\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:06: global_step:82779  current_step:17780\n",
      "speed: 0.162s, remaining training time: 00:02:07:26\n",
      "total_losses:0.605\n",
      "cls_loss:0.155\n",
      "reg_loss:0.450\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:13: global_step:82819  current_step:17820\n",
      "speed: 0.158s, remaining training time: 00:02:03:53\n",
      "total_losses:0.579\n",
      "cls_loss:0.021\n",
      "reg_loss:0.558\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:16: global_step:82839  current_step:17840\n",
      "speed: 0.159s, remaining training time: 00:02:04:40\n",
      "total_losses:0.455\n",
      "cls_loss:0.014\n",
      "reg_loss:0.441\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:19: global_step:82859  current_step:17860\n",
      "speed: 0.174s, remaining training time: 00:02:16:29\n",
      "total_losses:0.510\n",
      "cls_loss:0.039\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:23: global_step:82879  current_step:17880\n",
      "speed: 0.168s, remaining training time: 00:02:11:40\n",
      "total_losses:0.573\n",
      "cls_loss:0.144\n",
      "reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:26: global_step:82899  current_step:17900\n",
      "speed: 0.157s, remaining training time: 00:02:02:59\n",
      "total_losses:0.744\n",
      "cls_loss:0.131\n",
      "reg_loss:0.613\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:29: global_step:82919  current_step:17920\n",
      "speed: 0.164s, remaining training time: 00:02:08:27\n",
      "total_losses:0.319\n",
      "cls_loss:0.065\n",
      "reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:33: global_step:82939  current_step:17940\n",
      "speed: 0.186s, remaining training time: 00:02:25:45\n",
      "total_losses:0.598\n",
      "cls_loss:0.069\n",
      "reg_loss:0.529\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:36: global_step:82959  current_step:17960\n",
      "speed: 0.175s, remaining training time: 00:02:16:53\n",
      "total_losses:0.283\n",
      "cls_loss:0.037\n",
      "reg_loss:0.246\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:39: global_step:82979  current_step:17980\n",
      "speed: 0.167s, remaining training time: 00:02:10:47\n",
      "total_losses:0.339\n",
      "cls_loss:0.014\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:46: global_step:83019  current_step:18020\n",
      "speed: 0.156s, remaining training time: 00:02:02:27\n",
      "total_losses:0.299\n",
      "cls_loss:0.007\n",
      "reg_loss:0.292\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:49: global_step:83039  current_step:18040\n",
      "speed: 0.160s, remaining training time: 00:02:05:26\n",
      "total_losses:0.226\n",
      "cls_loss:0.017\n",
      "reg_loss:0.209\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:53: global_step:83059  current_step:18060\n",
      "speed: 0.170s, remaining training time: 00:02:12:52\n",
      "total_losses:0.438\n",
      "cls_loss:0.061\n",
      "reg_loss:0.377\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:56: global_step:83079  current_step:18080\n",
      "speed: 0.160s, remaining training time: 00:02:04:46\n",
      "total_losses:0.771\n",
      "cls_loss:0.166\n",
      "reg_loss:0.605\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:13:59: global_step:83099  current_step:18100\n",
      "speed: 0.176s, remaining training time: 00:02:17:52\n",
      "total_losses:0.267\n",
      "cls_loss:0.045\n",
      "reg_loss:0.221\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:03: global_step:83119  current_step:18120\n",
      "speed: 0.157s, remaining training time: 00:02:02:48\n",
      "total_losses:0.458\n",
      "cls_loss:0.051\n",
      "reg_loss:0.406\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:06: global_step:83139  current_step:18140\n",
      "speed: 0.167s, remaining training time: 00:02:10:40\n",
      "total_losses:0.377\n",
      "cls_loss:0.042\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:09: global_step:83159  current_step:18160\n",
      "speed: 0.148s, remaining training time: 00:01:55:30\n",
      "total_losses:0.500\n",
      "cls_loss:0.071\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:13: global_step:83179  current_step:18180\n",
      "speed: 0.152s, remaining training time: 00:01:58:16\n",
      "total_losses:0.564\n",
      "cls_loss:0.130\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:19: global_step:83219  current_step:18220\n",
      "speed: 0.163s, remaining training time: 00:02:07:27\n",
      "total_losses:0.518\n",
      "cls_loss:0.119\n",
      "reg_loss:0.400\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:23: global_step:83239  current_step:18240\n",
      "speed: 0.169s, remaining training time: 00:02:11:55\n",
      "total_losses:0.512\n",
      "cls_loss:0.041\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:26: global_step:83259  current_step:18260\n",
      "speed: 0.161s, remaining training time: 00:02:05:16\n",
      "total_losses:0.509\n",
      "cls_loss:0.077\n",
      "reg_loss:0.432\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:29: global_step:83279  current_step:18280\n",
      "speed: 0.166s, remaining training time: 00:02:09:10\n",
      "total_losses:0.515\n",
      "cls_loss:0.075\n",
      "reg_loss:0.440\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:33: global_step:83299  current_step:18300\n",
      "speed: 0.172s, remaining training time: 00:02:14:12\n",
      "total_losses:0.717\n",
      "cls_loss:0.106\n",
      "reg_loss:0.611\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:36: global_step:83319  current_step:18320\n",
      "speed: 0.164s, remaining training time: 00:02:07:36\n",
      "total_losses:0.328\n",
      "cls_loss:0.037\n",
      "reg_loss:0.291\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:39: global_step:83339  current_step:18340\n",
      "speed: 0.157s, remaining training time: 00:02:01:45\n",
      "total_losses:0.429\n",
      "cls_loss:0.074\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:43: global_step:83359  current_step:18360\n",
      "speed: 0.168s, remaining training time: 00:02:10:49\n",
      "total_losses:0.604\n",
      "cls_loss:0.103\n",
      "reg_loss:0.500\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:46: global_step:83379  current_step:18380\n",
      "speed: 0.157s, remaining training time: 00:02:01:56\n",
      "total_losses:0.836\n",
      "cls_loss:0.214\n",
      "reg_loss:0.622\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:53: global_step:83419  current_step:18420\n",
      "speed: 0.159s, remaining training time: 00:02:03:10\n",
      "total_losses:0.762\n",
      "cls_loss:0.275\n",
      "reg_loss:0.487\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:56: global_step:83439  current_step:18440\n",
      "speed: 0.159s, remaining training time: 00:02:03:15\n",
      "total_losses:0.693\n",
      "cls_loss:0.127\n",
      "reg_loss:0.565\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:14:59: global_step:83459  current_step:18460\n",
      "speed: 0.155s, remaining training time: 00:02:00:14\n",
      "total_losses:0.540\n",
      "cls_loss:0.022\n",
      "reg_loss:0.518\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:03: global_step:83479  current_step:18480\n",
      "speed: 0.170s, remaining training time: 00:02:11:48\n",
      "total_losses:0.461\n",
      "cls_loss:0.152\n",
      "reg_loss:0.309\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:06: global_step:83499  current_step:18500\n",
      "speed: 0.162s, remaining training time: 00:02:05:12\n",
      "total_losses:0.638\n",
      "cls_loss:0.064\n",
      "reg_loss:0.574\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:10: global_step:83519  current_step:18520\n",
      "speed: 0.157s, remaining training time: 00:02:01:45\n",
      "total_losses:0.014\n",
      "cls_loss:0.014\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:13: global_step:83539  current_step:18540\n",
      "speed: 0.163s, remaining training time: 00:02:05:52\n",
      "total_losses:1.084\n",
      "cls_loss:0.220\n",
      "reg_loss:0.864\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:16: global_step:83559  current_step:18560\n",
      "speed: 0.161s, remaining training time: 00:02:04:44\n",
      "total_losses:0.274\n",
      "cls_loss:0.009\n",
      "reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:20: global_step:83579  current_step:18580\n",
      "speed: 0.168s, remaining training time: 00:02:09:37\n",
      "total_losses:0.285\n",
      "cls_loss:0.032\n",
      "reg_loss:0.253\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:26: global_step:83619  current_step:18620\n",
      "speed: 0.164s, remaining training time: 00:02:06:28\n",
      "total_losses:0.589\n",
      "cls_loss:0.020\n",
      "reg_loss:0.569\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:30: global_step:83639  current_step:18640\n",
      "speed: 0.170s, remaining training time: 00:02:11:18\n",
      "total_losses:0.228\n",
      "cls_loss:0.009\n",
      "reg_loss:0.219\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:33: global_step:83659  current_step:18660\n",
      "speed: 0.175s, remaining training time: 00:02:14:51\n",
      "total_losses:0.449\n",
      "cls_loss:0.027\n",
      "reg_loss:0.422\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:37: global_step:83679  current_step:18680\n",
      "speed: 0.180s, remaining training time: 00:02:18:37\n",
      "total_losses:0.466\n",
      "cls_loss:0.141\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:40: global_step:83699  current_step:18700\n",
      "speed: 0.157s, remaining training time: 00:02:01:05\n",
      "total_losses:0.408\n",
      "cls_loss:0.033\n",
      "reg_loss:0.375\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:43: global_step:83719  current_step:18720\n",
      "speed: 0.173s, remaining training time: 00:02:13:06\n",
      "total_losses:0.564\n",
      "cls_loss:0.060\n",
      "reg_loss:0.504\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:47: global_step:83739  current_step:18740\n",
      "speed: 0.166s, remaining training time: 00:02:08:01\n",
      "total_losses:0.253\n",
      "cls_loss:0.015\n",
      "reg_loss:0.238\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:50: global_step:83759  current_step:18760\n",
      "speed: 0.169s, remaining training time: 00:02:10:02\n",
      "total_losses:0.557\n",
      "cls_loss:0.067\n",
      "reg_loss:0.490\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:15:53: global_step:83779  current_step:18780\n",
      "speed: 0.167s, remaining training time: 00:02:08:29\n",
      "total_losses:0.377\n",
      "cls_loss:0.062\n",
      "reg_loss:0.315\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:00: global_step:83819  current_step:18820\n",
      "speed: 0.171s, remaining training time: 00:02:11:57\n",
      "total_losses:0.406\n",
      "cls_loss:0.069\n",
      "reg_loss:0.336\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:04: global_step:83839  current_step:18840\n",
      "speed: 0.168s, remaining training time: 00:02:09:17\n",
      "total_losses:0.851\n",
      "cls_loss:0.190\n",
      "reg_loss:0.661\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:07: global_step:83859  current_step:18860\n",
      "speed: 0.162s, remaining training time: 00:02:04:45\n",
      "total_losses:0.494\n",
      "cls_loss:0.037\n",
      "reg_loss:0.457\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:10: global_step:83879  current_step:18880\n",
      "speed: 0.190s, remaining training time: 00:02:25:49\n",
      "total_losses:0.719\n",
      "cls_loss:0.061\n",
      "reg_loss:0.659\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:13: global_step:83899  current_step:18900\n",
      "speed: 0.163s, remaining training time: 00:02:04:56\n",
      "total_losses:0.632\n",
      "cls_loss:0.172\n",
      "reg_loss:0.460\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:17: global_step:83919  current_step:18920\n",
      "speed: 0.167s, remaining training time: 00:02:08:27\n",
      "total_losses:0.488\n",
      "cls_loss:0.061\n",
      "reg_loss:0.427\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:20: global_step:83939  current_step:18940\n",
      "speed: 0.159s, remaining training time: 00:02:01:49\n",
      "total_losses:0.529\n",
      "cls_loss:0.027\n",
      "reg_loss:0.502\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:23: global_step:83959  current_step:18960\n",
      "speed: 0.166s, remaining training time: 00:02:07:34\n",
      "total_losses:1.172\n",
      "cls_loss:0.511\n",
      "reg_loss:0.661\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:27: global_step:83979  current_step:18980\n",
      "speed: 0.161s, remaining training time: 00:02:03:48\n",
      "total_losses:0.413\n",
      "cls_loss:0.034\n",
      "reg_loss:0.379\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:34: global_step:84019  current_step:19020\n",
      "speed: 0.181s, remaining training time: 00:02:19:03\n",
      "total_losses:0.528\n",
      "cls_loss:0.073\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:37: global_step:84039  current_step:19040\n",
      "speed: 0.167s, remaining training time: 00:02:08:09\n",
      "total_losses:0.445\n",
      "cls_loss:0.056\n",
      "reg_loss:0.389\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:40: global_step:84059  current_step:19060\n",
      "speed: 0.157s, remaining training time: 00:02:00:03\n",
      "total_losses:0.579\n",
      "cls_loss:0.082\n",
      "reg_loss:0.497\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:44: global_step:84079  current_step:19080\n",
      "speed: 0.192s, remaining training time: 00:02:26:53\n",
      "total_losses:0.450\n",
      "cls_loss:0.056\n",
      "reg_loss:0.394\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:47: global_step:84099  current_step:19100\n",
      "speed: 0.160s, remaining training time: 00:02:02:45\n",
      "total_losses:0.545\n",
      "cls_loss:0.168\n",
      "reg_loss:0.376\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:50: global_step:84119  current_step:19120\n",
      "speed: 0.163s, remaining training time: 00:02:04:55\n",
      "total_losses:0.437\n",
      "cls_loss:0.114\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:54: global_step:84139  current_step:19140\n",
      "speed: 0.160s, remaining training time: 00:02:02:04\n",
      "total_losses:0.331\n",
      "cls_loss:0.017\n",
      "reg_loss:0.314\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:16:57: global_step:84159  current_step:19160\n",
      "speed: 0.174s, remaining training time: 00:02:13:03\n",
      "total_losses:0.538\n",
      "cls_loss:0.046\n",
      "reg_loss:0.492\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:00: global_step:84179  current_step:19180\n",
      "speed: 0.161s, remaining training time: 00:02:03:07\n",
      "total_losses:0.391\n",
      "cls_loss:0.022\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:07: global_step:84219  current_step:19220\n",
      "speed: 0.184s, remaining training time: 00:02:20:13\n",
      "total_losses:0.507\n",
      "cls_loss:0.060\n",
      "reg_loss:0.447\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:10: global_step:84239  current_step:19240\n",
      "speed: 0.190s, remaining training time: 00:02:24:45\n",
      "total_losses:0.413\n",
      "cls_loss:0.049\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:14: global_step:84259  current_step:19260\n",
      "speed: 0.187s, remaining training time: 00:02:22:29\n",
      "total_losses:0.493\n",
      "cls_loss:0.026\n",
      "reg_loss:0.466\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:17: global_step:84279  current_step:19280\n",
      "speed: 0.170s, remaining training time: 00:02:09:18\n",
      "total_losses:0.331\n",
      "cls_loss:0.009\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:21: global_step:84299  current_step:19300\n",
      "speed: 0.190s, remaining training time: 00:02:24:52\n",
      "total_losses:0.652\n",
      "cls_loss:0.203\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:24: global_step:84319  current_step:19320\n",
      "speed: 0.165s, remaining training time: 00:02:05:17\n",
      "total_losses:0.830\n",
      "cls_loss:0.148\n",
      "reg_loss:0.682\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:27: global_step:84339  current_step:19340\n",
      "speed: 0.166s, remaining training time: 00:02:06:22\n",
      "total_losses:0.542\n",
      "cls_loss:0.101\n",
      "reg_loss:0.441\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:31: global_step:84359  current_step:19360\n",
      "speed: 0.166s, remaining training time: 00:02:05:59\n",
      "total_losses:0.635\n",
      "cls_loss:0.181\n",
      "reg_loss:0.454\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:34: global_step:84379  current_step:19380\n",
      "speed: 0.165s, remaining training time: 00:02:05:39\n",
      "total_losses:0.436\n",
      "cls_loss:0.037\n",
      "reg_loss:0.398\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:41: global_step:84419  current_step:19420\n",
      "speed: 0.171s, remaining training time: 00:02:09:56\n",
      "total_losses:0.694\n",
      "cls_loss:0.133\n",
      "reg_loss:0.560\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:44: global_step:84439  current_step:19440\n",
      "speed: 0.166s, remaining training time: 00:02:06:00\n",
      "total_losses:0.456\n",
      "cls_loss:0.097\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:47: global_step:84459  current_step:19460\n",
      "speed: 0.172s, remaining training time: 00:02:10:49\n",
      "total_losses:0.553\n",
      "cls_loss:0.074\n",
      "reg_loss:0.480\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:51: global_step:84479  current_step:19480\n",
      "speed: 0.165s, remaining training time: 00:02:05:16\n",
      "total_losses:0.734\n",
      "cls_loss:0.079\n",
      "reg_loss:0.655\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:54: global_step:84499  current_step:19500\n",
      "speed: 0.146s, remaining training time: 00:01:51:01\n",
      "total_losses:0.392\n",
      "cls_loss:0.042\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:17:57: global_step:84519  current_step:19520\n",
      "speed: 0.169s, remaining training time: 00:02:07:53\n",
      "total_losses:0.513\n",
      "cls_loss:0.010\n",
      "reg_loss:0.504\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:01: global_step:84539  current_step:19540\n",
      "speed: 0.170s, remaining training time: 00:02:08:43\n",
      "total_losses:0.366\n",
      "cls_loss:0.068\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:04: global_step:84559  current_step:19560\n",
      "speed: 0.164s, remaining training time: 00:02:04:33\n",
      "total_losses:0.613\n",
      "cls_loss:0.193\n",
      "reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:07: global_step:84579  current_step:19580\n",
      "speed: 0.152s, remaining training time: 00:01:55:25\n",
      "total_losses:0.230\n",
      "cls_loss:0.006\n",
      "reg_loss:0.225\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:14: global_step:84619  current_step:19620\n",
      "speed: 0.179s, remaining training time: 00:02:15:29\n",
      "total_losses:0.264\n",
      "cls_loss:0.009\n",
      "reg_loss:0.255\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:17: global_step:84639  current_step:19640\n",
      "speed: 0.173s, remaining training time: 00:02:10:33\n",
      "total_losses:0.480\n",
      "cls_loss:0.032\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:21: global_step:84659  current_step:19660\n",
      "speed: 0.147s, remaining training time: 00:01:51:27\n",
      "total_losses:0.230\n",
      "cls_loss:0.014\n",
      "reg_loss:0.216\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:24: global_step:84679  current_step:19680\n",
      "speed: 0.154s, remaining training time: 00:01:56:27\n",
      "total_losses:0.269\n",
      "cls_loss:0.035\n",
      "reg_loss:0.234\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:27: global_step:84699  current_step:19700\n",
      "speed: 0.164s, remaining training time: 00:02:03:48\n",
      "total_losses:0.334\n",
      "cls_loss:0.010\n",
      "reg_loss:0.324\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:31: global_step:84719  current_step:19720\n",
      "speed: 0.165s, remaining training time: 00:02:04:29\n",
      "total_losses:0.354\n",
      "cls_loss:0.016\n",
      "reg_loss:0.337\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:34: global_step:84739  current_step:19740\n",
      "speed: 0.165s, remaining training time: 00:02:04:44\n",
      "total_losses:0.444\n",
      "cls_loss:0.082\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:37: global_step:84759  current_step:19760\n",
      "speed: 0.156s, remaining training time: 00:01:57:55\n",
      "total_losses:0.486\n",
      "cls_loss:0.092\n",
      "reg_loss:0.394\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:41: global_step:84779  current_step:19780\n",
      "speed: 0.151s, remaining training time: 00:01:53:40\n",
      "total_losses:0.971\n",
      "cls_loss:0.435\n",
      "reg_loss:0.536\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:47: global_step:84819  current_step:19820\n",
      "speed: 0.165s, remaining training time: 00:02:04:23\n",
      "total_losses:0.486\n",
      "cls_loss:0.036\n",
      "reg_loss:0.451\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:51: global_step:84839  current_step:19840\n",
      "speed: 0.164s, remaining training time: 00:02:03:15\n",
      "total_losses:0.421\n",
      "cls_loss:0.064\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:54: global_step:84859  current_step:19860\n",
      "speed: 0.176s, remaining training time: 00:02:12:19\n",
      "total_losses:0.480\n",
      "cls_loss:0.027\n",
      "reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:18:57: global_step:84879  current_step:19880\n",
      "speed: 0.157s, remaining training time: 00:01:58:17\n",
      "total_losses:0.494\n",
      "cls_loss:0.099\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:01: global_step:84899  current_step:19900\n",
      "speed: 0.161s, remaining training time: 00:02:00:50\n",
      "total_losses:0.288\n",
      "cls_loss:0.015\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:04: global_step:84919  current_step:19920\n",
      "speed: 0.170s, remaining training time: 00:02:07:22\n",
      "total_losses:0.459\n",
      "cls_loss:0.072\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:07: global_step:84939  current_step:19940\n",
      "speed: 0.160s, remaining training time: 00:01:59:58\n",
      "total_losses:0.289\n",
      "cls_loss:0.027\n",
      "reg_loss:0.262\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:11: global_step:84959  current_step:19960\n",
      "speed: 0.174s, remaining training time: 00:02:10:49\n",
      "total_losses:0.381\n",
      "cls_loss:0.052\n",
      "reg_loss:0.328\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:14: global_step:84979  current_step:19980\n",
      "speed: 0.161s, remaining training time: 00:02:00:34\n",
      "total_losses:0.620\n",
      "cls_loss:0.178\n",
      "reg_loss:0.442\n",
      "\n",
      "Weights had been saved\n",
      "************************************************************************\n",
      "2021-06-01 18:19:22: global_step:85019  current_step:20020\n",
      "speed: 0.163s, remaining training time: 00:02:02:11\n",
      "total_losses:0.443\n",
      "cls_loss:0.043\n",
      "reg_loss:0.400\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:25: global_step:85039  current_step:20040\n",
      "speed: 0.186s, remaining training time: 00:02:19:05\n",
      "total_losses:0.427\n",
      "cls_loss:0.055\n",
      "reg_loss:0.373\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:29: global_step:85059  current_step:20060\n",
      "speed: 0.176s, remaining training time: 00:02:11:50\n",
      "total_losses:0.252\n",
      "cls_loss:0.015\n",
      "reg_loss:0.237\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:32: global_step:85079  current_step:20080\n",
      "speed: 0.160s, remaining training time: 00:01:59:46\n",
      "total_losses:0.373\n",
      "cls_loss:0.022\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:35: global_step:85099  current_step:20100\n",
      "speed: 0.159s, remaining training time: 00:01:59:12\n",
      "total_losses:0.562\n",
      "cls_loss:0.117\n",
      "reg_loss:0.445\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:39: global_step:85119  current_step:20120\n",
      "speed: 0.168s, remaining training time: 00:02:05:20\n",
      "total_losses:0.981\n",
      "cls_loss:0.142\n",
      "reg_loss:0.838\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:42: global_step:85139  current_step:20140\n",
      "speed: 0.169s, remaining training time: 00:02:06:25\n",
      "total_losses:0.419\n",
      "cls_loss:0.034\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:45: global_step:85159  current_step:20160\n",
      "speed: 0.166s, remaining training time: 00:02:04:04\n",
      "total_losses:0.527\n",
      "cls_loss:0.024\n",
      "reg_loss:0.503\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:49: global_step:85179  current_step:20180\n",
      "speed: 0.187s, remaining training time: 00:02:19:32\n",
      "total_losses:1.227\n",
      "cls_loss:0.572\n",
      "reg_loss:0.655\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:55: global_step:85219  current_step:20220\n",
      "speed: 0.186s, remaining training time: 00:02:19:11\n",
      "total_losses:1.485\n",
      "cls_loss:0.903\n",
      "reg_loss:0.582\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:19:59: global_step:85239  current_step:20240\n",
      "speed: 0.171s, remaining training time: 00:02:07:17\n",
      "total_losses:0.412\n",
      "cls_loss:0.012\n",
      "reg_loss:0.400\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:02: global_step:85259  current_step:20260\n",
      "speed: 0.166s, remaining training time: 00:02:03:49\n",
      "total_losses:0.970\n",
      "cls_loss:0.061\n",
      "reg_loss:0.909\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:05: global_step:85279  current_step:20280\n",
      "speed: 0.161s, remaining training time: 00:02:00:09\n",
      "total_losses:0.561\n",
      "cls_loss:0.056\n",
      "reg_loss:0.505\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:09: global_step:85299  current_step:20300\n",
      "speed: 0.173s, remaining training time: 00:02:08:42\n",
      "total_losses:0.616\n",
      "cls_loss:0.103\n",
      "reg_loss:0.514\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:12: global_step:85319  current_step:20320\n",
      "speed: 0.169s, remaining training time: 00:02:06:10\n",
      "total_losses:0.584\n",
      "cls_loss:0.167\n",
      "reg_loss:0.417\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:15: global_step:85339  current_step:20340\n",
      "speed: 0.154s, remaining training time: 00:01:54:59\n",
      "total_losses:0.592\n",
      "cls_loss:0.169\n",
      "reg_loss:0.423\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:19: global_step:85359  current_step:20360\n",
      "speed: 0.165s, remaining training time: 00:02:02:51\n",
      "total_losses:0.637\n",
      "cls_loss:0.154\n",
      "reg_loss:0.483\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:22: global_step:85379  current_step:20380\n",
      "speed: 0.164s, remaining training time: 00:02:01:44\n",
      "total_losses:0.910\n",
      "cls_loss:0.072\n",
      "reg_loss:0.837\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:29: global_step:85419  current_step:20420\n",
      "speed: 0.164s, remaining training time: 00:02:01:40\n",
      "total_losses:0.439\n",
      "cls_loss:0.030\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:32: global_step:85439  current_step:20440\n",
      "speed: 0.167s, remaining training time: 00:02:03:52\n",
      "total_losses:0.353\n",
      "cls_loss:0.057\n",
      "reg_loss:0.296\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:35: global_step:85459  current_step:20460\n",
      "speed: 0.168s, remaining training time: 00:02:04:42\n",
      "total_losses:0.406\n",
      "cls_loss:0.023\n",
      "reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:39: global_step:85479  current_step:20480\n",
      "speed: 0.168s, remaining training time: 00:02:04:55\n",
      "total_losses:0.326\n",
      "cls_loss:0.029\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:42: global_step:85499  current_step:20500\n",
      "speed: 0.144s, remaining training time: 00:01:46:36\n",
      "total_losses:0.419\n",
      "cls_loss:0.031\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:46: global_step:85519  current_step:20520\n",
      "speed: 0.166s, remaining training time: 00:02:03:24\n",
      "total_losses:0.547\n",
      "cls_loss:0.138\n",
      "reg_loss:0.408\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:49: global_step:85539  current_step:20540\n",
      "speed: 0.178s, remaining training time: 00:02:11:51\n",
      "total_losses:0.685\n",
      "cls_loss:0.129\n",
      "reg_loss:0.556\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:52: global_step:85559  current_step:20560\n",
      "speed: 0.174s, remaining training time: 00:02:08:54\n",
      "total_losses:0.467\n",
      "cls_loss:0.110\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:20:56: global_step:85579  current_step:20580\n",
      "speed: 0.154s, remaining training time: 00:01:54:09\n",
      "total_losses:0.497\n",
      "cls_loss:0.146\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:02: global_step:85619  current_step:20620\n",
      "speed: 0.170s, remaining training time: 00:02:05:33\n",
      "total_losses:0.597\n",
      "cls_loss:0.202\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:06: global_step:85639  current_step:20640\n",
      "speed: 0.167s, remaining training time: 00:02:03:40\n",
      "total_losses:0.430\n",
      "cls_loss:0.027\n",
      "reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:09: global_step:85659  current_step:20660\n",
      "speed: 0.164s, remaining training time: 00:02:01:18\n",
      "total_losses:0.374\n",
      "cls_loss:0.042\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:12: global_step:85679  current_step:20680\n",
      "speed: 0.172s, remaining training time: 00:02:07:25\n",
      "total_losses:0.358\n",
      "cls_loss:0.038\n",
      "reg_loss:0.320\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:16: global_step:85699  current_step:20700\n",
      "speed: 0.154s, remaining training time: 00:01:53:41\n",
      "total_losses:0.246\n",
      "cls_loss:0.010\n",
      "reg_loss:0.236\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:19: global_step:85719  current_step:20720\n",
      "speed: 0.162s, remaining training time: 00:01:59:18\n",
      "total_losses:0.518\n",
      "cls_loss:0.013\n",
      "reg_loss:0.505\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:22: global_step:85739  current_step:20740\n",
      "speed: 0.157s, remaining training time: 00:01:55:33\n",
      "total_losses:0.597\n",
      "cls_loss:0.025\n",
      "reg_loss:0.571\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:26: global_step:85759  current_step:20760\n",
      "speed: 0.165s, remaining training time: 00:02:01:34\n",
      "total_losses:0.039\n",
      "cls_loss:0.039\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:29: global_step:85779  current_step:20780\n",
      "speed: 0.169s, remaining training time: 00:02:04:32\n",
      "total_losses:0.750\n",
      "cls_loss:0.069\n",
      "reg_loss:0.681\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:36: global_step:85819  current_step:20820\n",
      "speed: 0.160s, remaining training time: 00:01:57:38\n",
      "total_losses:0.677\n",
      "cls_loss:0.314\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:39: global_step:85839  current_step:20840\n",
      "speed: 0.171s, remaining training time: 00:02:05:46\n",
      "total_losses:0.373\n",
      "cls_loss:0.015\n",
      "reg_loss:0.358\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:43: global_step:85859  current_step:20860\n",
      "speed: 0.173s, remaining training time: 00:02:06:58\n",
      "total_losses:0.016\n",
      "cls_loss:0.016\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:46: global_step:85879  current_step:20880\n",
      "speed: 0.196s, remaining training time: 00:02:24:08\n",
      "total_losses:0.395\n",
      "cls_loss:0.056\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:49: global_step:85899  current_step:20900\n",
      "speed: 0.166s, remaining training time: 00:02:01:45\n",
      "total_losses:0.954\n",
      "cls_loss:0.156\n",
      "reg_loss:0.798\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:53: global_step:85919  current_step:20920\n",
      "speed: 0.162s, remaining training time: 00:01:59:15\n",
      "total_losses:0.336\n",
      "cls_loss:0.016\n",
      "reg_loss:0.320\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:56: global_step:85939  current_step:20940\n",
      "speed: 0.168s, remaining training time: 00:02:03:42\n",
      "total_losses:0.492\n",
      "cls_loss:0.038\n",
      "reg_loss:0.454\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:21:59: global_step:85959  current_step:20960\n",
      "speed: 0.165s, remaining training time: 00:02:00:51\n",
      "total_losses:0.389\n",
      "cls_loss:0.091\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:03: global_step:85979  current_step:20980\n",
      "speed: 0.163s, remaining training time: 00:01:59:55\n",
      "total_losses:0.338\n",
      "cls_loss:0.010\n",
      "reg_loss:0.328\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:09: global_step:86019  current_step:21020\n",
      "speed: 0.191s, remaining training time: 00:02:19:47\n",
      "total_losses:0.327\n",
      "cls_loss:0.043\n",
      "reg_loss:0.284\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:13: global_step:86039  current_step:21040\n",
      "speed: 0.186s, remaining training time: 00:02:16:16\n",
      "total_losses:0.531\n",
      "cls_loss:0.144\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:16: global_step:86059  current_step:21060\n",
      "speed: 0.211s, remaining training time: 00:02:34:38\n",
      "total_losses:0.486\n",
      "cls_loss:0.047\n",
      "reg_loss:0.439\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:19: global_step:86079  current_step:21080\n",
      "speed: 0.161s, remaining training time: 00:01:57:48\n",
      "total_losses:0.470\n",
      "cls_loss:0.053\n",
      "reg_loss:0.417\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:23: global_step:86099  current_step:21100\n",
      "speed: 0.170s, remaining training time: 00:02:04:18\n",
      "total_losses:0.235\n",
      "cls_loss:0.008\n",
      "reg_loss:0.227\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:26: global_step:86119  current_step:21120\n",
      "speed: 0.175s, remaining training time: 00:02:07:56\n",
      "total_losses:0.773\n",
      "cls_loss:0.263\n",
      "reg_loss:0.510\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:29: global_step:86139  current_step:21140\n",
      "speed: 0.170s, remaining training time: 00:02:04:13\n",
      "total_losses:0.332\n",
      "cls_loss:0.026\n",
      "reg_loss:0.307\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:33: global_step:86159  current_step:21160\n",
      "speed: 0.192s, remaining training time: 00:02:20:37\n",
      "total_losses:0.529\n",
      "cls_loss:0.119\n",
      "reg_loss:0.410\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:36: global_step:86179  current_step:21180\n",
      "speed: 0.158s, remaining training time: 00:01:55:29\n",
      "total_losses:0.320\n",
      "cls_loss:0.026\n",
      "reg_loss:0.294\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:43: global_step:86219  current_step:21220\n",
      "speed: 0.182s, remaining training time: 00:02:12:58\n",
      "total_losses:0.514\n",
      "cls_loss:0.100\n",
      "reg_loss:0.413\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:46: global_step:86239  current_step:21240\n",
      "speed: 0.194s, remaining training time: 00:02:21:12\n",
      "total_losses:0.331\n",
      "cls_loss:0.025\n",
      "reg_loss:0.306\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:50: global_step:86259  current_step:21260\n",
      "speed: 0.166s, remaining training time: 00:02:01:04\n",
      "total_losses:0.696\n",
      "cls_loss:0.106\n",
      "reg_loss:0.590\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:53: global_step:86279  current_step:21280\n",
      "speed: 0.153s, remaining training time: 00:01:51:14\n",
      "total_losses:0.419\n",
      "cls_loss:0.069\n",
      "reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:22:57: global_step:86299  current_step:21300\n",
      "speed: 0.184s, remaining training time: 00:02:14:02\n",
      "total_losses:0.055\n",
      "cls_loss:0.055\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:00: global_step:86319  current_step:21320\n",
      "speed: 0.167s, remaining training time: 00:02:01:52\n",
      "total_losses:0.483\n",
      "cls_loss:0.089\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:03: global_step:86339  current_step:21340\n",
      "speed: 0.164s, remaining training time: 00:01:59:34\n",
      "total_losses:0.352\n",
      "cls_loss:0.013\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:06: global_step:86359  current_step:21360\n",
      "speed: 0.171s, remaining training time: 00:02:04:39\n",
      "total_losses:0.474\n",
      "cls_loss:0.016\n",
      "reg_loss:0.458\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:10: global_step:86379  current_step:21380\n",
      "speed: 0.177s, remaining training time: 00:02:09:02\n",
      "total_losses:0.369\n",
      "cls_loss:0.018\n",
      "reg_loss:0.352\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:17: global_step:86419  current_step:21420\n",
      "speed: 0.169s, remaining training time: 00:02:03:01\n",
      "total_losses:0.856\n",
      "cls_loss:0.127\n",
      "reg_loss:0.729\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:20: global_step:86439  current_step:21440\n",
      "speed: 0.166s, remaining training time: 00:02:00:43\n",
      "total_losses:0.465\n",
      "cls_loss:0.041\n",
      "reg_loss:0.423\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:23: global_step:86459  current_step:21460\n",
      "speed: 0.162s, remaining training time: 00:01:57:32\n",
      "total_losses:0.363\n",
      "cls_loss:0.028\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:27: global_step:86479  current_step:21480\n",
      "speed: 0.153s, remaining training time: 00:01:51:14\n",
      "total_losses:0.548\n",
      "cls_loss:0.059\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:30: global_step:86499  current_step:21500\n",
      "speed: 0.173s, remaining training time: 00:02:05:33\n",
      "total_losses:0.607\n",
      "cls_loss:0.077\n",
      "reg_loss:0.530\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:33: global_step:86519  current_step:21520\n",
      "speed: 0.161s, remaining training time: 00:01:56:21\n",
      "total_losses:0.333\n",
      "cls_loss:0.065\n",
      "reg_loss:0.268\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:37: global_step:86539  current_step:21540\n",
      "speed: 0.161s, remaining training time: 00:01:56:45\n",
      "total_losses:0.551\n",
      "cls_loss:0.220\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:40: global_step:86559  current_step:21560\n",
      "speed: 0.149s, remaining training time: 00:01:47:57\n",
      "total_losses:0.790\n",
      "cls_loss:0.239\n",
      "reg_loss:0.551\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:43: global_step:86579  current_step:21580\n",
      "speed: 0.164s, remaining training time: 00:01:58:25\n",
      "total_losses:0.496\n",
      "cls_loss:0.058\n",
      "reg_loss:0.438\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:50: global_step:86619  current_step:21620\n",
      "speed: 0.182s, remaining training time: 00:02:11:51\n",
      "total_losses:0.605\n",
      "cls_loss:0.139\n",
      "reg_loss:0.465\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:53: global_step:86639  current_step:21640\n",
      "speed: 0.163s, remaining training time: 00:01:57:53\n",
      "total_losses:0.391\n",
      "cls_loss:0.035\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:23:57: global_step:86659  current_step:21660\n",
      "speed: 0.163s, remaining training time: 00:01:58:04\n",
      "total_losses:0.472\n",
      "cls_loss:0.010\n",
      "reg_loss:0.462\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:00: global_step:86679  current_step:21680\n",
      "speed: 0.161s, remaining training time: 00:01:55:56\n",
      "total_losses:0.526\n",
      "cls_loss:0.140\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:03: global_step:86699  current_step:21700\n",
      "speed: 0.160s, remaining training time: 00:01:55:08\n",
      "total_losses:0.273\n",
      "cls_loss:0.017\n",
      "reg_loss:0.257\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:07: global_step:86719  current_step:21720\n",
      "speed: 0.158s, remaining training time: 00:01:54:16\n",
      "total_losses:0.631\n",
      "cls_loss:0.071\n",
      "reg_loss:0.560\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:10: global_step:86739  current_step:21740\n",
      "speed: 0.152s, remaining training time: 00:01:49:51\n",
      "total_losses:0.527\n",
      "cls_loss:0.076\n",
      "reg_loss:0.451\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:13: global_step:86759  current_step:21760\n",
      "speed: 0.155s, remaining training time: 00:01:51:47\n",
      "total_losses:0.633\n",
      "cls_loss:0.101\n",
      "reg_loss:0.532\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:17: global_step:86779  current_step:21780\n",
      "speed: 0.184s, remaining training time: 00:02:12:28\n",
      "total_losses:0.831\n",
      "cls_loss:0.141\n",
      "reg_loss:0.689\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:23: global_step:86819  current_step:21820\n",
      "speed: 0.172s, remaining training time: 00:02:03:30\n",
      "total_losses:0.685\n",
      "cls_loss:0.053\n",
      "reg_loss:0.633\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:27: global_step:86839  current_step:21840\n",
      "speed: 0.159s, remaining training time: 00:01:54:09\n",
      "total_losses:0.876\n",
      "cls_loss:0.085\n",
      "reg_loss:0.791\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:30: global_step:86859  current_step:21860\n",
      "speed: 0.175s, remaining training time: 00:02:05:48\n",
      "total_losses:0.801\n",
      "cls_loss:0.234\n",
      "reg_loss:0.567\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:33: global_step:86879  current_step:21880\n",
      "speed: 0.161s, remaining training time: 00:01:55:31\n",
      "total_losses:0.661\n",
      "cls_loss:0.168\n",
      "reg_loss:0.494\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:37: global_step:86899  current_step:21900\n",
      "speed: 0.164s, remaining training time: 00:01:57:47\n",
      "total_losses:0.474\n",
      "cls_loss:0.091\n",
      "reg_loss:0.383\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:40: global_step:86919  current_step:21920\n",
      "speed: 0.160s, remaining training time: 00:01:54:46\n",
      "total_losses:0.455\n",
      "cls_loss:0.052\n",
      "reg_loss:0.403\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:44: global_step:86939  current_step:21940\n",
      "speed: 0.167s, remaining training time: 00:01:59:58\n",
      "total_losses:0.949\n",
      "cls_loss:0.370\n",
      "reg_loss:0.579\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:47: global_step:86959  current_step:21960\n",
      "speed: 0.171s, remaining training time: 00:02:02:20\n",
      "total_losses:0.439\n",
      "cls_loss:0.028\n",
      "reg_loss:0.411\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:50: global_step:86979  current_step:21980\n",
      "speed: 0.188s, remaining training time: 00:02:14:29\n",
      "total_losses:0.348\n",
      "cls_loss:0.027\n",
      "reg_loss:0.321\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:24:57: global_step:87019  current_step:22020\n",
      "speed: 0.160s, remaining training time: 00:01:54:16\n",
      "total_losses:0.367\n",
      "cls_loss:0.015\n",
      "reg_loss:0.352\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:00: global_step:87039  current_step:22040\n",
      "speed: 0.146s, remaining training time: 00:01:44:45\n",
      "total_losses:0.809\n",
      "cls_loss:0.317\n",
      "reg_loss:0.491\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:04: global_step:87059  current_step:22060\n",
      "speed: 0.158s, remaining training time: 00:01:53:24\n",
      "total_losses:0.331\n",
      "cls_loss:0.016\n",
      "reg_loss:0.314\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:07: global_step:87079  current_step:22080\n",
      "speed: 0.165s, remaining training time: 00:01:58:06\n",
      "total_losses:0.437\n",
      "cls_loss:0.076\n",
      "reg_loss:0.360\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:11: global_step:87099  current_step:22100\n",
      "speed: 0.172s, remaining training time: 00:02:02:54\n",
      "total_losses:0.860\n",
      "cls_loss:0.145\n",
      "reg_loss:0.715\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:14: global_step:87119  current_step:22120\n",
      "speed: 0.185s, remaining training time: 00:02:12:31\n",
      "total_losses:0.725\n",
      "cls_loss:0.181\n",
      "reg_loss:0.543\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:17: global_step:87139  current_step:22140\n",
      "speed: 0.185s, remaining training time: 00:02:12:24\n",
      "total_losses:0.554\n",
      "cls_loss:0.093\n",
      "reg_loss:0.461\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:21: global_step:87159  current_step:22160\n",
      "speed: 0.156s, remaining training time: 00:01:51:43\n",
      "total_losses:0.517\n",
      "cls_loss:0.121\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:24: global_step:87179  current_step:22180\n",
      "speed: 0.171s, remaining training time: 00:02:02:16\n",
      "total_losses:0.386\n",
      "cls_loss:0.018\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:31: global_step:87219  current_step:22220\n",
      "speed: 0.166s, remaining training time: 00:01:58:11\n",
      "total_losses:0.399\n",
      "cls_loss:0.070\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:34: global_step:87239  current_step:22240\n",
      "speed: 0.166s, remaining training time: 00:01:58:15\n",
      "total_losses:0.649\n",
      "cls_loss:0.108\n",
      "reg_loss:0.541\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:37: global_step:87259  current_step:22260\n",
      "speed: 0.165s, remaining training time: 00:01:57:47\n",
      "total_losses:0.316\n",
      "cls_loss:0.033\n",
      "reg_loss:0.283\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:41: global_step:87279  current_step:22280\n",
      "speed: 0.161s, remaining training time: 00:01:54:50\n",
      "total_losses:0.381\n",
      "cls_loss:0.059\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:44: global_step:87299  current_step:22300\n",
      "speed: 0.166s, remaining training time: 00:01:57:57\n",
      "total_losses:0.326\n",
      "cls_loss:0.025\n",
      "reg_loss:0.301\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:48: global_step:87319  current_step:22320\n",
      "speed: 0.162s, remaining training time: 00:01:55:22\n",
      "total_losses:0.443\n",
      "cls_loss:0.052\n",
      "reg_loss:0.391\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:51: global_step:87339  current_step:22340\n",
      "speed: 0.169s, remaining training time: 00:02:00:03\n",
      "total_losses:0.661\n",
      "cls_loss:0.114\n",
      "reg_loss:0.547\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:54: global_step:87359  current_step:22360\n",
      "speed: 0.165s, remaining training time: 00:01:57:22\n",
      "total_losses:0.438\n",
      "cls_loss:0.039\n",
      "reg_loss:0.399\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:25:58: global_step:87379  current_step:22380\n",
      "speed: 0.194s, remaining training time: 00:02:17:32\n",
      "total_losses:0.362\n",
      "cls_loss:0.032\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:05: global_step:87419  current_step:22420\n",
      "speed: 0.177s, remaining training time: 00:02:05:41\n",
      "total_losses:0.439\n",
      "cls_loss:0.076\n",
      "reg_loss:0.363\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:08: global_step:87439  current_step:22440\n",
      "speed: 0.162s, remaining training time: 00:01:54:56\n",
      "total_losses:0.522\n",
      "cls_loss:0.029\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:11: global_step:87459  current_step:22460\n",
      "speed: 0.167s, remaining training time: 00:01:58:13\n",
      "total_losses:0.444\n",
      "cls_loss:0.067\n",
      "reg_loss:0.377\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:15: global_step:87479  current_step:22480\n",
      "speed: 0.170s, remaining training time: 00:02:00:15\n",
      "total_losses:0.501\n",
      "cls_loss:0.075\n",
      "reg_loss:0.425\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:18: global_step:87499  current_step:22500\n",
      "speed: 0.171s, remaining training time: 00:02:01:05\n",
      "total_losses:0.420\n",
      "cls_loss:0.067\n",
      "reg_loss:0.353\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:21: global_step:87519  current_step:22520\n",
      "speed: 0.175s, remaining training time: 00:02:04:01\n",
      "total_losses:0.314\n",
      "cls_loss:0.012\n",
      "reg_loss:0.302\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:25: global_step:87539  current_step:22540\n",
      "speed: 0.168s, remaining training time: 00:01:58:34\n",
      "total_losses:0.271\n",
      "cls_loss:0.018\n",
      "reg_loss:0.253\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:28: global_step:87559  current_step:22560\n",
      "speed: 0.165s, remaining training time: 00:01:56:51\n",
      "total_losses:0.344\n",
      "cls_loss:0.042\n",
      "reg_loss:0.302\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:31: global_step:87579  current_step:22580\n",
      "speed: 0.163s, remaining training time: 00:01:55:08\n",
      "total_losses:0.288\n",
      "cls_loss:0.011\n",
      "reg_loss:0.277\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:38: global_step:87619  current_step:22620\n",
      "speed: 0.157s, remaining training time: 00:01:50:47\n",
      "total_losses:0.499\n",
      "cls_loss:0.049\n",
      "reg_loss:0.449\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:41: global_step:87639  current_step:22640\n",
      "speed: 0.176s, remaining training time: 00:02:04:03\n",
      "total_losses:0.614\n",
      "cls_loss:0.129\n",
      "reg_loss:0.485\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:45: global_step:87659  current_step:22660\n",
      "speed: 0.165s, remaining training time: 00:01:56:16\n",
      "total_losses:0.267\n",
      "cls_loss:0.016\n",
      "reg_loss:0.250\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:48: global_step:87679  current_step:22680\n",
      "speed: 0.155s, remaining training time: 00:01:49:24\n",
      "total_losses:0.424\n",
      "cls_loss:0.125\n",
      "reg_loss:0.299\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:51: global_step:87699  current_step:22700\n",
      "speed: 0.163s, remaining training time: 00:01:54:46\n",
      "total_losses:0.408\n",
      "cls_loss:0.117\n",
      "reg_loss:0.292\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:55: global_step:87719  current_step:22720\n",
      "speed: 0.154s, remaining training time: 00:01:48:14\n",
      "total_losses:0.238\n",
      "cls_loss:0.015\n",
      "reg_loss:0.223\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:26:58: global_step:87739  current_step:22740\n",
      "speed: 0.160s, remaining training time: 00:01:52:30\n",
      "total_losses:0.377\n",
      "cls_loss:0.022\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:01: global_step:87759  current_step:22760\n",
      "speed: 0.152s, remaining training time: 00:01:46:52\n",
      "total_losses:0.398\n",
      "cls_loss:0.034\n",
      "reg_loss:0.364\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:05: global_step:87779  current_step:22780\n",
      "speed: 0.174s, remaining training time: 00:02:02:12\n",
      "total_losses:0.341\n",
      "cls_loss:0.021\n",
      "reg_loss:0.320\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:11: global_step:87819  current_step:22820\n",
      "speed: 0.164s, remaining training time: 00:01:55:28\n",
      "total_losses:0.554\n",
      "cls_loss:0.209\n",
      "reg_loss:0.345\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:15: global_step:87839  current_step:22840\n",
      "speed: 0.152s, remaining training time: 00:01:46:50\n",
      "total_losses:0.222\n",
      "cls_loss:0.016\n",
      "reg_loss:0.206\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:18: global_step:87859  current_step:22860\n",
      "speed: 0.168s, remaining training time: 00:01:57:46\n",
      "total_losses:0.420\n",
      "cls_loss:0.060\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:21: global_step:87879  current_step:22880\n",
      "speed: 0.165s, remaining training time: 00:01:56:04\n",
      "total_losses:0.518\n",
      "cls_loss:0.183\n",
      "reg_loss:0.335\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:25: global_step:87899  current_step:22900\n",
      "speed: 0.175s, remaining training time: 00:02:02:53\n",
      "total_losses:0.415\n",
      "cls_loss:0.065\n",
      "reg_loss:0.350\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:28: global_step:87919  current_step:22920\n",
      "speed: 0.162s, remaining training time: 00:01:53:46\n",
      "total_losses:0.726\n",
      "cls_loss:0.082\n",
      "reg_loss:0.644\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:31: global_step:87939  current_step:22940\n",
      "speed: 0.156s, remaining training time: 00:01:49:29\n",
      "total_losses:0.688\n",
      "cls_loss:0.147\n",
      "reg_loss:0.541\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:35: global_step:87959  current_step:22960\n",
      "speed: 0.162s, remaining training time: 00:01:53:34\n",
      "total_losses:0.460\n",
      "cls_loss:0.076\n",
      "reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:38: global_step:87979  current_step:22980\n",
      "speed: 0.191s, remaining training time: 00:02:14:04\n",
      "total_losses:0.467\n",
      "cls_loss:0.079\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:45: global_step:88019  current_step:23020\n",
      "speed: 0.170s, remaining training time: 00:01:59:15\n",
      "total_losses:0.570\n",
      "cls_loss:0.083\n",
      "reg_loss:0.487\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:48: global_step:88039  current_step:23040\n",
      "speed: 0.162s, remaining training time: 00:01:53:35\n",
      "total_losses:0.499\n",
      "cls_loss:0.103\n",
      "reg_loss:0.396\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:52: global_step:88059  current_step:23060\n",
      "speed: 0.190s, remaining training time: 00:02:12:39\n",
      "total_losses:0.673\n",
      "cls_loss:0.120\n",
      "reg_loss:0.552\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:55: global_step:88079  current_step:23080\n",
      "speed: 0.177s, remaining training time: 00:02:03:23\n",
      "total_losses:0.394\n",
      "cls_loss:0.022\n",
      "reg_loss:0.372\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:27:58: global_step:88099  current_step:23100\n",
      "speed: 0.159s, remaining training time: 00:01:51:07\n",
      "total_losses:0.872\n",
      "cls_loss:0.133\n",
      "reg_loss:0.739\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:02: global_step:88119  current_step:23120\n",
      "speed: 0.160s, remaining training time: 00:01:51:57\n",
      "total_losses:0.626\n",
      "cls_loss:0.070\n",
      "reg_loss:0.556\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:05: global_step:88139  current_step:23140\n",
      "speed: 0.186s, remaining training time: 00:02:10:03\n",
      "total_losses:0.434\n",
      "cls_loss:0.035\n",
      "reg_loss:0.399\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:08: global_step:88159  current_step:23160\n",
      "speed: 0.168s, remaining training time: 00:01:56:58\n",
      "total_losses:0.545\n",
      "cls_loss:0.092\n",
      "reg_loss:0.453\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:12: global_step:88179  current_step:23180\n",
      "speed: 0.162s, remaining training time: 00:01:52:37\n",
      "total_losses:0.289\n",
      "cls_loss:0.016\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:19: global_step:88219  current_step:23220\n",
      "speed: 0.178s, remaining training time: 00:02:04:07\n",
      "total_losses:0.411\n",
      "cls_loss:0.050\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:22: global_step:88239  current_step:23240\n",
      "speed: 0.170s, remaining training time: 00:01:58:06\n",
      "total_losses:0.454\n",
      "cls_loss:0.081\n",
      "reg_loss:0.374\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:25: global_step:88259  current_step:23260\n",
      "speed: 0.167s, remaining training time: 00:01:56:23\n",
      "total_losses:0.282\n",
      "cls_loss:0.044\n",
      "reg_loss:0.237\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:29: global_step:88279  current_step:23280\n",
      "speed: 0.172s, remaining training time: 00:01:59:18\n",
      "total_losses:0.356\n",
      "cls_loss:0.046\n",
      "reg_loss:0.310\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:32: global_step:88299  current_step:23300\n",
      "speed: 0.169s, remaining training time: 00:01:57:19\n",
      "total_losses:0.447\n",
      "cls_loss:0.032\n",
      "reg_loss:0.415\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:35: global_step:88319  current_step:23320\n",
      "speed: 0.177s, remaining training time: 00:02:02:59\n",
      "total_losses:0.439\n",
      "cls_loss:0.024\n",
      "reg_loss:0.415\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:39: global_step:88339  current_step:23340\n",
      "speed: 0.161s, remaining training time: 00:01:51:53\n",
      "total_losses:0.609\n",
      "cls_loss:0.133\n",
      "reg_loss:0.476\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:42: global_step:88359  current_step:23360\n",
      "speed: 0.164s, remaining training time: 00:01:53:53\n",
      "total_losses:0.430\n",
      "cls_loss:0.061\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:45: global_step:88379  current_step:23380\n",
      "speed: 0.163s, remaining training time: 00:01:52:48\n",
      "total_losses:0.328\n",
      "cls_loss:0.022\n",
      "reg_loss:0.306\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:52: global_step:88419  current_step:23420\n",
      "speed: 0.177s, remaining training time: 00:02:02:59\n",
      "total_losses:0.426\n",
      "cls_loss:0.014\n",
      "reg_loss:0.412\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:55: global_step:88439  current_step:23440\n",
      "speed: 0.167s, remaining training time: 00:01:55:31\n",
      "total_losses:0.325\n",
      "cls_loss:0.020\n",
      "reg_loss:0.305\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:28:59: global_step:88459  current_step:23460\n",
      "speed: 0.153s, remaining training time: 00:01:45:36\n",
      "total_losses:0.673\n",
      "cls_loss:0.124\n",
      "reg_loss:0.549\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:02: global_step:88479  current_step:23480\n",
      "speed: 0.161s, remaining training time: 00:01:51:25\n",
      "total_losses:0.698\n",
      "cls_loss:0.167\n",
      "reg_loss:0.531\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:06: global_step:88499  current_step:23500\n",
      "speed: 0.166s, remaining training time: 00:01:54:57\n",
      "total_losses:0.771\n",
      "cls_loss:0.225\n",
      "reg_loss:0.546\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:09: global_step:88519  current_step:23520\n",
      "speed: 0.158s, remaining training time: 00:01:48:59\n",
      "total_losses:0.656\n",
      "cls_loss:0.072\n",
      "reg_loss:0.585\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:12: global_step:88539  current_step:23540\n",
      "speed: 0.166s, remaining training time: 00:01:55:00\n",
      "total_losses:0.417\n",
      "cls_loss:0.047\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:16: global_step:88559  current_step:23560\n",
      "speed: 0.168s, remaining training time: 00:01:56:10\n",
      "total_losses:0.409\n",
      "cls_loss:0.090\n",
      "reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:19: global_step:88579  current_step:23580\n",
      "speed: 0.168s, remaining training time: 00:01:56:02\n",
      "total_losses:0.622\n",
      "cls_loss:0.189\n",
      "reg_loss:0.433\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:26: global_step:88619  current_step:23620\n",
      "speed: 0.168s, remaining training time: 00:01:56:07\n",
      "total_losses:0.012\n",
      "cls_loss:0.012\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:29: global_step:88639  current_step:23640\n",
      "speed: 0.165s, remaining training time: 00:01:53:33\n",
      "total_losses:0.759\n",
      "cls_loss:0.296\n",
      "reg_loss:0.463\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:32: global_step:88659  current_step:23660\n",
      "speed: 0.194s, remaining training time: 00:02:13:59\n",
      "total_losses:0.537\n",
      "cls_loss:0.027\n",
      "reg_loss:0.510\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:36: global_step:88679  current_step:23680\n",
      "speed: 0.156s, remaining training time: 00:01:47:29\n",
      "total_losses:0.551\n",
      "cls_loss:0.033\n",
      "reg_loss:0.519\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:39: global_step:88699  current_step:23700\n",
      "speed: 0.164s, remaining training time: 00:01:52:55\n",
      "total_losses:0.274\n",
      "cls_loss:0.027\n",
      "reg_loss:0.247\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:42: global_step:88719  current_step:23720\n",
      "speed: 0.169s, remaining training time: 00:01:56:31\n",
      "total_losses:0.402\n",
      "cls_loss:0.032\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:46: global_step:88739  current_step:23740\n",
      "speed: 0.159s, remaining training time: 00:01:49:36\n",
      "total_losses:0.242\n",
      "cls_loss:0.050\n",
      "reg_loss:0.193\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:49: global_step:88759  current_step:23760\n",
      "speed: 0.170s, remaining training time: 00:01:56:42\n",
      "total_losses:0.269\n",
      "cls_loss:0.023\n",
      "reg_loss:0.245\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:52: global_step:88779  current_step:23780\n",
      "speed: 0.173s, remaining training time: 00:01:59:06\n",
      "total_losses:0.453\n",
      "cls_loss:0.011\n",
      "reg_loss:0.442\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:29:59: global_step:88819  current_step:23820\n",
      "speed: 0.161s, remaining training time: 00:01:50:39\n",
      "total_losses:0.447\n",
      "cls_loss:0.061\n",
      "reg_loss:0.386\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:02: global_step:88839  current_step:23840\n",
      "speed: 0.147s, remaining training time: 00:01:40:57\n",
      "total_losses:0.330\n",
      "cls_loss:0.023\n",
      "reg_loss:0.308\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:06: global_step:88859  current_step:23860\n",
      "speed: 0.171s, remaining training time: 00:01:57:34\n",
      "total_losses:0.544\n",
      "cls_loss:0.074\n",
      "reg_loss:0.470\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:09: global_step:88879  current_step:23880\n",
      "speed: 0.165s, remaining training time: 00:01:52:48\n",
      "total_losses:0.356\n",
      "cls_loss:0.073\n",
      "reg_loss:0.283\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:12: global_step:88899  current_step:23900\n",
      "speed: 0.174s, remaining training time: 00:01:59:17\n",
      "total_losses:0.719\n",
      "cls_loss:0.135\n",
      "reg_loss:0.584\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:16: global_step:88919  current_step:23920\n",
      "speed: 0.173s, remaining training time: 00:01:58:43\n",
      "total_losses:0.353\n",
      "cls_loss:0.030\n",
      "reg_loss:0.323\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:19: global_step:88939  current_step:23940\n",
      "speed: 0.156s, remaining training time: 00:01:47:00\n",
      "total_losses:0.450\n",
      "cls_loss:0.019\n",
      "reg_loss:0.431\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:22: global_step:88959  current_step:23960\n",
      "speed: 0.172s, remaining training time: 00:01:57:40\n",
      "total_losses:0.382\n",
      "cls_loss:0.015\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:26: global_step:88979  current_step:23980\n",
      "speed: 0.168s, remaining training time: 00:01:54:55\n",
      "total_losses:0.552\n",
      "cls_loss:0.081\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:33: global_step:89019  current_step:24020\n",
      "speed: 0.183s, remaining training time: 00:02:05:01\n",
      "total_losses:0.542\n",
      "cls_loss:0.020\n",
      "reg_loss:0.522\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:36: global_step:89039  current_step:24040\n",
      "speed: 0.192s, remaining training time: 00:02:11:06\n",
      "total_losses:0.556\n",
      "cls_loss:0.037\n",
      "reg_loss:0.518\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:39: global_step:89059  current_step:24060\n",
      "speed: 0.169s, remaining training time: 00:01:55:16\n",
      "total_losses:0.607\n",
      "cls_loss:0.027\n",
      "reg_loss:0.580\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:43: global_step:89079  current_step:24080\n",
      "speed: 0.181s, remaining training time: 00:02:03:22\n",
      "total_losses:0.409\n",
      "cls_loss:0.017\n",
      "reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:46: global_step:89099  current_step:24100\n",
      "speed: 0.164s, remaining training time: 00:01:51:53\n",
      "total_losses:0.364\n",
      "cls_loss:0.015\n",
      "reg_loss:0.349\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:49: global_step:89119  current_step:24120\n",
      "speed: 0.163s, remaining training time: 00:01:50:58\n",
      "total_losses:0.313\n",
      "cls_loss:0.040\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:53: global_step:89139  current_step:24140\n",
      "speed: 0.149s, remaining training time: 00:01:41:19\n",
      "total_losses:1.812\n",
      "cls_loss:1.054\n",
      "reg_loss:0.758\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:56: global_step:89159  current_step:24160\n",
      "speed: 0.157s, remaining training time: 00:01:46:49\n",
      "total_losses:0.537\n",
      "cls_loss:0.013\n",
      "reg_loss:0.523\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:30:59: global_step:89179  current_step:24180\n",
      "speed: 0.166s, remaining training time: 00:01:52:50\n",
      "total_losses:0.334\n",
      "cls_loss:0.060\n",
      "reg_loss:0.273\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:06: global_step:89219  current_step:24220\n",
      "speed: 0.187s, remaining training time: 00:02:06:58\n",
      "total_losses:0.283\n",
      "cls_loss:0.022\n",
      "reg_loss:0.261\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:09: global_step:89239  current_step:24240\n",
      "speed: 0.165s, remaining training time: 00:01:52:08\n",
      "total_losses:0.154\n",
      "cls_loss:0.004\n",
      "reg_loss:0.149\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:13: global_step:89259  current_step:24260\n",
      "speed: 0.173s, remaining training time: 00:01:57:21\n",
      "total_losses:0.431\n",
      "cls_loss:0.025\n",
      "reg_loss:0.406\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:16: global_step:89279  current_step:24280\n",
      "speed: 0.166s, remaining training time: 00:01:52:26\n",
      "total_losses:0.243\n",
      "cls_loss:0.025\n",
      "reg_loss:0.218\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:20: global_step:89299  current_step:24300\n",
      "speed: 0.163s, remaining training time: 00:01:50:51\n",
      "total_losses:0.414\n",
      "cls_loss:0.037\n",
      "reg_loss:0.377\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:23: global_step:89319  current_step:24320\n",
      "speed: 0.164s, remaining training time: 00:01:51:22\n",
      "total_losses:0.625\n",
      "cls_loss:0.121\n",
      "reg_loss:0.504\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:26: global_step:89339  current_step:24340\n",
      "speed: 0.168s, remaining training time: 00:01:54:11\n",
      "total_losses:0.503\n",
      "cls_loss:0.070\n",
      "reg_loss:0.433\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:30: global_step:89359  current_step:24360\n",
      "speed: 0.170s, remaining training time: 00:01:55:01\n",
      "total_losses:0.411\n",
      "cls_loss:0.060\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:33: global_step:89379  current_step:24380\n",
      "speed: 0.179s, remaining training time: 00:02:00:56\n",
      "total_losses:0.584\n",
      "cls_loss:0.085\n",
      "reg_loss:0.499\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:40: global_step:89419  current_step:24420\n",
      "speed: 0.154s, remaining training time: 00:01:44:23\n",
      "total_losses:0.589\n",
      "cls_loss:0.059\n",
      "reg_loss:0.530\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:43: global_step:89439  current_step:24440\n",
      "speed: 0.168s, remaining training time: 00:01:53:39\n",
      "total_losses:0.468\n",
      "cls_loss:0.080\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:46: global_step:89459  current_step:24460\n",
      "speed: 0.164s, remaining training time: 00:01:50:34\n",
      "total_losses:0.514\n",
      "cls_loss:0.090\n",
      "reg_loss:0.424\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:50: global_step:89479  current_step:24480\n",
      "speed: 0.174s, remaining training time: 00:01:57:25\n",
      "total_losses:0.452\n",
      "cls_loss:0.123\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:53: global_step:89499  current_step:24500\n",
      "speed: 0.171s, remaining training time: 00:01:55:18\n",
      "total_losses:0.674\n",
      "cls_loss:0.156\n",
      "reg_loss:0.518\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:31:57: global_step:89519  current_step:24520\n",
      "speed: 0.176s, remaining training time: 00:01:58:42\n",
      "total_losses:0.483\n",
      "cls_loss:0.054\n",
      "reg_loss:0.429\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:00: global_step:89539  current_step:24540\n",
      "speed: 0.147s, remaining training time: 00:01:38:50\n",
      "total_losses:0.657\n",
      "cls_loss:0.183\n",
      "reg_loss:0.474\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:03: global_step:89559  current_step:24560\n",
      "speed: 0.188s, remaining training time: 00:02:06:25\n",
      "total_losses:0.367\n",
      "cls_loss:0.036\n",
      "reg_loss:0.332\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:07: global_step:89579  current_step:24580\n",
      "speed: 0.160s, remaining training time: 00:01:47:29\n",
      "total_losses:0.394\n",
      "cls_loss:0.053\n",
      "reg_loss:0.340\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:13: global_step:89619  current_step:24620\n",
      "speed: 0.163s, remaining training time: 00:01:49:38\n",
      "total_losses:0.430\n",
      "cls_loss:0.079\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:17: global_step:89639  current_step:24640\n",
      "speed: 0.172s, remaining training time: 00:01:55:23\n",
      "total_losses:0.371\n",
      "cls_loss:0.049\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:20: global_step:89659  current_step:24660\n",
      "speed: 0.176s, remaining training time: 00:01:58:25\n",
      "total_losses:0.570\n",
      "cls_loss:0.098\n",
      "reg_loss:0.473\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:23: global_step:89679  current_step:24680\n",
      "speed: 0.165s, remaining training time: 00:01:50:59\n",
      "total_losses:0.491\n",
      "cls_loss:0.101\n",
      "reg_loss:0.390\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:27: global_step:89699  current_step:24700\n",
      "speed: 0.163s, remaining training time: 00:01:49:13\n",
      "total_losses:0.428\n",
      "cls_loss:0.065\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:30: global_step:89719  current_step:24720\n",
      "speed: 0.168s, remaining training time: 00:01:52:54\n",
      "total_losses:0.624\n",
      "cls_loss:0.010\n",
      "reg_loss:0.614\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:33: global_step:89739  current_step:24740\n",
      "speed: 0.172s, remaining training time: 00:01:55:17\n",
      "total_losses:0.508\n",
      "cls_loss:0.211\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:37: global_step:89759  current_step:24760\n",
      "speed: 0.172s, remaining training time: 00:01:55:23\n",
      "total_losses:0.469\n",
      "cls_loss:0.014\n",
      "reg_loss:0.455\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:40: global_step:89779  current_step:24780\n",
      "speed: 0.168s, remaining training time: 00:01:52:49\n",
      "total_losses:0.017\n",
      "cls_loss:0.017\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:47: global_step:89819  current_step:24820\n",
      "speed: 0.157s, remaining training time: 00:01:45:19\n",
      "total_losses:0.245\n",
      "cls_loss:0.007\n",
      "reg_loss:0.239\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:50: global_step:89839  current_step:24840\n",
      "speed: 0.152s, remaining training time: 00:01:41:47\n",
      "total_losses:0.249\n",
      "cls_loss:0.020\n",
      "reg_loss:0.229\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:53: global_step:89859  current_step:24860\n",
      "speed: 0.166s, remaining training time: 00:01:51:22\n",
      "total_losses:0.441\n",
      "cls_loss:0.085\n",
      "reg_loss:0.356\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:32:57: global_step:89879  current_step:24880\n",
      "speed: 0.169s, remaining training time: 00:01:53:09\n",
      "total_losses:0.718\n",
      "cls_loss:0.081\n",
      "reg_loss:0.637\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:00: global_step:89899  current_step:24900\n",
      "speed: 0.157s, remaining training time: 00:01:44:45\n",
      "total_losses:0.335\n",
      "cls_loss:0.013\n",
      "reg_loss:0.322\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:03: global_step:89919  current_step:24920\n",
      "speed: 0.168s, remaining training time: 00:01:52:03\n",
      "total_losses:0.447\n",
      "cls_loss:0.039\n",
      "reg_loss:0.408\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:07: global_step:89939  current_step:24940\n",
      "speed: 0.148s, remaining training time: 00:01:38:47\n",
      "total_losses:0.476\n",
      "cls_loss:0.066\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:10: global_step:89959  current_step:24960\n",
      "speed: 0.171s, remaining training time: 00:01:54:10\n",
      "total_losses:0.481\n",
      "cls_loss:0.088\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:13: global_step:89979  current_step:24980\n",
      "speed: 0.156s, remaining training time: 00:01:44:16\n",
      "total_losses:0.510\n",
      "cls_loss:0.046\n",
      "reg_loss:0.464\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:20: global_step:90019  current_step:25020\n",
      "speed: 0.168s, remaining training time: 00:01:51:53\n",
      "total_losses:0.462\n",
      "cls_loss:0.070\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:23: global_step:90039  current_step:25040\n",
      "speed: 0.154s, remaining training time: 00:01:42:43\n",
      "total_losses:0.563\n",
      "cls_loss:0.070\n",
      "reg_loss:0.493\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:27: global_step:90059  current_step:25060\n",
      "speed: 0.162s, remaining training time: 00:01:47:53\n",
      "total_losses:0.399\n",
      "cls_loss:0.074\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:30: global_step:90079  current_step:25080\n",
      "speed: 0.167s, remaining training time: 00:01:51:11\n",
      "total_losses:0.671\n",
      "cls_loss:0.038\n",
      "reg_loss:0.633\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:33: global_step:90099  current_step:25100\n",
      "speed: 0.168s, remaining training time: 00:01:51:40\n",
      "total_losses:0.719\n",
      "cls_loss:0.128\n",
      "reg_loss:0.592\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:37: global_step:90119  current_step:25120\n",
      "speed: 0.155s, remaining training time: 00:01:43:04\n",
      "total_losses:0.474\n",
      "cls_loss:0.049\n",
      "reg_loss:0.425\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:40: global_step:90139  current_step:25140\n",
      "speed: 0.206s, remaining training time: 00:02:17:00\n",
      "total_losses:0.568\n",
      "cls_loss:0.107\n",
      "reg_loss:0.460\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:43: global_step:90159  current_step:25160\n",
      "speed: 0.171s, remaining training time: 00:01:53:52\n",
      "total_losses:0.534\n",
      "cls_loss:0.103\n",
      "reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:47: global_step:90179  current_step:25180\n",
      "speed: 0.165s, remaining training time: 00:01:49:37\n",
      "total_losses:0.397\n",
      "cls_loss:0.027\n",
      "reg_loss:0.370\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:54: global_step:90219  current_step:25220\n",
      "speed: 0.161s, remaining training time: 00:01:46:32\n",
      "total_losses:0.581\n",
      "cls_loss:0.108\n",
      "reg_loss:0.473\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:33:57: global_step:90239  current_step:25240\n",
      "speed: 0.156s, remaining training time: 00:01:43:11\n",
      "total_losses:0.401\n",
      "cls_loss:0.060\n",
      "reg_loss:0.341\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:00: global_step:90259  current_step:25260\n",
      "speed: 0.167s, remaining training time: 00:01:50:49\n",
      "total_losses:0.669\n",
      "cls_loss:0.198\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:04: global_step:90279  current_step:25280\n",
      "speed: 0.165s, remaining training time: 00:01:49:24\n",
      "total_losses:0.462\n",
      "cls_loss:0.065\n",
      "reg_loss:0.397\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:07: global_step:90299  current_step:25300\n",
      "speed: 0.154s, remaining training time: 00:01:42:12\n",
      "total_losses:0.638\n",
      "cls_loss:0.032\n",
      "reg_loss:0.606\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:10: global_step:90319  current_step:25320\n",
      "speed: 0.163s, remaining training time: 00:01:47:39\n",
      "total_losses:0.567\n",
      "cls_loss:0.139\n",
      "reg_loss:0.428\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:14: global_step:90339  current_step:25340\n",
      "speed: 0.171s, remaining training time: 00:01:53:13\n",
      "total_losses:0.517\n",
      "cls_loss:0.045\n",
      "reg_loss:0.472\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:17: global_step:90359  current_step:25360\n",
      "speed: 0.166s, remaining training time: 00:01:49:52\n",
      "total_losses:0.490\n",
      "cls_loss:0.127\n",
      "reg_loss:0.362\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:20: global_step:90379  current_step:25380\n",
      "speed: 0.162s, remaining training time: 00:01:47:18\n",
      "total_losses:0.718\n",
      "cls_loss:0.138\n",
      "reg_loss:0.581\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:27: global_step:90419  current_step:25420\n",
      "speed: 0.164s, remaining training time: 00:01:48:04\n",
      "total_losses:0.555\n",
      "cls_loss:0.139\n",
      "reg_loss:0.415\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:30: global_step:90439  current_step:25440\n",
      "speed: 0.162s, remaining training time: 00:01:47:01\n",
      "total_losses:0.830\n",
      "cls_loss:0.238\n",
      "reg_loss:0.592\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:34: global_step:90459  current_step:25460\n",
      "speed: 0.162s, remaining training time: 00:01:46:58\n",
      "total_losses:0.410\n",
      "cls_loss:0.097\n",
      "reg_loss:0.313\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:37: global_step:90479  current_step:25480\n",
      "speed: 0.163s, remaining training time: 00:01:47:30\n",
      "total_losses:0.507\n",
      "cls_loss:0.099\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:40: global_step:90499  current_step:25500\n",
      "speed: 0.165s, remaining training time: 00:01:48:33\n",
      "total_losses:0.505\n",
      "cls_loss:0.021\n",
      "reg_loss:0.484\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:44: global_step:90519  current_step:25520\n",
      "speed: 0.161s, remaining training time: 00:01:45:49\n",
      "total_losses:0.500\n",
      "cls_loss:0.046\n",
      "reg_loss:0.454\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:47: global_step:90539  current_step:25540\n",
      "speed: 0.171s, remaining training time: 00:01:52:30\n",
      "total_losses:0.480\n",
      "cls_loss:0.093\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:51: global_step:90559  current_step:25560\n",
      "speed: 0.174s, remaining training time: 00:01:54:32\n",
      "total_losses:0.623\n",
      "cls_loss:0.214\n",
      "reg_loss:0.409\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:34:54: global_step:90579  current_step:25580\n",
      "speed: 0.153s, remaining training time: 00:01:40:20\n",
      "total_losses:0.768\n",
      "cls_loss:0.200\n",
      "reg_loss:0.568\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:01: global_step:90619  current_step:25620\n",
      "speed: 0.156s, remaining training time: 00:01:42:12\n",
      "total_losses:0.643\n",
      "cls_loss:0.091\n",
      "reg_loss:0.552\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:04: global_step:90639  current_step:25640\n",
      "speed: 0.168s, remaining training time: 00:01:50:13\n",
      "total_losses:0.401\n",
      "cls_loss:0.042\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:08: global_step:90659  current_step:25660\n",
      "speed: 0.168s, remaining training time: 00:01:49:57\n",
      "total_losses:0.477\n",
      "cls_loss:0.023\n",
      "reg_loss:0.454\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:11: global_step:90679  current_step:25680\n",
      "speed: 0.169s, remaining training time: 00:01:50:34\n",
      "total_losses:0.515\n",
      "cls_loss:0.061\n",
      "reg_loss:0.454\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:14: global_step:90699  current_step:25700\n",
      "speed: 0.189s, remaining training time: 00:02:03:42\n",
      "total_losses:0.333\n",
      "cls_loss:0.035\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:18: global_step:90719  current_step:25720\n",
      "speed: 0.158s, remaining training time: 00:01:43:13\n",
      "total_losses:0.460\n",
      "cls_loss:0.044\n",
      "reg_loss:0.416\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:21: global_step:90739  current_step:25740\n",
      "speed: 0.172s, remaining training time: 00:01:52:14\n",
      "total_losses:0.569\n",
      "cls_loss:0.025\n",
      "reg_loss:0.544\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:24: global_step:90759  current_step:25760\n",
      "speed: 0.157s, remaining training time: 00:01:42:56\n",
      "total_losses:0.304\n",
      "cls_loss:0.045\n",
      "reg_loss:0.259\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:28: global_step:90779  current_step:25780\n",
      "speed: 0.164s, remaining training time: 00:01:47:15\n",
      "total_losses:0.396\n",
      "cls_loss:0.017\n",
      "reg_loss:0.379\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:35: global_step:90819  current_step:25820\n",
      "speed: 0.182s, remaining training time: 00:01:58:59\n",
      "total_losses:0.436\n",
      "cls_loss:0.065\n",
      "reg_loss:0.371\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:38: global_step:90839  current_step:25840\n",
      "speed: 0.172s, remaining training time: 00:01:52:21\n",
      "total_losses:0.274\n",
      "cls_loss:0.022\n",
      "reg_loss:0.251\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:41: global_step:90859  current_step:25860\n",
      "speed: 0.188s, remaining training time: 00:02:02:36\n",
      "total_losses:0.376\n",
      "cls_loss:0.025\n",
      "reg_loss:0.351\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:45: global_step:90879  current_step:25880\n",
      "speed: 0.167s, remaining training time: 00:01:49:01\n",
      "total_losses:0.298\n",
      "cls_loss:0.019\n",
      "reg_loss:0.278\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:48: global_step:90899  current_step:25900\n",
      "speed: 0.207s, remaining training time: 00:02:14:51\n",
      "total_losses:0.231\n",
      "cls_loss:0.008\n",
      "reg_loss:0.223\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:51: global_step:90919  current_step:25920\n",
      "speed: 0.158s, remaining training time: 00:01:43:02\n",
      "total_losses:0.304\n",
      "cls_loss:0.006\n",
      "reg_loss:0.298\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:55: global_step:90939  current_step:25940\n",
      "speed: 0.166s, remaining training time: 00:01:48:20\n",
      "total_losses:0.226\n",
      "cls_loss:0.019\n",
      "reg_loss:0.207\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:35:58: global_step:90959  current_step:25960\n",
      "speed: 0.163s, remaining training time: 00:01:46:08\n",
      "total_losses:0.330\n",
      "cls_loss:0.026\n",
      "reg_loss:0.304\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:02: global_step:90979  current_step:25980\n",
      "speed: 0.180s, remaining training time: 00:01:56:58\n",
      "total_losses:0.343\n",
      "cls_loss:0.017\n",
      "reg_loss:0.326\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:08: global_step:91019  current_step:26020\n",
      "speed: 0.173s, remaining training time: 00:01:52:19\n",
      "total_losses:0.347\n",
      "cls_loss:0.035\n",
      "reg_loss:0.312\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:12: global_step:91039  current_step:26040\n",
      "speed: 0.174s, remaining training time: 00:01:52:42\n",
      "total_losses:1.015\n",
      "cls_loss:0.519\n",
      "reg_loss:0.495\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:15: global_step:91059  current_step:26060\n",
      "speed: 0.164s, remaining training time: 00:01:46:37\n",
      "total_losses:0.409\n",
      "cls_loss:0.048\n",
      "reg_loss:0.361\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:18: global_step:91079  current_step:26080\n",
      "speed: 0.162s, remaining training time: 00:01:44:58\n",
      "total_losses:0.542\n",
      "cls_loss:0.045\n",
      "reg_loss:0.497\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:22: global_step:91099  current_step:26100\n",
      "speed: 0.172s, remaining training time: 00:01:51:41\n",
      "total_losses:0.475\n",
      "cls_loss:0.044\n",
      "reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:25: global_step:91119  current_step:26120\n",
      "speed: 0.167s, remaining training time: 00:01:48:15\n",
      "total_losses:0.497\n",
      "cls_loss:0.113\n",
      "reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:28: global_step:91139  current_step:26140\n",
      "speed: 0.153s, remaining training time: 00:01:39:16\n",
      "total_losses:0.479\n",
      "cls_loss:0.109\n",
      "reg_loss:0.369\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:32: global_step:91159  current_step:26160\n",
      "speed: 0.161s, remaining training time: 00:01:44:08\n",
      "total_losses:0.222\n",
      "cls_loss:0.013\n",
      "reg_loss:0.209\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:35: global_step:91179  current_step:26180\n",
      "speed: 0.156s, remaining training time: 00:01:41:06\n",
      "total_losses:0.548\n",
      "cls_loss:0.035\n",
      "reg_loss:0.513\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:42: global_step:91219  current_step:26220\n",
      "speed: 0.153s, remaining training time: 00:01:38:50\n",
      "total_losses:0.605\n",
      "cls_loss:0.138\n",
      "reg_loss:0.467\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:45: global_step:91239  current_step:26240\n",
      "speed: 0.166s, remaining training time: 00:01:47:06\n",
      "total_losses:0.482\n",
      "cls_loss:0.098\n",
      "reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:48: global_step:91259  current_step:26260\n",
      "speed: 0.162s, remaining training time: 00:01:44:41\n",
      "total_losses:0.323\n",
      "cls_loss:0.024\n",
      "reg_loss:0.299\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:52: global_step:91279  current_step:26280\n",
      "speed: 0.157s, remaining training time: 00:01:41:31\n",
      "total_losses:0.432\n",
      "cls_loss:0.027\n",
      "reg_loss:0.405\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:55: global_step:91299  current_step:26300\n",
      "speed: 0.152s, remaining training time: 00:01:38:11\n",
      "total_losses:0.350\n",
      "cls_loss:0.031\n",
      "reg_loss:0.319\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:36:58: global_step:91319  current_step:26320\n",
      "speed: 0.157s, remaining training time: 00:01:41:30\n",
      "total_losses:0.520\n",
      "cls_loss:0.029\n",
      "reg_loss:0.492\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:02: global_step:91339  current_step:26340\n",
      "speed: 0.170s, remaining training time: 00:01:49:19\n",
      "total_losses:0.531\n",
      "cls_loss:0.068\n",
      "reg_loss:0.463\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:05: global_step:91359  current_step:26360\n",
      "speed: 0.171s, remaining training time: 00:01:50:20\n",
      "total_losses:0.587\n",
      "cls_loss:0.077\n",
      "reg_loss:0.510\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:08: global_step:91379  current_step:26380\n",
      "speed: 0.163s, remaining training time: 00:01:44:53\n",
      "total_losses:0.684\n",
      "cls_loss:0.086\n",
      "reg_loss:0.597\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:15: global_step:91419  current_step:26420\n",
      "speed: 0.154s, remaining training time: 00:01:39:19\n",
      "total_losses:0.436\n",
      "cls_loss:0.097\n",
      "reg_loss:0.339\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:18: global_step:91439  current_step:26440\n",
      "speed: 0.165s, remaining training time: 00:01:45:56\n",
      "total_losses:0.452\n",
      "cls_loss:0.048\n",
      "reg_loss:0.404\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:22: global_step:91459  current_step:26460\n",
      "speed: 0.171s, remaining training time: 00:01:49:57\n",
      "total_losses:0.352\n",
      "cls_loss:0.021\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:25: global_step:91479  current_step:26480\n",
      "speed: 0.163s, remaining training time: 00:01:44:20\n",
      "total_losses:0.425\n",
      "cls_loss:0.059\n",
      "reg_loss:0.366\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:29: global_step:91499  current_step:26500\n",
      "speed: 0.157s, remaining training time: 00:01:40:43\n",
      "total_losses:0.260\n",
      "cls_loss:0.011\n",
      "reg_loss:0.249\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:32: global_step:91519  current_step:26520\n",
      "speed: 0.158s, remaining training time: 00:01:41:37\n",
      "total_losses:0.796\n",
      "cls_loss:0.024\n",
      "reg_loss:0.772\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:35: global_step:91539  current_step:26540\n",
      "speed: 0.164s, remaining training time: 00:01:45:06\n",
      "total_losses:0.492\n",
      "cls_loss:0.005\n",
      "reg_loss:0.487\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:38: global_step:91559  current_step:26560\n",
      "speed: 0.179s, remaining training time: 00:01:54:42\n",
      "total_losses:0.526\n",
      "cls_loss:0.063\n",
      "reg_loss:0.462\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:42: global_step:91579  current_step:26580\n",
      "speed: 0.173s, remaining training time: 00:01:50:47\n",
      "total_losses:0.463\n",
      "cls_loss:0.044\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:49: global_step:91619  current_step:26620\n",
      "speed: 0.164s, remaining training time: 00:01:44:45\n",
      "total_losses:0.472\n",
      "cls_loss:0.108\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:52: global_step:91639  current_step:26640\n",
      "speed: 0.162s, remaining training time: 00:01:43:36\n",
      "total_losses:0.911\n",
      "cls_loss:0.086\n",
      "reg_loss:0.825\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:55: global_step:91659  current_step:26660\n",
      "speed: 0.179s, remaining training time: 00:01:54:31\n",
      "total_losses:0.743\n",
      "cls_loss:0.254\n",
      "reg_loss:0.489\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:37:59: global_step:91679  current_step:26680\n",
      "speed: 0.151s, remaining training time: 00:01:36:20\n",
      "total_losses:0.649\n",
      "cls_loss:0.128\n",
      "reg_loss:0.522\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:02: global_step:91699  current_step:26700\n",
      "speed: 0.167s, remaining training time: 00:01:46:51\n",
      "total_losses:0.538\n",
      "cls_loss:0.073\n",
      "reg_loss:0.465\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:05: global_step:91719  current_step:26720\n",
      "speed: 0.163s, remaining training time: 00:01:43:40\n",
      "total_losses:0.309\n",
      "cls_loss:0.022\n",
      "reg_loss:0.288\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:09: global_step:91739  current_step:26740\n",
      "speed: 0.166s, remaining training time: 00:01:45:53\n",
      "total_losses:0.412\n",
      "cls_loss:0.056\n",
      "reg_loss:0.355\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:12: global_step:91759  current_step:26760\n",
      "speed: 0.156s, remaining training time: 00:01:39:19\n",
      "total_losses:0.552\n",
      "cls_loss:0.053\n",
      "reg_loss:0.499\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:15: global_step:91779  current_step:26780\n",
      "speed: 0.163s, remaining training time: 00:01:43:33\n",
      "total_losses:0.656\n",
      "cls_loss:0.088\n",
      "reg_loss:0.569\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:22: global_step:91819  current_step:26820\n",
      "speed: 0.158s, remaining training time: 00:01:40:51\n",
      "total_losses:0.384\n",
      "cls_loss:0.087\n",
      "reg_loss:0.297\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:26: global_step:91839  current_step:26840\n",
      "speed: 0.167s, remaining training time: 00:01:46:07\n",
      "total_losses:0.302\n",
      "cls_loss:0.018\n",
      "reg_loss:0.284\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:29: global_step:91859  current_step:26860\n",
      "speed: 0.164s, remaining training time: 00:01:44:08\n",
      "total_losses:0.394\n",
      "cls_loss:0.068\n",
      "reg_loss:0.327\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:32: global_step:91879  current_step:26880\n",
      "speed: 0.171s, remaining training time: 00:01:48:20\n",
      "total_losses:0.472\n",
      "cls_loss:0.135\n",
      "reg_loss:0.336\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:36: global_step:91899  current_step:26900\n",
      "speed: 0.161s, remaining training time: 00:01:42:06\n",
      "total_losses:0.266\n",
      "cls_loss:0.012\n",
      "reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:39: global_step:91919  current_step:26920\n",
      "speed: 0.178s, remaining training time: 00:01:52:54\n",
      "total_losses:0.471\n",
      "cls_loss:0.047\n",
      "reg_loss:0.424\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:42: global_step:91939  current_step:26940\n",
      "speed: 0.164s, remaining training time: 00:01:43:49\n",
      "total_losses:0.355\n",
      "cls_loss:0.012\n",
      "reg_loss:0.342\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:46: global_step:91959  current_step:26960\n",
      "speed: 0.169s, remaining training time: 00:01:47:10\n",
      "total_losses:0.423\n",
      "cls_loss:0.057\n",
      "reg_loss:0.365\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:49: global_step:91979  current_step:26980\n",
      "speed: 0.153s, remaining training time: 00:01:36:43\n",
      "total_losses:0.561\n",
      "cls_loss:0.058\n",
      "reg_loss:0.503\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:56: global_step:92019  current_step:27020\n",
      "speed: 0.162s, remaining training time: 00:01:42:51\n",
      "total_losses:0.012\n",
      "cls_loss:0.012\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:38:59: global_step:92039  current_step:27040\n",
      "speed: 0.170s, remaining training time: 00:01:47:26\n",
      "total_losses:0.493\n",
      "cls_loss:0.028\n",
      "reg_loss:0.465\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:03: global_step:92059  current_step:27060\n",
      "speed: 0.159s, remaining training time: 00:01:40:26\n",
      "total_losses:0.612\n",
      "cls_loss:0.081\n",
      "reg_loss:0.531\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:06: global_step:92079  current_step:27080\n",
      "speed: 0.164s, remaining training time: 00:01:43:45\n",
      "total_losses:0.494\n",
      "cls_loss:0.165\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:09: global_step:92099  current_step:27100\n",
      "speed: 0.162s, remaining training time: 00:01:42:14\n",
      "total_losses:0.375\n",
      "cls_loss:0.115\n",
      "reg_loss:0.261\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:13: global_step:92119  current_step:27120\n",
      "speed: 0.176s, remaining training time: 00:01:51:18\n",
      "total_losses:0.013\n",
      "cls_loss:0.013\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:16: global_step:92139  current_step:27140\n",
      "speed: 0.168s, remaining training time: 00:01:45:55\n",
      "total_losses:0.407\n",
      "cls_loss:0.019\n",
      "reg_loss:0.388\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:19: global_step:92159  current_step:27160\n",
      "speed: 0.170s, remaining training time: 00:01:47:00\n",
      "total_losses:0.591\n",
      "cls_loss:0.122\n",
      "reg_loss:0.469\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:23: global_step:92179  current_step:27180\n",
      "speed: 0.172s, remaining training time: 00:01:48:09\n",
      "total_losses:0.268\n",
      "cls_loss:0.016\n",
      "reg_loss:0.252\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:29: global_step:92219  current_step:27220\n",
      "speed: 0.170s, remaining training time: 00:01:47:03\n",
      "total_losses:0.551\n",
      "cls_loss:0.069\n",
      "reg_loss:0.483\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:33: global_step:92239  current_step:27240\n",
      "speed: 0.148s, remaining training time: 00:01:33:15\n",
      "total_losses:0.195\n",
      "cls_loss:0.006\n",
      "reg_loss:0.189\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:36: global_step:92259  current_step:27260\n",
      "speed: 0.173s, remaining training time: 00:01:49:06\n",
      "total_losses:0.361\n",
      "cls_loss:0.027\n",
      "reg_loss:0.334\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:39: global_step:92279  current_step:27280\n",
      "speed: 0.164s, remaining training time: 00:01:43:11\n",
      "total_losses:0.353\n",
      "cls_loss:0.028\n",
      "reg_loss:0.325\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:43: global_step:92299  current_step:27300\n",
      "speed: 0.152s, remaining training time: 00:01:35:36\n",
      "total_losses:0.449\n",
      "cls_loss:0.090\n",
      "reg_loss:0.359\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:46: global_step:92319  current_step:27320\n",
      "speed: 0.170s, remaining training time: 00:01:46:30\n",
      "total_losses:0.596\n",
      "cls_loss:0.040\n",
      "reg_loss:0.556\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:49: global_step:92339  current_step:27340\n",
      "speed: 0.163s, remaining training time: 00:01:42:16\n",
      "total_losses:0.451\n",
      "cls_loss:0.054\n",
      "reg_loss:0.397\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:53: global_step:92359  current_step:27360\n",
      "speed: 0.155s, remaining training time: 00:01:37:01\n",
      "total_losses:0.441\n",
      "cls_loss:0.007\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:39:56: global_step:92379  current_step:27380\n",
      "speed: 0.155s, remaining training time: 00:01:36:55\n",
      "total_losses:0.299\n",
      "cls_loss:0.059\n",
      "reg_loss:0.240\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:03: global_step:92419  current_step:27420\n",
      "speed: 0.155s, remaining training time: 00:01:37:11\n",
      "total_losses:0.415\n",
      "cls_loss:0.076\n",
      "reg_loss:0.340\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:06: global_step:92439  current_step:27440\n",
      "speed: 0.152s, remaining training time: 00:01:35:12\n",
      "total_losses:0.444\n",
      "cls_loss:0.037\n",
      "reg_loss:0.407\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:10: global_step:92459  current_step:27460\n",
      "speed: 0.173s, remaining training time: 00:01:48:19\n",
      "total_losses:0.643\n",
      "cls_loss:0.082\n",
      "reg_loss:0.561\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:13: global_step:92479  current_step:27480\n",
      "speed: 0.173s, remaining training time: 00:01:48:15\n",
      "total_losses:0.698\n",
      "cls_loss:0.101\n",
      "reg_loss:0.597\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:16: global_step:92499  current_step:27500\n",
      "speed: 0.163s, remaining training time: 00:01:41:51\n",
      "total_losses:0.280\n",
      "cls_loss:0.034\n",
      "reg_loss:0.247\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:20: global_step:92519  current_step:27520\n",
      "speed: 0.174s, remaining training time: 00:01:48:27\n",
      "total_losses:0.381\n",
      "cls_loss:0.036\n",
      "reg_loss:0.345\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:23: global_step:92539  current_step:27540\n",
      "speed: 0.176s, remaining training time: 00:01:49:52\n",
      "total_losses:0.447\n",
      "cls_loss:0.028\n",
      "reg_loss:0.419\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:26: global_step:92559  current_step:27560\n",
      "speed: 0.159s, remaining training time: 00:01:39:08\n",
      "total_losses:0.026\n",
      "cls_loss:0.026\n",
      "reg_loss:0.000\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:30: global_step:92579  current_step:27580\n",
      "speed: 0.161s, remaining training time: 00:01:40:19\n",
      "total_losses:0.305\n",
      "cls_loss:0.027\n",
      "reg_loss:0.278\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:37: global_step:92619  current_step:27620\n",
      "speed: 0.195s, remaining training time: 00:02:01:37\n",
      "total_losses:0.734\n",
      "cls_loss:0.012\n",
      "reg_loss:0.722\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:40: global_step:92639  current_step:27640\n",
      "speed: 0.179s, remaining training time: 00:01:51:32\n",
      "total_losses:0.324\n",
      "cls_loss:0.020\n",
      "reg_loss:0.304\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:43: global_step:92659  current_step:27660\n",
      "speed: 0.167s, remaining training time: 00:01:43:52\n",
      "total_losses:0.538\n",
      "cls_loss:0.097\n",
      "reg_loss:0.441\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:47: global_step:92679  current_step:27680\n",
      "speed: 0.153s, remaining training time: 00:01:35:24\n",
      "total_losses:1.145\n",
      "cls_loss:0.710\n",
      "reg_loss:0.435\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:50: global_step:92699  current_step:27700\n",
      "speed: 0.179s, remaining training time: 00:01:51:34\n",
      "total_losses:0.396\n",
      "cls_loss:0.014\n",
      "reg_loss:0.382\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:53: global_step:92719  current_step:27720\n",
      "speed: 0.154s, remaining training time: 00:01:35:53\n",
      "total_losses:0.449\n",
      "cls_loss:0.191\n",
      "reg_loss:0.258\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:40:57: global_step:92739  current_step:27740\n",
      "speed: 0.179s, remaining training time: 00:01:51:24\n",
      "total_losses:0.646\n",
      "cls_loss:0.042\n",
      "reg_loss:0.604\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:00: global_step:92759  current_step:27760\n",
      "speed: 0.156s, remaining training time: 00:01:36:47\n",
      "total_losses:0.567\n",
      "cls_loss:0.168\n",
      "reg_loss:0.399\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:03: global_step:92779  current_step:27780\n",
      "speed: 0.155s, remaining training time: 00:01:36:24\n",
      "total_losses:0.416\n",
      "cls_loss:0.014\n",
      "reg_loss:0.402\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:10: global_step:92819  current_step:27820\n",
      "speed: 0.153s, remaining training time: 00:01:34:59\n",
      "total_losses:0.605\n",
      "cls_loss:0.220\n",
      "reg_loss:0.385\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:13: global_step:92839  current_step:27840\n",
      "speed: 0.169s, remaining training time: 00:01:44:41\n",
      "total_losses:0.396\n",
      "cls_loss:0.042\n",
      "reg_loss:0.354\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:17: global_step:92859  current_step:27860\n",
      "speed: 0.170s, remaining training time: 00:01:45:17\n",
      "total_losses:0.645\n",
      "cls_loss:0.197\n",
      "reg_loss:0.448\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:20: global_step:92879  current_step:27880\n",
      "speed: 0.157s, remaining training time: 00:01:37:21\n",
      "total_losses:0.665\n",
      "cls_loss:0.272\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:23: global_step:92899  current_step:27900\n",
      "speed: 0.170s, remaining training time: 00:01:45:23\n",
      "total_losses:0.639\n",
      "cls_loss:0.052\n",
      "reg_loss:0.587\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:27: global_step:92919  current_step:27920\n",
      "speed: 0.167s, remaining training time: 00:01:43:19\n",
      "total_losses:0.413\n",
      "cls_loss:0.026\n",
      "reg_loss:0.387\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:30: global_step:92939  current_step:27940\n",
      "speed: 0.155s, remaining training time: 00:01:35:49\n",
      "total_losses:0.237\n",
      "cls_loss:0.027\n",
      "reg_loss:0.210\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:34: global_step:92959  current_step:27960\n",
      "speed: 0.160s, remaining training time: 00:01:39:02\n",
      "total_losses:0.387\n",
      "cls_loss:0.058\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:37: global_step:92979  current_step:27980\n",
      "speed: 0.152s, remaining training time: 00:01:33:45\n",
      "total_losses:0.314\n",
      "cls_loss:0.009\n",
      "reg_loss:0.305\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:44: global_step:93019  current_step:28020\n",
      "speed: 0.171s, remaining training time: 00:01:45:34\n",
      "total_losses:0.272\n",
      "cls_loss:0.022\n",
      "reg_loss:0.250\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:47: global_step:93039  current_step:28040\n",
      "speed: 0.183s, remaining training time: 00:01:52:27\n",
      "total_losses:0.687\n",
      "cls_loss:0.073\n",
      "reg_loss:0.614\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:50: global_step:93059  current_step:28060\n",
      "speed: 0.163s, remaining training time: 00:01:40:27\n",
      "total_losses:0.302\n",
      "cls_loss:0.008\n",
      "reg_loss:0.294\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:54: global_step:93079  current_step:28080\n",
      "speed: 0.166s, remaining training time: 00:01:42:15\n",
      "total_losses:0.624\n",
      "cls_loss:0.092\n",
      "reg_loss:0.532\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:41:57: global_step:93099  current_step:28100\n",
      "speed: 0.159s, remaining training time: 00:01:37:58\n",
      "total_losses:0.550\n",
      "cls_loss:0.048\n",
      "reg_loss:0.502\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:00: global_step:93119  current_step:28120\n",
      "speed: 0.167s, remaining training time: 00:01:42:36\n",
      "total_losses:0.633\n",
      "cls_loss:0.161\n",
      "reg_loss:0.471\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:04: global_step:93139  current_step:28140\n",
      "speed: 0.179s, remaining training time: 00:01:49:59\n",
      "total_losses:0.474\n",
      "cls_loss:0.037\n",
      "reg_loss:0.437\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:07: global_step:93159  current_step:28160\n",
      "speed: 0.160s, remaining training time: 00:01:38:15\n",
      "total_losses:0.388\n",
      "cls_loss:0.104\n",
      "reg_loss:0.285\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:10: global_step:93179  current_step:28180\n",
      "speed: 0.166s, remaining training time: 00:01:41:41\n",
      "total_losses:0.401\n",
      "cls_loss:0.026\n",
      "reg_loss:0.375\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:17: global_step:93219  current_step:28220\n",
      "speed: 0.169s, remaining training time: 00:01:43:44\n",
      "total_losses:0.465\n",
      "cls_loss:0.035\n",
      "reg_loss:0.430\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:21: global_step:93239  current_step:28240\n",
      "speed: 0.164s, remaining training time: 00:01:40:42\n",
      "total_losses:0.403\n",
      "cls_loss:0.037\n",
      "reg_loss:0.366\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:24: global_step:93259  current_step:28260\n",
      "speed: 0.165s, remaining training time: 00:01:41:04\n",
      "total_losses:0.254\n",
      "cls_loss:0.021\n",
      "reg_loss:0.233\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:27: global_step:93279  current_step:28280\n",
      "speed: 0.160s, remaining training time: 00:01:37:44\n",
      "total_losses:0.414\n",
      "cls_loss:0.024\n",
      "reg_loss:0.390\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:31: global_step:93299  current_step:28300\n",
      "speed: 0.168s, remaining training time: 00:01:42:48\n",
      "total_losses:0.928\n",
      "cls_loss:0.482\n",
      "reg_loss:0.446\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:34: global_step:93319  current_step:28320\n",
      "speed: 0.166s, remaining training time: 00:01:41:31\n",
      "total_losses:0.282\n",
      "cls_loss:0.015\n",
      "reg_loss:0.266\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:37: global_step:93339  current_step:28340\n",
      "speed: 0.161s, remaining training time: 00:01:38:12\n",
      "total_losses:0.435\n",
      "cls_loss:0.043\n",
      "reg_loss:0.392\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:41: global_step:93359  current_step:28360\n",
      "speed: 0.163s, remaining training time: 00:01:39:48\n",
      "total_losses:0.928\n",
      "cls_loss:0.233\n",
      "reg_loss:0.695\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:44: global_step:93379  current_step:28380\n",
      "speed: 0.163s, remaining training time: 00:01:39:14\n",
      "total_losses:0.690\n",
      "cls_loss:0.205\n",
      "reg_loss:0.485\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:51: global_step:93419  current_step:28420\n",
      "speed: 0.160s, remaining training time: 00:01:37:26\n",
      "total_losses:0.469\n",
      "cls_loss:0.154\n",
      "reg_loss:0.315\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:54: global_step:93439  current_step:28440\n",
      "speed: 0.162s, remaining training time: 00:01:38:33\n",
      "total_losses:0.416\n",
      "cls_loss:0.022\n",
      "reg_loss:0.393\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:42:57: global_step:93459  current_step:28460\n",
      "speed: 0.181s, remaining training time: 00:01:50:23\n",
      "total_losses:0.639\n",
      "cls_loss:0.205\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:01: global_step:93479  current_step:28480\n",
      "speed: 0.163s, remaining training time: 00:01:39:20\n",
      "total_losses:0.369\n",
      "cls_loss:0.012\n",
      "reg_loss:0.357\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:04: global_step:93499  current_step:28500\n",
      "speed: 0.164s, remaining training time: 00:01:39:46\n",
      "total_losses:0.540\n",
      "cls_loss:0.061\n",
      "reg_loss:0.479\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:07: global_step:93519  current_step:28520\n",
      "speed: 0.160s, remaining training time: 00:01:37:16\n",
      "total_losses:0.258\n",
      "cls_loss:0.040\n",
      "reg_loss:0.218\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:11: global_step:93539  current_step:28540\n",
      "speed: 0.172s, remaining training time: 00:01:44:16\n",
      "total_losses:0.360\n",
      "cls_loss:0.031\n",
      "reg_loss:0.329\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:14: global_step:93559  current_step:28560\n",
      "speed: 0.167s, remaining training time: 00:01:41:35\n",
      "total_losses:0.267\n",
      "cls_loss:0.013\n",
      "reg_loss:0.254\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:17: global_step:93579  current_step:28580\n",
      "speed: 0.161s, remaining training time: 00:01:37:53\n",
      "total_losses:0.324\n",
      "cls_loss:0.049\n",
      "reg_loss:0.274\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:24: global_step:93619  current_step:28620\n",
      "speed: 0.177s, remaining training time: 00:01:47:34\n",
      "total_losses:0.364\n",
      "cls_loss:0.020\n",
      "reg_loss:0.344\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:28: global_step:93639  current_step:28640\n",
      "speed: 0.154s, remaining training time: 00:01:33:35\n",
      "total_losses:0.617\n",
      "cls_loss:0.198\n",
      "reg_loss:0.420\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:31: global_step:93659  current_step:28660\n",
      "speed: 0.200s, remaining training time: 00:02:01:01\n",
      "total_losses:0.545\n",
      "cls_loss:0.111\n",
      "reg_loss:0.434\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:35: global_step:93679  current_step:28680\n",
      "speed: 0.157s, remaining training time: 00:01:35:14\n",
      "total_losses:0.443\n",
      "cls_loss:0.075\n",
      "reg_loss:0.368\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:38: global_step:93699  current_step:28700\n",
      "speed: 0.167s, remaining training time: 00:01:41:05\n",
      "total_losses:0.419\n",
      "cls_loss:0.035\n",
      "reg_loss:0.384\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:41: global_step:93719  current_step:28720\n",
      "speed: 0.161s, remaining training time: 00:01:37:37\n",
      "total_losses:0.346\n",
      "cls_loss:0.014\n",
      "reg_loss:0.331\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:45: global_step:93739  current_step:28740\n",
      "speed: 0.193s, remaining training time: 00:01:56:51\n",
      "total_losses:0.433\n",
      "cls_loss:0.041\n",
      "reg_loss:0.391\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:48: global_step:93759  current_step:28760\n",
      "speed: 0.168s, remaining training time: 00:01:41:44\n",
      "total_losses:0.489\n",
      "cls_loss:0.081\n",
      "reg_loss:0.408\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:51: global_step:93779  current_step:28780\n",
      "speed: 0.164s, remaining training time: 00:01:38:46\n",
      "total_losses:0.318\n",
      "cls_loss:0.008\n",
      "reg_loss:0.311\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:43:58: global_step:93819  current_step:28820\n",
      "speed: 0.165s, remaining training time: 00:01:39:19\n",
      "total_losses:0.355\n",
      "cls_loss:0.037\n",
      "reg_loss:0.317\n",
      "\n",
      "************************************************************************\n",
      "2021-06-01 18:44:02: global_step:93839  current_step:28840\n",
      "speed: 0.159s, remaining training time: 00:01:35:49\n",
      "total_losses:0.303\n",
      "cls_loss:0.010\n",
      "reg_loss:0.292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/tools/gwd\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/tools/gwd\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/mobilenet/mobilenet.py:357: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:139: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:219: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/losses/losses_gwd.py:29: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "/workdir/msc/RotationDetection\n",
      "WARNING:tensorflow:From ../../tools/test_hrsc2016_base.py:69: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:282: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ../../libs/models/necks/fpn_p3top7.py:24: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/anchor_heads/generate_anchors.py:21: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From ../../libs/models/detectors/gwd/build_whole_network.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../../tools/test_hrsc2016_base.py:84: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_hrsc2016_base.py:85: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      " CHECKPOINT PATH: /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_HRSC2016_L1/HRSC2016_129998model.ckpt\n",
      "\n",
      "******************************\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:173: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "model restore from : /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_HRSC2016_L1/HRSC2016_129998model.ckpt\n",
      "WARNING:tensorflow:From ../../tools/test_hrsc2016_base.py:90: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_hrsc2016_base.py:93: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-06-01 13:14:32.551155: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-06-01 13:14:32.574501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2021-06-01 13:14:32.576342: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58293b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-01 13:14:32.576385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-01 13:14:32.580982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-01 13:14:32.712423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6cd6820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-01 13:14:32.712484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2021-06-01 13:14:32.714509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65\n",
      "pciBusID: 0000:2d:00.0\n",
      "2021-06-01 13:14:32.714608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-01 13:14:32.717421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-01 13:14:32.719715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-01 13:14:32.720321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-01 13:14:32.723393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-01 13:14:32.725416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-01 13:14:32.731626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-01 13:14:32.733820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-01 13:14:32.733887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-01 13:14:32.736345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-01 13:14:32.736364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-01 13:14:32.736372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-01 13:14:32.738245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5)\n",
      "\n",
      "**********\n",
      "Restored model\n",
      "/workdir/msc/RotationDetection/output/trained_weights/RetinaNet_HRSC2016_L1/HRSC2016_129998model.ckpt\n",
      "**********\n",
      "  0%|                                                   | 0/444 [00:00<?, ?it/s]2021-06-01 13:14:34.770152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-01 13:14:35.749159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "Eval image 100000848: 100%|███████████████████| 444/444 [00:21<00:00, 20.23it/s]\n",
      "********************\n",
      "rotation eval:\n",
      "Writing ship VOC resutls file\n",
      "Threshold:  0.5\n",
      "cls : ship|| Recall: 0.9804560252602149 || Precison: 0.3125649013499481|| AP: 0.8702914852175588\n",
      "F1:0.8928377010759021 P:0.8867469879518072 R:0.8990228005708283\n",
      "mAP is : 0.8702914852175588\n",
      "\n",
      "\n",
      "Threshold:  0.55\n",
      "cls : ship|| Recall: 0.9641693803223376 || Precison: 0.3073727933541018|| AP: 0.8625760022051606\n",
      "F1:0.8839416234412855 P:0.8779116465863454 R:0.8900651458549957\n",
      "mAP is : 0.8625760022051606\n",
      "\n",
      "\n",
      "Threshold:  0.6000000000000001\n",
      "cls : ship|| Recall: 0.9438110741499909 || Precison: 0.3008826583592939|| AP: 0.8531906062262157\n",
      "F1:0.872433313689331 P:0.8968185726569218 R:0.8493485335103024\n",
      "mAP is : 0.8531906062262157\n",
      "\n",
      "\n",
      "Threshold:  0.6500000000000001\n",
      "cls : ship|| Recall: 0.9193811067431749 || Precison: 0.2930944963655244|| AP: 0.8390725935938772\n",
      "F1:0.8598862622520852 P:0.883920894239037 R:0.8371335498068945\n",
      "mAP is : 0.8390725935938772\n",
      "\n",
      "\n",
      "Threshold:  0.7000000000000002\n",
      "cls : ship|| Recall: 0.8770358299046939 || Precison: 0.279595015576324|| AP: 0.7538494855451576\n",
      "F1:0.828936868706933 P:0.8521066208082545 R:0.8070032566718214\n",
      "mAP is : 0.7538494855451576\n",
      "\n",
      "\n",
      "Threshold:  0.7500000000000002\n",
      "cls : ship|| Recall: 0.7833876215118992 || Precison: 0.2497403946002077|| AP: 0.6407896742574546\n",
      "F1:0.7603463208504235 P:0.7815993121238177 R:0.7402280124265244\n",
      "mAP is : 0.6407896742574546\n",
      "\n",
      "\n",
      "Threshold:  0.8000000000000003\n",
      "cls : ship|| Recall: 0.6156351786517629 || Precison: 0.19626168224299065|| AP: 0.45712748401881\n",
      "F1:0.6071976839081654 P:0.625 R:0.590390878998053\n",
      "mAP is : 0.45712748401881\n",
      "\n",
      "\n",
      "Threshold:  0.8500000000000003\n",
      "cls : ship|| Recall: 0.3216612375230771 || Precison: 0.1025441329179647|| AP: 0.15859279945832513\n",
      "F1:0.32029450311610613 P:0.3273809523809524 R:0.31351791505413845\n",
      "mAP is : 0.15859279945832513\n",
      "\n",
      "\n",
      "Threshold:  0.9000000000000004\n",
      "cls : ship|| Recall: 0.07573289896112956 || Precison: 0.024143302180685357|| AP: 0.012345679012345678\n",
      "F1:0.07573366273882778 P:0.0774468085106383 R:0.07410423446734182\n",
      "mAP is : 0.012345679012345678\n",
      "\n",
      "\n",
      "Threshold:  0.9500000000000004\n",
      "cls : ship|| Recall: 0.0024429967406815983 || Precison: 0.000778816199376947|| AP: 0.00030609121518212427\n",
      "F1:0.002767742965589178 P:0.003205128205128205 R:0.0024429967406815983\n",
      "mAP is : 0.00030609121518212427\n",
      "\n",
      "\n",
      "mAP50:95 :  0.5448141900750088\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/tools/gwd\n",
    "!python test_hrsc2016.py --img_dir='/datasets/msc/HRSC2016/HRSC2016/Test/AllImages'  \\\n",
    "                         --gpu=0 \\\n",
    "                         --image_ext='.bmp' \\\n",
    "                         --test_annotation_path='/datasets/msc/HRSC2016/HRSC2016/Test/xmls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workdir/msc/RotationDetection/tools/gwd\n",
      "2021-05-21 13:02:38.519306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/mobilenet/mobilenet.py:357: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:139: The name tf.layers.BatchNormalization is deprecated. Please use tf.compat.v1.layers.BatchNormalization instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/efficientnet/utils.py:219: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/losses/losses_gwd.py:29: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "/workdir/msc/RotationDetection\n",
      "************************************************************************************\n",
      "Already tested imgs: []\n",
      "************************************************************************************\n",
      "  0%|                                                   | 0/937 [00:00<?, ?it/s]process:0, start:0, end:469\n",
      "process:1, start:469, end:937\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:71: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:71: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:282: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:282: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/backbones/resnet_gluoncv.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/necks/fpn_p3top7.py:24: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../libs/models/necks/fpn_p3top7.py:24: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:86: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:87: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      " CHECKPOINT PATH: /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_DOTA_probiou_v2/DOTA_316004model.ckpt\n",
      "\n",
      "******************************\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:172: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:86: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:87: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "\n",
      "\n",
      "******************************\n",
      " CHECKPOINT PATH: /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_DOTA_probiou_v2/DOTA_316004model.ckpt\n",
      "\n",
      "******************************\n",
      "WARNING:tensorflow:From ../../libs/models/detectors/single_stage_base_network.py:172: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "model restore from : /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_DOTA_probiou_v2/DOTA_316004model.ckpt\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:92: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:95: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "model restore from : /workdir/msc/RotationDetection/output/trained_weights/RetinaNet_DOTA_probiou_v2/DOTA_316004model.ckpt\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:92: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../tools/test_dota_base.py:95: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-21 13:02:45.136419: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz\n",
      "2021-05-21 13:02:45.137389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x66abc70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-21 13:02:45.137416: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-21 13:02:45.139981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-21 13:02:45.150292: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3399905000 Hz\n",
      "2021-05-21 13:02:45.150768: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x681b560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-21 13:02:45.150806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-21 13:02:45.152963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-21 13:02:45.361523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.362397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x66abc70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-21 13:02:45.362414: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2021-05-21 13:02:45.363008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.363676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2021-05-21 13:02:45.363715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-21 13:02:45.377314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-05-21 13:02:45.379625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.380261: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x66ab470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-21 13:02:45.380276: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2021-05-21 13:02:45.380484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.380966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:02:00.0\n",
      "2021-05-21 13:02:45.380988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-21 13:02:45.383349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-05-21 13:02:45.387747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-05-21 13:02:45.387781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2021-05-21 13:02:45.389795: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-05-21 13:02:45.389796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2021-05-21 13:02:45.415467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-05-21 13:02:45.415522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-05-21 13:02:45.418842: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-05-21 13:02:45.418857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-05-21 13:02:45.420468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-05-21 13:02:45.420480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-05-21 13:02:45.420782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.420789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.425322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.425395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:45.428945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-05-21 13:02:45.429097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-05-21 13:02:45.429748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-21 13:02:45.429751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-05-21 13:02:48.182757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-05-21 13:02:48.182757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-05-21 13:02:48.182787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-05-21 13:02:48.182787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-05-21 13:02:48.182793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-05-21 13:02:48.182793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-05-21 13:02:48.183790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:48.183790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:48.184804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:48.184823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-05-21 13:02:48.185687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9992 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-05-21 13:02:48.185713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10104 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "restore model 0 ...\n",
      "restore model 1 ...\n",
      "2021-05-21 13:02:51.213426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-05-21 13:02:51.215090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-05-21 13:02:54.527038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "2021-05-21 13:02:54.738843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11\n",
      "Test image P0024.png: 100%|███████████████████| 937/937 [29:46<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "%cd /workdir/msc/RotationDetection/tools/gwd\n",
    "!python test_dota.py --test_dir='/datasets/dataset/DOTA/test/images'  \\\n",
    "                     --gpus=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
